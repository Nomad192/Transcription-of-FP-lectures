0:06
На сегодняшней лекции мы поговорим, как писать многопоточный код на Haskell,
0:11
какие есть примитивы для синхронизации потоков,
0:14
какие есть библиотеки для работы с этим,
0:18
потому что работа с низкоуровневыми примитивами имеет свои проблемы, и так далее.
0:23
Вот потихоньку небольшой план лекции.
0:26
Сначала мы обсудим, как писать многопоточные программы
0:30
в Haskell с использованием легковесных трудов.
0:34
Потом научимся синхронизировать эти потоки между собой и поймем,
0:39
какие в Haskell бывают базовые примитивы синхронизации.
0:42
Поговорим немного об эксепшенах в очередной раз,
0:44
потому что там, где обычно возникает конкуренция, возникают и эксепшены непременно.
0:50
Затем поговорим про библиотеку Async, самую популярную
0:54
в Haskell для работы с многопоточным асинхронным кодом.
0:59
Затронем немного такую вещь, как STM – Software Transactional Memory.
1:04
Затем в конце лекции поговорим про параллелизм.
1:07
Важное замечание, конкретно в рамках данной
1:09
лекции, да и в принципе, насколько мне известно,
1:12
по общепринятой терминологии, конкуренция – это про взаимодействие потоков между собой,
1:19
по тому, как они работают с каким-то shared
1:21
ресурсами, как их синхронизировать и так далее.
1:24
То есть это всегда про эошный код в терминах Haskell.
1:28
Параллелизм же, напротив, это когда у нас есть
1:30
какая-то чистая функция, и мы хотим ее распараллелить.
1:33
Мы сначала первую половину лекции, даже большую
1:36
часть, будем делять именно конкуренцией,
1:39
а затем коснемся параллелизма.
1:41
С параллелизмом в Haskell все весьма и весьма просто.
1:44
И в конце немного затронем на то, какие есть утилиты
1:47
для того, чтобы профайлить многопоточный код,
1:51
если вдруг оно кому-то пригодится.
1:59
Тут почему-то не грозит картинка.
2:01
Тут должна быть картинка про сравнение количества
2:05
памяти, которую потребляет Haskell интернет,
2:10
в сравнении с ирландовским процессом и джавовским и сишным петредом.
2:16
Спойлер – Haskell интернет занимает что-то типа…
2:21
Ладно, я не буду врать, сколько конкретно по памяти, но меньше всех.
2:25
Уж, по крайней мере, на момент создания этой презентации это было так.
2:29
Из чего мы делаем вывод?
2:30
Что Haskell – довольно удобный язык в терминах уж конкретного
2:36
потребления ресурсов для написания многопоточных программ.
2:39
На диаграммке это можно представить следующим образом.
2:41
То, что у нас есть ядра нашего процессора,
2:45
над ними идут OS-трэды, так называемые трэды операционной системы,
2:50
которые непосредственно исполняются на ядрах.
2:54
Над ними у нас есть Haskell легковесные трэды,
2:57
или, как по-другому говорят, green-трэды,
2:59
которые также есть во многих других языках.
3:02
Они не обязательно один в один мапятся к OS-трэдам.
3:06
То есть на одном OS-трэде можно запускать много-много Haskell легковесных трэдов.
3:12
И самая мелкая, самая гранулярная единица – это так называемые спарки.
3:18
О спарках мы будем говорить, когда будем говорить о параллелизме.
3:22
Спарк представляет собой маленькую задачку из fork-drawing-pool Haskell,
3:29
которую мы хотим запустить в отдельном потоке.
3:32
То есть если трэдов в Haskell можно наспавнить достаточно много,
3:37
потому что они не обязательно один в один мапятся
3:41
к OS-трэдам, потому что они достаточно легковесные,
3:43
то спарки – это куда более и более мелкая единица,
3:46
которой вообще можно тысячами плодить и никаким образом от этого не страдать.
3:54
Ну, разберем базовую функцию в Haskell, которая
3:57
нужна для того, чтобы создать новый трэд.
3:59
Она называется fork.io.
4:01
Она принимает какое-то риошное действие и возвращает трэд-айди, открывает его.
4:06
Что такое трэд-айди, мы поговорим немного попозже.
4:09
Точнее, немного попозже мы поговорим, что с ним можно делать.
4:12
Трэд-айди – это просто какой-то идентификатор конкретного Haskell-грин-трэда.
4:17
Здесь мы видим пример, как можно работать с функцией fork.io.
4:21
Например, мы в мейн-функции спавним следующее вычисление,
4:26
описанное do-блоком в новом потоке.
4:29
В нем мы ждем одну секунду, трэд-дилей принимает дилей в микросекунду.
4:34
Соответственно, тут мы ждем одну секунду, печатаем в консоль, что fork-thread awake.
4:39
А в мейн-трэде, после того, как мы запустили,
4:41
мы ждем две секунды и печатаем мейн-трэд finish.
4:46
Замечание. По дефолту, если мы компилируем Haskell-модуль через GHC,
4:54
не через stack, не через compile, то нам нужно
4:57
указывать при компиляции определенные флешки,
5:00
для того, чтобы наша программа скомпилировалась
5:03
для использования в многоточном режиме.
5:07
Для этого нужно использовать флаг min-threaded.
5:11
Также при запуске нашего экзешника, результирующего,
5:14
мы должны передать туда определенные флешки.
5:18
В Haskell есть вещь, которая называется RTS, или же runtime system.
5:23
Это библиотека, которая линкуется по итогу к вашему
5:28
объектнику, чтобы получился финальный экзекютабл.
5:33
То есть Haskell-код, как мы знаем, компилируется
5:35
в машинный код, и там нет виртуальной машины,
5:38
или там в отличие от Python, от JavaScript нет интерпретатора,
5:42
и весь необходимый вспомогательный код, например,
5:45
garbage collector или scheduler потоков,
5:48
он находится как раз-таки в этой библиотеке.
5:51
И когда мы запускаем нашу Haskell-программу, мы
5:55
можем, начав с плюс RTS и закончив минус RTS,
6:00
если мы потом еще хотим передать какие-то
6:02
другие опции, перечислить опции runtime system.
6:05
В данном случае мы ставим флажок минус n2, что означает, что используем два потока.
6:09
Мы тут не пишем минус RTS, потому что у нас после ничего не идет.
6:13
Если бы мы хотели еще передать какие-то аргументы
6:15
командной строки, мы бы закончили минус RTS.
6:20
Исполнение программы довольно интуитивно на двух потоках, потому что сначала,
6:24
так как у нас forked thread ждет меньше, печатается
6:27
это, а затем печатается main thread finish.
6:32
По дефолту, если мы опять же компилируем через GHC, без стека, без кабала,
6:38
без каких-то вспомогательных еще команд, которые указаны в стеке кабала в файле,
6:44
у нас многопоточность выключена. Но, тем не менее, данный код будет работать.
6:48
И ваше предположение, почему, во чем будет
6:51
работать, без явного включения многопоточности?
6:56
И как это будет происходить?
7:02
Ну, какое-то внутреннее представление языка многопоточности, наверное, происходит.
7:06
На самом деле все используется.
7:10
Только в питоне был. Когда-то очень давно.
7:15
Ну, в питоне все-таки, насколько мне известно,
7:18
есть так называемая вещь Global Interpreter Log.
7:21
И там, чтобы запускать отдельные потоки, люди исхитряются,
7:26
по крайней мере, до каких-то старых версий питона довольно сильно исхитрялись.
7:31
Тут же все будет, на самом деле, весьма прозаично,
7:33
потому что все действительно запустится на одном потоке.
7:36
Просто будет использоваться простой шедулер однопоточный,
7:40
который будет запускать действия по round robin, так называемому, то есть по очереди.
7:46
Какое-то действие минимальное прогоняется у первого потока, потом у второго,
7:50
потом опять у первого, потом у второго, так по
7:52
очереди, используя всего лишь один настоящий поток.
7:56
Поэтому, несмотря на то, что результат исполнения
7:58
конкретно в данном случае не изменится,
8:01
но важно понимать, что если мы явно не подключим многопоточность,
8:05
при указании соответственных флажков, хаскельный код будет работать в один поток.
8:10
Есть еще такой забавный спецфект. Насколько я помню, его нет дальше в презентации.
8:18
Как раз таки про то, как работает однопоточный шедулер в хаскеле.
8:21
Это если мы запустим два тардана, каждый из
8:24
которых будет с помощью putstrln печатать строчку,
8:29
одновременно, то есть без разных дилеев, то мы
8:32
будем видеть, если мы отключим буферизацию в выводе,
8:36
чтобы не флаттался у нас output после конкретного куска,
8:42
чтобы каждый символ выводился по одиночке.
8:45
Мы увидим такую забавную картину, что выводится по одной букве из первой строки,
8:50
чередуясь по одной букве из второй строки.
8:53
Что как раз таки будет явно иллюстрировать то,
8:55
как работает однопоточный шедулер в хаскеле.
8:57
Он работает довольно тупо.
8:59
Мы помним, что строка – это на самом деле список символов,
9:02
поэтому он просто будет по одному элементу от
9:05
этого списка откусывать и печатать консоль.
9:08
И, соответственно, если у нас будет putstrln aaa, потом bbb, мы увидим ab, ab, ab.
9:15
Забавно, что если мы будем использовать оптимальные хаскельные строки,
9:19
такие как текст или байтстринг, это не будет работать таким образом,
9:24
потому что они представлены не с помощью списка, а более эффективной реализацией,
9:28
и там они будут печататься полностью.
9:32
Это было такое лирическое отступление.
9:35
На данном слайде видно то, что я проговаривал минуту назад,
9:40
по поводу того, что вот у нас есть хаскельный исходник,
9:43
с помощью jhc мы его компилируем, получаем какой-то объект, файл с расширением .op.
9:48
Затем он линкуется с runtime-системой, которая называется libhs-rts.op.
9:55
Там находится гербыш коллектор, там находятся шедулеры и другие вещи,
9:58
необходимые для того, чтобы программа, которая написана вами, работала.
10:04
И также это линкуется с библиотеками, например, с библиотекой base,
10:08
которая подставляется с каждым исходным кодом на хаскель.
10:13
И таким образом после линковки всего этого дела мы получаем executable,
10:19
который мы уже можем запустить.
10:21
Вот в данном случае тест является executable.
10:26
А если мы захотим вдруг в интерпретаторе хаскеля jhc запустить многопоточный код?
10:31
Он запустится в отдельном потоке или в том же потоке, что и jhc,
10:35
и будет так же, как раунд Робина, гоняться по кругу?
10:40
Насколько я помню, при jhc можно также указывать флешки.
10:46
Возможно, они выглядят по-другому, но данное поведение также специфицируется.
10:53
Не могу на самом деле вам конкретно ответить на данный вопрос.
10:55
Никогда не экспериментировал с запуском многопоточки в jhc.
10:59
Но я уверен, что данное поведение также регулируется соответствующими флешками RTS,
11:04
которые можно установить, допустим, специальными
11:08
директивами, как мы ставим extension.
11:10
Через команду doi.js мы также можем, вероятно, установить какие-то опции RTS,
11:16
которые нам необходимы.
11:18
Но вопрос хороший.
11:19
К сожалению, точного ответа на него не имею.
11:31
Раунд Робин – поток работает с основным, да? Вместе?
11:37
То есть с главным.
11:38
Да, да. Это будет все работать в мейн-потоке.
11:43
То есть мейн-поток будет по очереди исполнять код, который мы написали здесь,
11:49
то есть в самом мейн-потоке, и который мы якобы форкнули в отдельный поток.
11:53
Но так как отдельных потоков у нас нет, это поток всего лишь один,
11:56
мейн-поток будет исполнять по очереди действия как из первого, так и из второго.
12:05
То есть если, допустим, там было бы три потока, а у нас только два потока запущены,
12:09
то у нас мейн-поток бы координировал бы еще,
12:11
допустим, каких-то два дополнительных потока.
12:17
Мейн-поток бы уже более хитрым образом координировался между двумя.
12:23
Очевидно, какая-то доля работы падала бы на мейн, но не обязательно.
12:26
То есть, если я вас правильно расслышал, вы сказали,
12:29
что мейн-поток координировал бы два дополнительных, это неверно.
12:31

12:32
Скорее, два потока координировали бы действия на трех потоках.
12:36
Что уже, на самом деле, довольно, я бы не сказал, что нечасто встречающаяся ситуация,
12:44
потому что у нас часто во всех этапах программирования есть такая вещь как трекпул,
12:49
где задач всегда больше, чем потока в этом пуле.
12:54
И у нас так получилось в данном случае, что
12:56
у нас трекпул из двух потоков на три задачи.
13:00
Они каким-то образом зависят от шедулера и его оптимизации,
13:05
и будут эти задачи шериться между данными двумя потоками.
13:15
Ок.
13:17
Есть ли еще вопросы?
13:20
Там в чате один человек написал, что не может зайти, возможно, его надо впустить.
13:26
Мне почему-то не видно.
13:32
Обычно у меня всплывает такая штучка.
13:35
Давайте я сейчас посмотрю.
13:39
Там справа, снизу.
13:43
Multiple people want to... А, господи, реально.
13:47
Почему-то в этот раз у меня не всплыл.
13:50
Обычно такая отвлекающая вещь всплывает.
13:53
Может, кто-то поменял настройки митинга из коллег.
13:58
Всем новоприбывшим, здравствуйте. Давайте продолжать, если нет еще вопросов.
14:04
Мы пока что разобрались, как в Haskell фортнуть Thread.
14:09
Спойлер, это можно сделать с помощью функции fork.io.
14:11
Тут ничего примечательного нет.
14:14
Ничего интересного мы не пропустили.
14:17
Давайте продолжать.
14:20
Раз уж мы умеем уже плодить на токе,
14:24
хорошо было бы научиться их синхронизировать.
14:26
Сейчас разберем основной примитив синхронизации потока в Haskell.
14:30
Он называется mvar.
14:32
mvar расшифровывается как mutex variable.
14:35
Это какая-то мутабельная переменная, защищенная mutex.
14:38
Сейчас разберемся, какой у нее API и как с ней работать.
14:42
Есть функция new empty mvar, которая создает пустой mvar,
14:48
то есть коробочку, в которой ничего не лежит.
14:50
И, понятно, данная функция, как и в случае с URF,
14:53
мутабельной переменной, которая в отличие от mvar не thread safe,
14:58
мы получаем наш результат в O.
15:00
Мы не можем в чистом ходе создать mvar.
15:03
Есть функция put mvar, которая принимает mvar
15:05
какое-то значение и кладет значение в mvar.
15:09
Соответственно, не возвращает ничего в URF контексте.
15:13
И также есть функция take mvar, которая берет наш mvar и
15:19
возвращает значение, которое в нем лежит, обернутое в O.
15:21
mvar работает следующим образом.
15:23
Это какая-то коробочка, в которой лежит значение типа A.
15:26
Данная коробочка может быть либо полная, то
15:28
есть там лежит какое-то значение, либо пустая.
15:31
Если мы хотим положить значение в коробку, которая уже полная, мы ждем.
15:36
Наш thread получится, пока какой-то другой thread
15:38
не заберет оттуда значение с помощью take mvar.
15:42
Наш thread будет ждать.
15:44
После того, как какой-то другой thread заберет,
15:46
наш thread положит и продолжит исполнять.
15:49
С take mvar ситуация аналогичная.
15:51
Если мы хотим взять значение из коробки, в которой ничего не лежит,
15:55
мы залочимся, пока никакой другой thread не положит туда значение.
16:02
Действительно, можно представить себе в голове,
16:05
как она более-менее реализована в терминах обычных
16:09
mutex, которые используются в других языках.
16:14
Давайте посмотрим пример, как мы можем использовать mvar.
16:17
Кстати, большинство из того, о чем мы будем говорить на сегодняшней лекции,
16:21
находится в стандартной библиотеке в модуле control.concur.
16:27
Помимо библиотека SYNC и SAM, которые не находятся в стандартной библиотеке, control.
16:30
concurrent – это base.
16:33
Также мы сегодня осветим вещи, в которых не присутствует base.
16:37
Для начала мы создаем две пустые коробочки и спавним до отрыда.
16:42
Первый thread ждет какое-то время и в первую коробку кладет числовое значение.
16:49
Второй тоже ждет какое-то время и кладет сроковое значение во вторую коробку.
16:54
Затем в данном main потоке мы ждем, пока оба из потоков завершат исполнение.
17:01
То есть в данном случае мы заспавним эти два отрыда и здесь будем ждать,
17:06
пока первый поток ждет секунду, мы эту секунду
17:08
будем ждать, пока наша коробочка не наполнится.
17:12
То же самое со второй коробочкой.
17:14
То есть это аналог так называемого join, который есть в других языках.
17:21
То есть для того, чтобы подождать, пока поток завершится.
17:25
Только в Haskell работа с этим происходит через mvar и его API.
17:31
По итогу мы дождались результатов обоих наших потоков и просто выгоним их в конце.
17:37
То есть take mvar, он именно ждет, пока сам
17:39
mvar не поменяется или что-то не заполнится.
17:44
Если вдруг будет пустая коробка, то он будет
17:47
ждать, а не бросит какой-нибудь exception,
17:49
что пустая коробка и я ничего не знаю, что там лежит.
17:53
Именно функция take mvar будет ждать.
17:56
Есть также в модуле control.concurrent функция
17:59
try take mvar, которая возвращает iobull.
18:03
Получилось или не получилось взять значение.
18:05
Точнее, она, помимо результата, который обернут в API,
18:08
она возвращает еще boolean сложок, насколько я помню.
18:11
А если в этот mvar никто ничего не положит, то поток будет ждать бесконечно долго?
18:17
Да, это будет deadlock.
18:22
Сейчас мы как раз таки разберем пример с deadlock и то,
18:27
какие именно в Haskell есть приколюхи, связанные с этим.
18:34
Действительно, если мы создадим программу, просто main.
18:38
run.do, создадим mvar и попытаемся его взять,
18:42
то наша программа должна работать бесконечно.
18:45
Спойлер. Рантайп система Haskell умеет детектить некоторые кейсы deadlock.
18:52
В основном, конечно, самые простые.
18:54
И в данном случае в Haskell будет кинуто
18:55
исключение по поводу того, что у нас deadlock.
18:58
Но далеко не все случаи deadlock в рантайп-системе Haskell умеет ловить.
19:04
Есть еще вопросы по mvar?
19:12
Когда мы положим значение, допустим, в tm1, у нас два потока ждут tm1.
19:22
У нас получится только на одном, да?
19:31
Обычно это называется, кажется, честность в терминах многоточности.
19:37
То есть, какой первый начал ждать, в порядке FIFO, такому и вернется.
19:41
То есть, да, второй будет ждать.
19:48
Могут ли два потока одновременно изменить mvar или mvar – это thread safe?
19:53
mvar – это thread safe.
19:58
Чтобы изменить mvar, конечно, есть в модуле control.concurrent функция update.
20:05
mvar, но на самом деле она работает через put.mvar и take.mvar.
20:08
Соответственно, чтобы изменить mvar, нужно ее сначала взять,
20:11
каким-либо образом изменить значение и обратно положить.
20:14
Несмотря на то, что для этого есть обертка, она реализована именно так.
20:19
Давайте представим ситуацию, что два потока одновременно хотят изменить mvar.
20:24
Так или иначе, какой-то первый из них возьмет и
20:27
прочитает значение с помощью take.mvar из коробки.
20:31
Второй в таком случае залочится, потому что, переводя
20:34
на аналогию из других языков программирования,
20:36
будет взят mutex на данную переменную.
20:39
Поэтому второй поток будет ждать, пока первый не положит обратно,
20:43
и второй возьмет уже обновленную версию.
20:44
Поэтому mvar – это третий примитив.
20:50
Спасибо.
20:52
Супер. Давайте продолжим.
20:55
Как уже говорилось, mvar – это просто значение, защищенное каким-то mutex.
21:03
И там, где обычно у нас возникают mutex в concurrency, у нас возникают и deadlocks.
21:09
Давайте разберем самый простейший пример deadlocks.
21:12
Как мы уже обсуждали ранее, давайте напишем main, в котором создается mvar,
21:17
и мы будем бесконечно ждать mvar.
21:20
Никаких других потоков в нашем приложении не существует.
21:23
Очевидно, что данный случай является простейшим примером deadlock в Haskell.
21:29
В данном случае, в силу того, что рантайм-система
21:31
Haskell умеет определять такие базовые кейсы deadlocks,
21:35
мы не будем ждать бесконечно, а наш main поток завершится заключением,
21:38
что thread blocked indefinitely in mvar operation.
21:43
Рантайм-система Haskell довольно умная и умеет распознавать такие кейсы.
21:48
Но не стоит над ним полагаться.
21:50
Если у вас есть менее тривиальный код, вполне возможно,
21:54
что обычным reference count это не задетектируешь.
21:58
Можно представить, как оно реализовано в Haskell.
22:01
Мы будем просто на каждый mvar считать количество потоков, которые ее ждут,
22:06
которые ждут для того, чтобы оттуда взять, и
22:08
которые ждут для того, чтобы туда положить.
22:10
И если у нас не сходятся эти значения,
22:13
например, один поток ждет, чтобы оттуда взять,
22:16
но ноль потоков туда кладут. Очевидно, в данном случае возникает deadlock.
22:22
Есть еще подобные исключения. Например, blocked
22:25
indefinitely on mvar, blocked indefinitely on stm.
22:30
Также есть исключение deadlock. Я его, кстати, ни разу не видел.
22:33
Это, видимо, deadlock, который возникает без
22:36
использования mvar с другими приоритетами синхронизации.
22:41
Но сам факт, что такие исключения для Haskell не
22:44
редкость, и на самом деле оно довольно полезное.
22:48
Иногда можно действительно добыть и допустить какую-то базовую ошибку,
22:52
которая в рамках системы Haskell сразу отловит.
22:57
С mvar на этом закончили.
22:58
И поговорим же теперь, что можно делать с значением
23:01
threadId, который возвращает у нас функция forKeo.
23:05
Делать можно, на самом деле, более-менее одну вещь.
23:08
Можно послать исключение в данный поток oid.
23:12
Делается это с помощью функции throwTo. Она принимает threadId,
23:17
принимает какое-то e, которое является instance класса exception.
23:21
То есть мы исключение с вами касались на лекции про его.
23:26
И ничего не возвращает.
23:28
Также есть оберточка killThread на функции throwTo, которая
23:32
просто данному threadId кидает исключение threadKilled.
23:36
Но можно кинуть какое-то другое исключение. То есть произвольный datatype,
23:40
который является instance класса exception.
23:43
Давайте разберем, как это можно делать.
23:45
Мы спавним какое-то тяжелое вычисление, которое может идти потенциально долго.
23:50
И хотим реализовать timeout.
23:52
Такой паттерн timeout, когда мы хотим ждать максимум одну секунду.
23:59
Иначе убивать данный поток. Потому что мы не хотим ждать больше.
24:11
Давайте продолжим.
24:13
Соответственно, мы хотим реализовать timeout в одну секунду для какого-то действия,
24:17
которое потенциально может идти больше. Что для этого можно сделать?
24:19
Мы форкаем наше вычисление потенциально тяжелое в
24:25
отдельный поток, запоминаем его threadId, ждем секунду.
24:28
И если же секунда прошла, а данный поток не завершился, мы его убиваем.
24:33
Соответственно, если данный поток уже завершился, killThread не будет ничего делать.
24:38
Для этого нужна функция killThread.
24:41
Но на самом-то деле механизм забегает вперед.
24:47
Немного скажу, что это называется асинхронное исключение.
24:51
Асинхронное исключение отличается от обычных,
24:53
которые мы с вами разбирали на лекции про ИО.
24:57
Допустим, когда мы читаем из файла, и файла не существует, вылетает исключение.
25:01
И так как это исключение возникло в том же потоке,
25:06
в котором мы работаем, оно называется асинхронное.
25:07
Асинхронное исключение – это исключение, которое
25:09
один какой-то поток бросает другому потоку.
25:11
Это очень похоже на механизм сигналов в линуксе.
25:15
Только вместо того, чтобы бросать какую-то чиселку
25:18
между разными процессами, в нашем случае потоками,
25:22
мы бросаем какие-то произвольные данные.
25:24
И на самом деле, так как мы умеем ловить эксепшены,
25:30
с помощью функции throwTo можно не только убивать поток.
25:33
То есть killThread – это один из видов того,
25:36
как можно использовать асинхронное исключение.
25:39
На самом деле, если нам очень захочется, на практике никто так, конечно же, не делает,
25:43
можно с помощью асинхронного исключения реализовать
25:46
полноценный механизм коммуникации между платформами.
25:49
То есть можно какие-то осмысленные данные класть в наш эксепшен,
25:55
кидать его в какой-то поток, в данном потоке ловить эксепшен,
25:58
и как-то обрабатывать эти данные.
26:00
Делать так, конечно же, не стоит, но сам факт, что механизм асинхронных исключений,
26:05
он не про то, как убивать потоки.
26:07
Он про то, как посылать другому потоку какое-то сообщение, какие-то данные.
26:12
А уж как этими данными распоряжаться, за это ответственный поток куда мы посылаем.
26:19
На практике это куда более сильный механизм, куда более
26:23
мощный механизм, чем просто взять и кинуть thread.
26:26
Иногда пригождается каким-то образом с этим исхитриться.
26:32
Давайте рассмотрим еще пример.
26:35
На то, как в нашем консольном приложении делать gracefully handle,
26:40
то есть каким-либо образом обрабатывать осмысленно control-c,
26:45
то есть seek-interrupt от пользователя.
26:50
Так как это эксепшен, который летит в наш мейн-поток.
26:53
Мы помним, что для того, чтобы ловить исключение, у нас есть функция catch,
26:57
и также есть ее аналог, функция handle, которая на самом деле flip-catch,
27:00
то есть это кетч с флипнутыми аргументами.
27:03
Напишем такую функцию как inter-hander, который понимает async-exception.
27:10
Давайте здесь несем ясность, что данная async-exception – это просто тип данных,
27:15
то есть это просто какой-то тип суммы для популярных и синхронных исключений,
27:19
которые определены в стандартной библиотеке.
27:21
Например, user-interrupt – это когда пользователь
27:24
нажимает control-c в нашем приложении.
27:26
Но данная async-exception и в принципе концепция асинкронных эксепшенов,
27:31
которые возникают при общении разных потоков между собой – это разные вещи.
27:37
Потому что мы можем создать какой-нибудь myException,
27:39
который не является типом async-exception,
27:41
и брать его в другой поток.
27:42
Просто для удобства, для популярных, часто встречающихся асинкронных исключений
27:47
в стандартной библиотеке заведем дата-тайп.
27:49
Одним из конструкторов async-exception является user-interrupt,
27:54
в который непосредственно конвертится
27:56
seek-interrupt, который летит в наш main-поток.
27:59
Что же мы, собственно, делаем?
28:01
Мы запускаем какое-то длинное, долгое вычисление в нашем main-потоке.
28:04
Мы идем по числам от 1 до 1000, на каждом из них ждем секунду,
28:10
и печатаем кодсоль, что завершили обрабатывать.
28:13
Если же пользователь во время этого нажмет control-c, у нас работает наш handler,
28:18
то есть в наш main-поток прилетит user-interrupt,
28:21
и мы каким-либо образом можем этот user-interrupt обработать.
28:25
Например, в каких-либо более умных случаях мы могли бы сделать clean-up
28:30
каких-то ресурсов, которые наша программа аллоцировала,
28:32
чтобы не было никаких утечек.
28:37
Получается, в случае user-interrupt мы пишем кодсоль,
28:40
что наша программа завершается, так как ее проработал пользователь,
28:43
иначе мы пишем, что поймали какое-то другое асинкронное исключение.
28:50
Есть вопросы по эксцепционам, асинкронным? Да-да, слушаю.
28:55
Можете сразу задавать.
28:58
А ThreadId – это ID-шник потока OS или внутри приложения?
29:04
Внутри приложения. В модуле control-concurrent
29:09
есть функция, которая называется OSThreadId,
29:13
которая возвращает IoInt или IoThreadId, которая непосредственно возвращает ID-шник
29:19
OS-ного потока, на котором запущен наш ThreadId.
29:24
Но ThreadId – это ID-шник конкретного легковесного green-thread-а хаскального.
29:31
Спасибо.
29:35
Окей, давайте продолжать.
29:37
И сейчас немного резюмируем наши знания об исключениях,
29:41
которые у нас имеются из лекций про Io и из сегодняшней лекции.
29:46
Для того, чтобы кидать асинкронные исключения, мы знаем, что существует две функции.
29:51
Есть функция throwIo, которая кидает исключения в Io-шном коде.
29:55
И есть функция throw, которая кидает исключения в чистом коде.
29:58
Например, throwIo используется в стандартной библиотеке, в функции openfile,
30:05
которая реализована через какой-то C-шный код.
30:08
Нам это не важно. Абсолютно. Мы видим, что здесь используется функция throwIo,
30:12
которая кидает какое-то Io-шное исключение.
30:15
В случае, допустим, деления на 0, мы кидаем чистое исключение,
30:18
потому что в чистом коде мы также хотим уметь кидать исключения.
30:22
Для этого существуют функции throw и throwIo.
30:26
Может ли мне кто-нибудь напомнить, какие функции
30:28
бывают для того, чтобы ловить исключения?
30:37
Handle на предыдущем слайде.
30:39
Handle и catch.
30:40
Да, Handle и catch.
30:42
Они Io-шные или чистые?
30:45
Handle равно-равно catch. Можно с точностью до перестановки аргументов.
30:48
Давайте рассматривать catch.
30:50
Это Io-шная или чистая функция? Io-шная.
30:53
Отлично.
30:56
Теперь давайте пофилософствуем над вопросом.
31:00
А если же мы хотим...
31:02
Вот у нас есть какой-то чистый exception, допустим, в случае деления на 0,
31:05
и мы хотим в чистом коде обработать наше исключение, то есть деление на 0.
31:12
Но функции для того, чтобы это сделать, нет.
31:16
Есть всего одна функция для того, чтобы ловить исключение. Это catch.
31:19
Вопрос, а как с этим жить?
31:22
Правда лишь, что если вся логика моей
31:24
программы чистая, я не могу поймать исключение.
31:30
Видимо, это значит, что у вас деление на 0 захардкошено в исходном коде,
31:34
вы его не снаружи получили.
31:35
Значит, с этим уже поздно что-то делать.
31:38
Поздно ловить, нужно в другом месте исправлять.
31:43
Ну, давайте возьмем какие-то более хитрые случаи возникновения чистых исключений,
31:49
которые у нас появляются в чистом коде.
31:52
Но я хочу в своей программе его словить, чистое исключение.
31:57
Но проблема в том, что у меня вся программа чистая.
32:01
Представим, что логика всей моей программы чистая.
32:06
Я не могу словить исключение.
32:08
Правда ли? Тут в моем вопросе есть небольшой подвох.
32:10
Просто он довольно сильно открывает глаза, этот вопрос на происходящее.
32:15
Хотел бы, чтобы указали на подвох.
32:19
Кажется просто, что если у нас летит исключение,
32:21
значит у нас, скорее всего, какое-то нечистое действие.
32:25
Максимум, что мы можем сделать из чистого такого, что бросит нам исключение,
32:29
это как раз-таки какая-нибудь именно логическая ошибка,
32:32
которую мы просто сами должны ручками отхандлить.
32:35
Например, разделение на ноль – это просто заефать.
32:38
Если, условно говоря, что-то еще происходит, что-то очень страшное,
32:41
то это просто заефать или вынести в отдельную функцию.
32:45
Ну, это как опция. Я согласен.
32:48
На самом деле функции error и undefined, с которыми вы
32:53
хорошо знакомы, они реализованы через функцию throw.
32:56
Допустим, функция error реализовывается через throw, так называемый error call.
33:01
Это один из конструкторов exception.
33:05
Но хочется все-таки их ловить, и давайте уже я тамить не буду.
33:08
На самом деле подвох в моем вопросе заключается в
33:11
том, что вся моя программа не может быть чистой.
33:14
У меня точка входа в программу – это main, который так или иначе ушли.
33:19
Поэтому если уж мне очень хочется поймать exception, который я кинул в чистом коде,
33:24
я это могу сделать только в ближайшем иошном коде, который вызывает мой чистый код.
33:30
В хаскале по-другому никак. То есть в чистом
33:32
коде нельзя ловить exception, только в иошном.
33:35
Но в крайнем случае, если уж нам очень хочется,
33:37
в любой программе есть иошный код – это main,
33:40
и там мы можем поймать исключение.
33:45
Вот в этом суть.
33:48
А если в программе нету main?
33:53
Допустим, если вы пишите библиотеку, так или иначе вы будете
33:57
ее использовать в конце концов в каком-нибудь экзекютабле.
34:01
И там есть main.
34:05
Если же вы пишете библиотеку, в которой нет никаких иошных функций,
34:11
допустим, это библиотека для арифметики, где трудно себе представить ее,
34:15
то действительно поймать exception, который вы кидаете из этой библиотеки,
34:19
можно только в программе, которая импортит вашу библиотеку в ее main.
34:25
Ну или в другой ее иошной функции.
34:28
Но мы здесь рассматриваем программу в хаскале
34:30
непосредственно как полноценное приложение с точкой входа.
34:33
То есть написание библиотек на такие вещи мы не делим.
34:38
Потому что так или иначе вашу программу плюс чью-то
34:40
библиотеку можно рассматривать как одну программу.
34:48
Окей, давайте пойдем дальше.
34:50
И сегодня мы с вами изучили еще один способ бросать исключения.
34:54
Это функция throwTool, которая бросает асинхронные исключения.
34:57
Важная ремарка, что с точки зрения рантайм-системы хаскаля,
35:02
эксепшены синхронные и эксепшены асинхронные
35:04
оба представлены type-классом exception.
35:08
То есть нет никакого различия для рантайма хаскаля,
35:11
является ли данный эксепшен синхронным или асинхронным.
35:16
Различие между этими эксепшенами сугубо семантическое по происхождению исключения.
35:20
Произошло ли оно в том же потоке, то есть
35:23
является ли оно асинхронным или асинхронным.
35:25
Рантайм-системе хаскаля на это наплевать.
35:32
Итого, мы имеем три способа кидать исключения, два из которых кидают синхронные,
35:36
одно из которых кидает асинхронные.
35:38
И ровно один способ, как эти исключения ловить.
35:41
Таким образом, небольшой самый нашей работы с эксепшеном.
35:46
Как ловить асинхронные исключения с помощью функции handle представлена на примере.
35:51
Ровно так же мы ловим наши асинхронные исключения.
35:53
Между ними никакой разницы нет.
35:56
Можно вопрос?
35:57
Да.
35:58
А у нас исключение кидается в момент ожидания?
36:06
Не совсем понял вопрос.
36:07
Вы имеете в виду, допустим, исключение в контексте
36:13
эмбарго, когда мы ждем какой-то mutex или что?
36:17
Да.
36:18
То есть в какой-нибудь Java, например, у нас исключение
36:23
из потока в поток кидается в момент ожидания.
36:26
То есть thread sleep или thread wait.
36:28
Какой-то такой потуз.
36:31
То же самое?
36:33
В Haskell асинхронное исключение может прилететь в любой момент.
36:39
То есть он может прервать какую-то операцию, если она не атомарна.
36:45
Когда мы пишем concurrent код в Haskell, мы должны держать в голове всегда,
36:50
что во время любой нашей операции нам может прилететь асинхронное исключение,
36:54
которое нам по-хорошему бы обработать в терминах очистки ресурсов.
36:58
То есть просто навесить хендлер на нашу программу.
37:00
Допустим, когда мы открыли файл, во время того, когда у нас
37:04
файл открыт, нам может прилететь асинхронное исключение.
37:05
Если мы не повесили хендлер, наш поток просто умрет.
37:08
Вот мы никаким образом не заглянапали ресурсы.
37:11
Поэтому в Haskell дело стоит так, что абсолютно в любой момент исключение прилетает.
37:18
Понял, спасибо.
37:21
Давайте разберем немного примеров с исключениями.
37:26
Как их можно кидать и как их можно ловить.
37:29
Первый пример достаточно простой.
37:31
Мы с помощью функции throw его кидаем какой-то myException,
37:34
который мы определили и реализовали для него instanceException.
37:38
Мы его кидаем, сразу же ловим с помощью функции catch,
37:41
и печатаем в консоль, что мы поймали эксепшен.
37:44
Здесь все довольно тривиально.
37:46
Затем разберем чисто эксепшен и, допустим, деление на 0.
37:50
Здесь мы используем функцию when.
37:51
When, как мы помним, это монетическая функция,
37:55
которая принимает какое-то условие и выполняет действие,
37:59
если это условие верно.
38:00
Если это условие не верно, ничего не выполняется.
38:03
Иными словами, происходит return в пустой скубочке.
38:05
Это просто такая обертка на default в бенче else в пустой скубочке.
38:12
Таким образом мы форсим данное выражение
38:14
вычислиться до слабой головной нормальной формы,
38:17
чтобы проверить, истинно или ложно условие.
38:20
Ловим исключение с помощью функции catch.
38:24
В данном случае бросится исключение типа it's exception,
38:28
а именно его конструктор divide by 0.
38:30
Мы его ловим и печатаем в консоль, что поймали,
38:33
также с помощью функции catch, уже чистое исключение.
38:37
И в конце концов разберем, как кидать и как ловить синхронные исключения.
38:43
Соответственно, мы форкаем какое-то вычисление в отдельный поток,
38:46
в нем мы ждем, и печатаем в консоль, что дело сделано.
38:52
И навешиваем на это действие хендлер.
38:55
То есть этот хендлер относится к этому действию.
38:58
То есть он идет после форкового.
39:00
Точнее, он относится к действию, которую мы форкнули в отдельный поток.
39:05
В catch мы также ловим наш myException и печатаем, что мы его поймали.
39:10
Ждем какое-то время, меньшее, чем на что это работает,
39:13
и кидаем myException на стред.
39:16
То есть здесь просто для примера было разобрано,
39:19
что API для работы для того, чтобы кидать и ловить синхронные исключения, довольно похож.
39:26
То есть ловим мы их все одинаково,
39:29
а кидаем просто используя разные функции.
39:32
То есть интерфейс exception в Haskell более-менее унифицирован.
39:40
Если есть какие-то вопросы по исключениям, давайте, иначе пойдем дальше.
39:49
Супер, видимо, нет.
39:52
И поговорим про сложности и трудности, которые
39:55
у нас бывают во время очистки ресурсов.
39:59
Представим себе такой код.
40:02
Наш main – это какое-то действие со следующим handler.
40:06
То есть мы ловим какой-то произвольный exception.
40:08
Кстати, напомнит ли мне кто-нибудь, как в Haskell,
40:14
используя функцию catch, можно поймать абсолютно любой exception?
40:23
То есть здесь мы видим, что мы матчимся по myException.
40:28
Это значит, что функция catch, сигнатура ее хендлера,
40:32
то есть сигнатура ее второго аргумента – это
40:34
myException, стрелка и о, пустые скобочки.
40:38
А как нам поймать любое исключение?
40:41
То есть любое значение является представителем класса типа catchException.
40:47
Мы это разбирали на лекции про EO.
40:57
Можно-то, по-моему, ловить catchException.
41:03
Проблема в том, что exception – это declass.
41:08
Создадим класс, который является instanceException, это exception и что-то такое.
41:14
Мы здесь писали раньше чуть выше instanceException, myException,
41:18
только теперь мы сделаем instanceException, exception его назовем, и все.
41:24
Это ничем не будет отличать.
41:26
Во-первых, конфликта имен у вас, кажется, все-таки не будет,
41:30
потому что это type класса, это data type.
41:33
Потому что в худшем случае у вас будет здесь конфликт нейминга,
41:36
но в лучшем случае у вас абсолютно ничего не изменится,
41:38
потому что ваш exception отличается от myException только именем.
41:42
То есть мысловой нагрузки оно не несет.
41:46
То есть exception – это не какое-то магическое слово,
41:48
которое позволяет в Haskell ловить произвольные исключения.
41:54
Давайте, если никто не помнит, я немного напомню,
41:56
что у нас есть такой data type, который называется someException.
42:04
Сейчас напишу в чате.
42:07
Это коробочка, которая умеет содержать внутри себя любое произвольное исключение.
42:14
И у нас в type классе exception существуют функции fromException и toException.
42:22
И с помощью функции fromException можно привести someException,
42:25
то есть какое-то произвольное исключение, мы пока не знаем, какое.
42:28
То есть какое-то наше исключение, которое лежит в коробочке.
42:31
Мы с помощью функции fromException можем попытаться
42:35
скальфить это произвольное исключение к нашему.
42:37
Можно с помощью функции fromException
42:40
попытаться привести someException к myException.
42:43
Функция fromException разрешает maybe.
42:45
То есть либо нам удалось распаковать someException, и там лежит то, что нам нужно,
42:50
либо там лежит что-то другое.
42:53
В данном случае нам вернется nothing.
42:55
Таким образом, если мы хотим в нашей функции поймать произвольное исключение,
42:59
но каким-либо конкретным образом обработать, допустим,
43:02
fileNotFound и divideByZero, условно говоря, мы ловим someException,
43:09
пытаемся достать из него arithException, то есть divideByZero.
43:13
Если нам удалось, мы каким-либо образом в специфичном обрабатываем.
43:16
Затем, если нам не удалось, мы пытаемся достать
43:19
оттуда ioshnyException pro fileNotFound.
43:22
Если нам удалось, мы каким-либо образом чистим ресурсы или делаем что-то еще.
43:27
И в каком-то общем кейсе, если там лежит что-то, что нам неизвестно,
43:30
какое-то произвольное исключение другое, которое нам не удалось достать,
43:33
мы каким-то последним случаем это обрабатываем.
43:39
В чем фундаментальная проблема?
43:41
В том, что тип нашего хендлера, вот этот аргумент, он называется хендлер.
43:47
То есть это обработчик с исключением.
43:49
Он должен иметь какой-то конкретный тип.
43:52
Мы здесь можем ловить только какой-то конкретный exception.
43:54
Допустим, myException или ourException.
43:58
Мы не можем тут поймать какой-то е, который exception.
44:01
И вот для того, чтобы уметь поймать что-то
44:03
произвольное, придумали такую вещь, как самException.
44:06
В него runtimeHaskell умеет запаковывать исключение, которое мы бросили.
44:12
Которое мы потом на стороне ловли можем распаковать.
44:15
На самом деле довольно важный аспект.
44:17
Если кто не помнит, я советую пересмотреть
44:19
это дело, пересмотреть слайды в лекции про IO.
44:23
Мы там довольно подробно на этом остановились.
44:26
Сейчас это было просто в качестве напоминания.
44:32
На чем мы остановились?
44:33
Мы остановились на том, какие у нас подводные камни могут быть вот в таком ходе.
44:38
То есть мы запускаем экшен, ловим с помощью него какой-то exception,
44:44
печатаем ошибку в консоль и делаем какой-то cleanup.
44:47
Видите ли вы какой-то подвох в этом ходе?
44:49
Что может быть не так?
44:57
Учитывая то, что для нашей программы,
44:59
представьте, критически важно почистить ресурсы.
45:04
Прям очень важно.
45:05
Ошибка во время cleanup.
45:08
Да, либо ошибка во время cleanup.
45:11
Или, допустим, эта ошибка может быть как синхронная, так и асинхронная.
45:16
Вряд ли функция printError умеет кидать синхронное
45:20
исключение, по ее логике, если мы ее нормально написали.
45:24
Но вполне возможно, она может произойти асинхронное исключение.
45:30
Давайте попробуем сделать так.
45:33
Но на самом-то деле, если присмотреться, лучше не становится.
45:36
У нас возникает бесконечная лесенка из кечей, вложенных
45:41
в каждом из которых может произойти исключение.
45:45
Сейчас мы разберемся, как с этим бороться.
45:49
У нас есть такая замечательная функция mask.
45:51
Вообще, существует две вариации функции mask.
45:54
Есть функция просто mask, она более сложная.
45:57
Мы разберем более простой случай, mask с нижним подчеркиваем.
46:00
Это функция, которая принимает какое-то иошное
46:03
действие и оборачивает его таким образом,
46:06
что оно защищено от асинхронных исключений.
46:10
То есть, в данном случае, пока наше действие
46:13
замаскировано, если можно так выразиться,
46:16
то его не может интерактнуть асинхронные исключения.
46:21
То есть, мы намеренно преграждаем, как будто образуется очередь из исключений,
46:25
если они туда летят, и перед ними ставится такое.
46:28
Но если это визуализировать, то можно сказать, что
46:31
мы блокируем проникновение exception в наш поток.
46:34
Блокируем, чтобы наш exception прервался в поток.
46:38
К сожалению, функция mask – это довольно опасная штука,
46:41
потому что таким образом у нас появляется...
46:44
Если же во время действия этого, которое мы оборачиваем с помощью функции mask,
46:50
наша программа внезапно зацикливается, то с ней
46:53
ничего нельзя делать, кроме как кинуть ей seek kill.
46:57
Потому что ни на какие асинхронные исключения, ни на всякие seek interrupt,
47:02
которые конвертятся в haskell на user interrupt, она не реагирует.
47:05
То есть, лучшее, что мы можем сделать с этой программой – это ее кинуть.
47:08
Поэтому функцию mask нужно использовать с осторожностью.
47:12
На какие-то минимальные действия, допустим, на чистку ресурсов,
47:17
в которых мы точно уверены, что там не может произойти
47:19
никакого зацикливания или бесконечного ожидания.
47:22
Потому что если мы в отчистке ресурсов хотим ходить куда-то по сети,
47:27
где возможен потенциальный тайм-аут, мы не хотим этого делать.
47:32
Поэтому для таких случаев функцию cleanup мы оборачиваем функцию mask.
47:38
И если же наша функция cleanup достаточно минималистичная,
47:41
то есть просто поудалять какие-то файлики или что-то еще,
47:45
хотя это тоже может быть небезопасно, мы пользуемся функцией mask.
47:56
Есть ли какие-то вопросы, может быть?
48:02
А если исключение прилетит во время принтерора, то мы тоже должны обернуть маску?
48:08
Да, можно написать. По-хорошему надо было,
48:11
наверное, раз уж мы говорим о худшем случае,
48:16
то действительно по-хорошему обернуть весь дублок в маску.
48:21
Также потому что исключение действительно может прилететь во время принтерора,
48:25
пока наше действие еще не стало замаскировано.
48:35
Можно еще раз быстренько? Что такое mask?
48:38
Это функция, которая оборачивает наше действие какое-то иошное
48:44
и возвращает новое иошное действие в так называемом masked state.
48:48
То есть, на самом деле, если лезть по трахаронтайм-системе в Haskell
48:52
и посмотреть состояние, какие бывают у потоков,
48:55
он может быть запущен, он может ожидать, и
48:57
вот одно из этих состояний называется masked.
49:01
Это значит, что данный поток не может быть прерван асинхронным исключением.
49:07
Представьте, что все асинхронные исключения, которые летят в наше действие,
49:12
которые находятся под маском, они туда не долетают.
49:17
Таким образом, оборачивая какое-либо действие с помощью функции mask,
49:22
мы делаем это действие непрерываемым нашими асинхронными исключениями.
49:27
Какая может быть проблема?
49:28
Проблема может быть в том, что если вот это
49:30
действие, которое мы обернули в функцию mask,
49:33
содержит в себе потенциальную бесконечную рекурсию или что-то еще,
49:36
или там какое-то долгое время исполнения, если мы идем куда-то по сети,
49:40
нам нашу программу становится никаким образом непрерывательным.
49:44
Потому что на seekInterrupt условно оно не будет реагировать,
49:48
потому что seekInterrupt представлен в Haskell
49:50
с соответствующим исключением – userInterrupt.
49:53
Лучшее, что мы можем сделать, и единственное,
49:55
что мы можем сделать в нашей программе,
49:56
это посылать туда seekKill, потому что для него нет обработчиков.
50:00
Поэтому функцию mask нужно использовать осторожно,
50:02
только в критически важных и минимальных местах, когда нам нужно почистить ресурсы.
50:08
Вот такая мораль.
50:15
Но на самом деле, слава богу, нам не приходится
50:18
в реальной жизни использовать функцию mask,
50:20
потому что за нас придумали более высокоуровневые
50:24
обработчики способа работы с ресурсами.
50:27
Мы уже на лекции про IO разбирали такие функции, как bracket и final.
50:32
Функция bracket представляет собой реализацию идиомы RAI в Haskell.
50:37
Это когда мы сначала берем, acquire-им какой-то
50:41
ресурс с помощью нашего первого аргумента,
50:46
мы предоставляем туда какое-то действие, которое
50:48
своим результатом дает нам какой-то ресурс.
50:51
Например, descriptor файл или соединение с базой данных.
50:55
Вторым аргументом мы принимаем вычисления по освобождению нашего ресурса.
51:01
То есть функцию из A в IO B, которая принимает
51:04
наш ресурс A, который был рожден первым действием,
51:07
и каким-либо образом с ним работает, закрывает его.
51:09
Допустим, закрыть соединение с базой данных, закрыть
51:11
сокет, закрыть файловый дескриптор, что-то в этом духе.
51:14
И третьим аргументом мы принимаем вычисления,
51:17
какое-то действие, которое запускается между ними.
51:21
То есть мы сначала acquire-им ресурс, потом
51:23
запускаем действие, потом release-им ресурс.
51:27
Функция bracket, вторая операция по релизу ресурса, на нее навежен маск.
51:35
То есть в явном виде маск мы практически никогда не применяем.
51:39
Потому что для работы с ресурсами, как правило, в Hustle
51:42
наиболее лучшей практикой является использование функции bracket.
51:46
Поэтому функция mask на самом деле просто находится под капотом
51:49
нашей функции bracket, которую мы юзаем в повседневной жизни.
51:52
Но мы коснулись функции mask просто для того, чтобы
51:55
понять, почему именно функция bracket так хороша.
51:57
Во-первых, у нее довольно удобный интерфейс, во-вторых, она
52:00
защищает нас от эксепшенов во время освобождения ресурса.
52:04
Также есть функция finally, она не такая популярная, но тем не менее.
52:09
Это представляет собой аналог finally блока в той же Java, только в Hustle это функция.
52:14
То есть мы принимаем какое-то вычисление и принимаем следующее вычисление.
52:19
Я всегда говорю про иошные действия, я всегда говорю вычисления.
52:23
Просто привычка, то есть очевидно у нас любое
52:24
действие в Hustle это какое-то вычисление.
52:27
То есть мы принимаем какое-то иошное действие и затем
52:30
принимаем действие, которое будет выполнено после него.
52:33
Даже если в данном случае будет кинутые исключения.
52:37
Это literally, finally из какой-нибудь Java.
52:42
То есть finally отличается от bracket тем, что у нас нет первого
52:45
действия, которое дает нам ресурс, которым мы пользуемся.
52:51
Ну и да, мораль всей басни.
52:55
Использование mask может быть проблематичным, с
52:58
ним очень легко ошибиться и получить программу,
53:01
которая становится unresponsive к каким-либо исключениям и сообщениям.
53:05
Лучше взять bracket.
53:08
Вторая мораль.
53:09
То, что каким-либо образом пытаться восстановить состояние
53:13
нашей программы от асинхронных исключений, это плохая идея.
53:17
Потому что мы помним в голове, что асинхронное исключение может прилететь всегда.
53:22
То есть очень тяжело в каждом моменте нашей
53:24
программы, на каждой строчке нашего кода думать о том,
53:27
а как же мне восстановить мое состояние от асинхронного исключения.
53:31
Всегда делаю так. Если нам прилетает асинхронное
53:34
исключение, мы просто чистим ресурсы и выходим нафиг.
53:38
И ничего больше не делаем в нашем потоке,
53:41
пусть это асинхронное исключение его убивает.
53:44
С этим становится жить намного и намного проще.
53:46
И последнее, о чем мы уже проговаривали с вами.
53:49
То, что асинхронные и синхронные исключения в
53:51
трехчетверении runtime системы Haskell не различимы.
53:54
Если же мы хотим, чтобы они были различимы в терминах хотя бы типов данных.
54:01
Вот, например, помните, у нас был UserInterrupt, который завернут в AsyncException.
54:07
Где же он был? Где-то он был.
54:12
Вот этот DataTypeAsyncException определен не в
54:16
стандартной библиотеке, а в пакете SafeExceptions,
54:21
который не дает ничего принципиально нового, а
54:24
просто нужным образом классифицирует эксепшены,
54:27
часто встречаемые для того, чтобы было удобнее их ловить.
54:32
Вот такая общая басня работы с эксепшенами в Haskell.
54:36
На первый взгляд кажется, что эксепшены в
54:38
Haskell это что-то очень непонятное и странное,
54:42
но на практике это довольно удобно.
54:45
Также можно почитать какой-то блог-пост, насколько я помню.
54:50
Да, это пост на fpcomplete про исключения, довольно хороший.
54:55
В свое время его читал.
54:57
Есть ли у вас какие-то вопросы по исключениям?
55:08
А мы вообще вот именно mask, который без
55:10
underscore мы будем где-то в курсе использовать?
55:13
Или это слишком опасная вещь для нас?
55:17
Я бы сказал, что не будете использовать.
55:19
Даже mask, который с нижним подчеркиванием, вам вряд ли пригодится.
55:26
Поэтому в какой-нибудь домашке у вас будет работа с файлами,
55:30
или, допустим, на практике у вас были таски для работы с файлами,
55:34
там можно использовать bracket условный, и это вполне себе ок.
55:41
Таски на многопоточность, я надеюсь, у вас будут
55:45
в этом году в домашках, но там mask не нужен.
55:56
Окей, давайте продолжать.
55:59
Продолжим со слайда, который имеет довольно интригующее название.
56:02
Никогда не используйте форкуео.
56:04
И сейчас мы разберем, почему форкуео – это достаточно низкоуровневый примитив,
56:10
и почему, используя форкуео, можно довольно легко
56:12
выстрелить себе в ногу с помощью такого примера.
56:16
Давайте заведем функцию, которая называется async.
56:19
exec, которая будет принимать еошное действие и
56:21
возвращать результат нашего еошного действия,
56:24
обернутый в mvar.
56:25
То есть мы принимаем какой-то action, создаем пустую коробочку,
56:30
запускаем наш action и кладем его результат в mvar.
56:33
И возвращаем mvar.
56:34
То есть это на самом деле обертка над boilerplate,
56:38
который раньше у нас был, если мы запускали поток.
56:39
Помните, у нас была функция, когда мы разбирали mvar,
56:43
мы там для каждого из потока писали такой boilerplate.
56:47
Сейчас мы его просто абстрагировали в отдельную функцию.
56:51
И таким образом сделали удобный примитив для того,
56:54
чтобы исполнять наше действие асинхронно в
56:56
отдельном потоке и возвращать его результат.
56:59
Потому что форкуео так делать не умеет, для этого нужно делать mvar,
57:02
что мы, собственно, и сделали.
57:05
И запускаем параллельно два действия.
57:08
Первый из них кладет в первый mvar результат,
57:10
второй из них кладет в второй mvar результат.
57:13
Затем удобно с помощью аппликативов достаем результат в пары.
57:19
То есть мы могли, как раньше, res1 достать с помощью takemvar,
57:25
res2 достать с помощью takemvar, все это переместить в пару.
57:27
Но зачем, если это можно сделать с помощью конструктора пары, поднятого в аппликативы.
57:33
Довольно удобно.
57:35
Таким образом у нас получается пара из результатов
57:41
двух наших действий, которые выполнены асинхронно.
57:43
И мы выводим в консоль эти результаты.
57:48
Что же может пойти не так, по-вашему,
57:52
зная о том, что после того, как мы с вами порядка 20 минут говорили об исключениях?
58:02
Логично, бросится какое-то исключение.
58:06
Конкретно в данном случае никакое исключение не бросится,
58:11
потому что наши действия, которые мы исполняем в потоках, довольно тупые.
58:17
То есть мы просто ждем и возвращаем какое-то значение.
58:20
А вот что, если действия у нас будут какие-то умнее?
58:23
Например, действия будут более интеллектуальные,
58:26
с какой-то более сложной логикой, которая чисто в теории может бросить exception.
58:29
Будем делить на 0.
58:31
Да, если в начальном потоке что-то бросим,
58:35
то основное, похоже, никогда не дождется.
58:38
Да, все верно.
58:40
Потому что представьте, что во время нашего экшена,
58:43
допустим, мы бросим myException во втором потоке.
58:47
Таким образом, мы в нашей функции asyncExec,
58:50
когда запустим действие forClose,
58:52
наш поток, в котором исполняется вот это действие, просто умрет,
58:56
и мы никогда не дождемся того, что putMvar отработает.
59:02
Таким образом, мы вернем пустой mvar.
59:04
То есть функция asyncExec вернет пустой mvar для второго действия.
59:09
Соответственно, данный mvar будет пустой,
59:11
и мы бесконечно заблочимся.
59:13
Собственно, это мы и увидим.
59:16
И, конечно же, абсолютно не хочется, чтобы такое происходило.
59:20
Потому что мы хотим как можно меньше париться
59:25
о синхронизации потоков при наличии исключений,
59:29
о потенциальных дедлоков,
59:31
и хотим иметь какие-то более высокоуровневые примитивы
59:35
для удобной работы с многопоточностью и эксепшенами.
59:39
Для этого у нас существует библиотека, которая называется async,
59:44
в которой уже есть функция, которая называется concurrently.
59:48
Сейчас мы ее разберем более подробно.
59:50
Concurrently принимает два иошных действия,
59:52
исполняет их параллельно и кладет результат в пару.
59:56
И в библиотеке async все спроектировано так,
59:59
что если вылетает какой-то эксепшен в одном из наших дочерних потоков,
1:00:04
он перепробрацивается в наш main поток.
1:00:06
Что довольно логично.
1:00:07
Потому что мы, если запамнили какой-то поток,
1:00:10
мы потенциально хотим знать, что если что-то в том потоке пошло не так.
1:00:14
Потому что если мы используем farqua,
1:00:17
нас абсолютно никто не предупредил о том,
1:00:20
что наш дочерний поток умер и наш mvar всегда будет пустым.
1:00:24
В случае библиотеки async это не так.
1:00:27
Таким образом, здесь вместо trend blocked indefinitely in mvar
1:00:33
мы получим myException, который был кинут в дочернем потоке.
1:00:37
Здесь мы могли его каким-либо образом поймать и обработать.
1:00:43
Если у нас какое-то второе вычисление недосчиталось,
1:00:45
положить на худой конец nothing и продолжить исполнение программы.
1:00:50
Это один из пойнтов, где farqua довольно опасен для использования.
1:00:57
Мы его разобрали сугубо в ознакомительной цели,
1:01:01
чтобы понимать, какой самый низкоуровневый примитив в Haskell для спавна потоков.
1:01:06
Но в реальной жизни им никто не пользуется.
1:01:08
Давайте уже разберем библиотеку async.
1:01:11
В принципе, в простых кейсах использование библиотеки async
1:01:20
можно ограничиться буквально двумя функциями.
1:01:22
Это функции concurrently и функции race.
1:01:26
По их названиям и сигнатурам довольно интуитивно понятно, что они делают.
1:01:31
Функция concurrently берет два иошных действия
1:01:34
и запускает их параллельно, возвращая результат в пару.
1:01:38
Функция race берет два иошных действия и возвращает изр из ab.
1:01:44
То есть она возвращает результат того действия, которое завершилось первым.
1:01:47
Что также бывает довольно удобно.
1:01:51
И с помощью farqua нам придется градить целый огород, чтобы это сделать.
1:01:54
А уж тем более, чтобы это все работало при наличии асинхронных заключений.
1:02:00
Вообще, библиотека async, помимо этого всего,
1:02:05
в отличие от farqua, вот эти функции спроектированы таким образом,
1:02:10
что наше ио-действие умеет возвращать какой-то результат.
1:02:13
Что уже довольно большой прорыв, потому что функция farqua, как мы помним,
1:02:17
принимает иошное действие, которое не возвращает результата.
1:02:21
И нам приходилось ручками писать boilerplate,
1:02:23
которое создает embar и кладет результат.
1:02:26
Библиотека async делает это за нас.
1:02:28
Также библиотека async человеческим образом поступает с exception,
1:02:34
интуитивно понятна программисту, в отличие от нативного использования farqua.
1:02:39
И также в библиотеке async есть множество примитивов полезных,
1:02:43
которые мы сейчас коротко коснемся, для более тонких
1:02:47
моментов обработки состояния наших асинхронных вычислений.
1:02:51
Но пока что остановимся на функции concurrently erase.
1:02:55
Давайте создадим функцию worker, которая принимает какой-то int,
1:02:59
будет ждать какое-то время, зависящее от нашего
1:03:03
int прямо пропорционально, и возвращать n квадрат.
1:03:07
И с помощью функции concurrently можно запустить два worker параллельно.
1:03:12
Или же с помощью функции erase можно запустить также два worker параллельно.
1:03:15
И тут очевидно, что вернется всегда left, потому
1:03:18
что левый по логике нашей функции ждет меньше.
1:03:21
Также, помимо функции concurrently erase, на самом деле
1:03:24
функция concurrently erase является некоторым баггерсом,
1:03:27
для того чтобы реализовать некоторые более сложные функции.
1:03:31
То есть с помощью функции concurrently можно реализовать функцию map concurrently,
1:03:37
которая принимает список каких-то действий и
1:03:41
запускает каждый из них в отдельном потоке.
1:03:47
Здесь мы понимаем и вспоминаем, что мы используем хаскельные грин трейды,
1:03:51
которые можно также вкладить сотнями или даже
1:03:54
тысячами, и наш программ не будет от этого плохо.
1:03:58
То есть сотни трейдов – это вполне себе окей.
1:04:03
Конечно же, с этим лучше не борщить.
1:04:05
Если на каждый чик создавать отдельный поток,
1:04:08
перформанс нашей программы очень и очень сильно просядет.
1:04:10
Но обработать какой-нибудь список из сотен
1:04:14
элементов в параллель ничего нам не мешает сделать.
1:04:18
Для этого существует функция map concurrently.
1:04:23
Но для того, чтобы моделировать какие-то кастомные условия,
1:04:33
многопоточные вычисления, мы хотим запустить
1:04:40
три потока и вернуть пару к первым элементам, которые являются изр.
1:04:49
Мы хотим, чтобы первым элементом этой пары был либо первый, либо второй поток.
1:04:55
Кто из них первый завершит.
1:04:56
И также третий поток, который будет работать с ними параллельно.
1:04:59
Короче, какие-то более нетривиальные кейсы, которые
1:05:01
выражаются, конечно же, через concurrently erase.
1:05:04
Но мы хотим иметь для этого более гибкое возможность.
1:05:07
Или мы хотим запустить четыре потока, первый со вторым,
1:05:10
или первый с третьим, второй с четвертым.
1:05:12
И все это дело параллельно.
1:05:15
Нам помогает new type, который называется concurrently.
1:05:18
Concurrently – это просто обертка над иошным действием,
1:05:22
который может быть скомпозирован с другими экземплярами типа concurrently,
1:05:27
с использованием инстансов этой класса, аппликатив и альтернатив.
1:05:31
И на самом деле инстанс аппликатива – это то же самое, что функция concurrently.
1:05:37
То есть она берет и оборачивает.
1:05:41
То есть мы с помощью инстанса аппликатива можем
1:05:44
взять и скомбинировать два наших действия,
1:05:47
чтобы они выполнялись параллельно.
1:05:49
То есть функцию concurrently можно легко
1:05:51
реализовать с помощью аппликативного инстанса.
1:05:53
Это просто мы берем конструктор пары, применяем к нашему первому действию,
1:05:58
применяем к нашему второму действию и вызываем
1:06:00
run concurrently, как просто разворачивая.
1:06:02
То есть я сначала говорил, что new type concurrently – это более общая вещь,
1:06:07
с помощью которой можно выразить concurrently erase более удобным образом.
1:06:11
Функцию erase также легко выразить через new type concurrently.
1:06:15
Что мы делаем?
1:06:16
Мы берем наше первое действие, запаковываем его в конструктор left
1:06:22
и через альтернативу комбинируем с вторым действием,
1:06:26
которое заворачивается в конструктор right и выполняется там worker 2000.
1:06:30
И в конечном итоге мы распаковываем все это дело с помощью run concurrently,
1:06:34
и у нас получается ровно то же самое, что функция erase.
1:06:38
Но это что-то более гибкое, потому что можно легко
1:06:41
сделать это для тюкла из трех или четырех элементов.
1:06:44
Или для нашего какого-то кастомного дата-тайпа,
1:06:49
каждое поле которого вычисляется в отдельном потоке.
1:06:52
То есть мы можем более-менее произвольным образом, с помощью двух данных инстанцев,
1:06:59
композировать параллельное вычисление.
1:07:02
Есть ли какие-то вопросы по этому поводу?
1:07:15
Окей, я надеюсь, что отсутствие вопросов, потому что все более-менее понятно,
1:07:19
а не потому что ни черта не понятно.
1:07:21
Это один момент. То есть мы тут можем только…
1:07:27
То есть это как бы обертка над concurrently erase, да?
1:07:31
Скорее наоборот. Скорее newtype concurrently позволяет…
1:07:36
Смотрите, функции concurrently erase – это
1:07:39
частные случаи работы с newtype concurrently.
1:07:43
Почему? Потому что вот мы на примере явно показали то,
1:07:47
как с помощью newtype concurrently и конструктора пары или же конструкторов изеров
1:07:52
смоделировать данные функции.
1:07:54
Но newtype concurrently – это что-то более общее.
1:07:57
Представьте, что у нас есть API для того, чтобы, имея два действия иошных,
1:08:05
либо запускать их параллельно и ждать оба,
1:08:10
либо запускать параллельно и ждать один из них.
1:08:12
И с помощью этого мы можем более-менее произвольную цепочку,
1:08:15
произвольное дерево наших concurrent вычислений смоделировать.
1:08:20
Мы можем это сделать также с помощью функции concurrently erase.
1:08:23
Никто не спорит.
1:08:24
Но в данном случае это будет просто какой-то огород из пар и изеров,
1:08:28
обернутых друг в друга.
1:08:29
В случае же newtype concurrently мы можем использовать абсолютно что угодно.
1:08:32
Вот здесь мы используем конструктор пары.
1:08:34
А представьте, что у нас есть какой-то юзер,
1:08:37
что у нас есть какой-то datatype юзер,
1:08:39
каждый из полей которого мы вычисляем в отдельном потоке.
1:08:42
В данном случае мы могли бы вместо конструктора
1:08:44
пары применить сюда конструктор юзера
1:08:46
и запустить не два потока, а три.
1:08:48
В случае с concurrently нам бы пришлось страдать,
1:08:50
у нас бы появилась вложенная пара из пар,
1:08:54
потому что первый элемент у нас один, а тут у нас два элемента,
1:08:57
потому что мы запускаем конкурентли внутри конкурентли.
1:08:59
Короче говоря, это более гибкий примитив для
1:09:02
конструирования произвольных параллельных вычислений,
1:09:06
которые могут результировать в абсолютно произвольный дататайп,
1:09:10
какой вашей душе угодно.
1:09:12
Просто у нас есть два оператора.
1:09:14
Вот такой вот для того, чтобы запустить параллельно и ждать оба,
1:09:19
и вот такой вот для того, чтобы запустить параллельно и ждать один из них.
1:09:22
Что после этого делать? Что вашей душе угодно.
1:09:24
Можете собрать любое абсолютно дерево, конкурент вычислений.
1:09:31
Получается, если бы мы там, допустим, конструктор листа применили,
1:09:35
то мы могли бы там бесконечное количество элементов считать.
1:09:39
Ну, оно бы у вас никогда не досчиталось,
1:09:42
если вы имеете в виду бесконечный список взять и запустить параллельно.
1:09:47
Наверное, вы имели в виду произвольное количество.
1:09:50
Да, действительно, мы можем запустить какое-то
1:09:53
произвольное количество вычислений здесь и обернуть это все в конструктор списка.
1:09:58
Почему нет? Таким образом реализовав как раз-таки map concurrently.
1:10:02
Все, понял, спасибо.
1:10:10
Ну, видимо, пойдем дальше.
1:10:12
И теперь разберем более детально то, что предоставляет нам библиотека Async.
1:10:19
То есть первое, что мы разобрали, это функции concurrently erase,
1:10:22
как самый-самый базовый API.
1:10:24
В самых базовых случаях его может хватать.
1:10:27
В случае, если нам нужно конструировать более
1:10:30
сложные деревья из наших параллельных вычислений,
1:10:33
мы используем new type concurrently.
1:10:36
Сейчас мы будем говорить про то, если нам нужно очень
1:10:40
внимательно следить за состоянием нашего асинхронного
1:10:45
вычисления, которое мы запустили в отдельном потоке.
1:10:47
Для этого существует функция visasync, которая принимает наше иошное действие,
1:10:54
вторым аргументом принимает функцию из так называемого async.
1:11:00
a, которая представляет собой вот это действие,
1:11:02
которое запущено асинхронно в новом потоке,
1:11:04
и его результатом является тип.a.
1:11:07
То есть это какое-то действие, которое мы запустили.
1:11:10
Непонятно, оно еще завершилось, оно еще не завершилось.
1:11:14
Но прикол функции visasync в том, что мы в каждый момент времени
1:11:19
с помощью функции wait, cancel, pull, которую мы сейчас разберем,
1:11:23
можем проследить за состоянием вычисления, которое мы запустили.
1:11:27
С помощью той же функции for.co и асинхронных исключений это можно было бы сделать,
1:11:33
просто запустив в отдельный поток и пытаться до
1:11:35
него достучаться с помощью асинхронных исключений.
1:11:38
Спросить, как ты там вообще выполняешься, собираешься ли ты завершаться или нет.
1:11:42
В библиотеке async, конкретно с помощью функции visasync,
1:11:47
у нас реализован удобный API для контроля за
1:11:49
асинхронными вычислениями, которые мы запустили.
1:11:54
Еще раз, наше вычисление, наше действие,
1:11:56
которое мы запустили асинхронно в другом потоке,
1:12:00
представляется дататайпом async.a.
1:12:03
Это просто какое-то действие, которое запущено в отдельном потоке в данный момент,
1:12:07
которое вернет результат.
1:12:10
Как мы используем функцию visasync? Давайте сразу разберем на примере.
1:12:13
Мы используем функцию visasync и скамливаем туда какое-то действие getUrl.
1:12:19
Таким образом, наш get запрос по данному URL будет исполняться параллельно.
1:12:26
И вот в этой функции, которая передается вторым аргументом,
1:12:30
мы можем оперировать вот этим дескриптором нашего вычисления,
1:12:36
которое выполняется параллельно.
1:12:38
Мы можем его подождать с помощью функции wait.
1:12:41
Мы можем его отменить с помощью функции cancel.
1:12:47
Мы можем сделать call, то есть спросить его, правда ли ты завершился.
1:12:53
Если завершился, то ты завершился с исключением или с результатом.
1:12:56
То есть если оно не завершилось, оно вернет nothing.
1:12:58
Если оно завершилось с исключением, оно вернет just, left some exception.
1:13:02
Если оно завершилось с результатом, оно вернет just, right результат.
1:13:08
Таким образом, у нас можно писать более сложные программы,
1:13:14
которые оперируют действиями, исполняющимися в разных потоках.
1:13:19
Допустим, мы хотим, чтобы наше действие не выполнялось слишком долго.
1:13:25
Мы можем тут подождать сколько-то там и сделать cancel.
1:13:29
Ровно так же, как мы делали с помощью функции call, но более удобно.
1:13:32
Итого, разбираем наш пример.
1:13:34
У нас есть два урла.
1:13:36
Мы хотим параллельно из них отправить get-запрос по этому урлу
1:13:41
и получить два byte-стринга как результат.
1:13:44
Для этого у нас есть функция getUrl.
1:13:46
Мы используем функцию visasync.
1:13:49
Запускаем первое вычисление параллельно.
1:13:51
Получаем descriptor первого нашего вычисления,
1:13:55
которое запускается параллельно, в переменную a1.
1:13:58
Затем сразу же мы запускаем второе вычисление в отдельном потоке, асинхронно,
1:14:02
и получаем его descriptor.
1:14:04
И вот, имея эти descriptors, мы можем с ними делать что угодно.
1:14:07
Но в данном примитивном случае мы просто берем и ждем оба из них и возвращаем пару.
1:14:13
То есть на самом деле данная функция не несет ничего нового,
1:14:17
ничего не делает умнее, чем конкартный.
1:14:21
Но сам факт того, что мы, имея данные вот эти штучки типа async,
1:14:26
могли бы делать с ними вещи произвольной сложности.
1:14:29
В отличие от функции concurrentlyErase, где мы запустили,
1:14:32
и бог весть, когда оно досчитается.
1:14:34
То есть функции concurrentlyErase, как и datatype.
1:14:38
concurrently, они про то, когда мы что-то запускаем в отдельный поток,
1:14:41
и не хотим особо это контролировать.
1:14:43
То есть когда-то оно досчитается, и нам это вернется.
1:14:47
Функции же visasync позволяют нам контролировать
1:14:51
то, что происходит в отдельном потоке.
1:14:54
Есть ли по этому поводу какие-то вопросы?
1:15:10
Окей, давайте тогда продолжать.
1:15:14
И разберем баянистый пример, который, мне кажется,
1:15:17
каждый из вас видел большое количество раз.
1:15:20
Представим, что у нас есть...
1:15:23
Можно? Можно? Один вопрос.
1:15:24
У нас перерыв будет?
1:15:28
Давайте сейчас немного окину глазами, сколько у нас осталось.
1:15:34
По ощущениям... Осталось немного.
1:15:35
Нет, на самом деле немного.
1:15:41
Короче, нет. Я думаю, что нам осталось где-то полчаса.
1:15:45
Потому что самый сложный материал мы уже прошли.
1:15:48
Я бы эти полчаса провел без перерыва, и мы бы разошлись.
1:15:52
Как вам?
1:15:55
Как вам такой вариант?
1:15:59
Я больше за то, чтобы не было перерыва.
1:16:03
Если не будет возражающих, давайте так и сделаем.
1:16:05
Потому что, да, несмотря на то, что у нас слайдов многовато,
1:16:08
последние 5-6 слайдов мы вообще не будем использовать.
1:16:12
Они есть для тех, кто интересуется.
1:16:15
Нам осталось разобрать транзакционную память и параллельность.
1:16:19
И все.
1:16:21
Если не полтора часа, я за.
1:16:23
Да, да.
1:16:24
Ну, давайте понадеемся, что мы все-таки закончим быстро,
1:16:28
потому что, опять же, самые сложные вещи мы уже прошли.
1:16:32
Давайте разберем в сотый раз пример, который вы
1:16:34
видите уже, наверное, в сотый раз на разных курсах.
1:16:38
Это перевод денег с одного счета на другой.
1:16:41
Заведем такой дататайп-аккаунт, который ERF,
1:16:45
который представляет собой просто мутабельную переменную с значением типа Integer.
1:16:50
ERF, который мы разбирали на лекции про EO.
1:16:52
И заведем функцию transfer, которая принимает количество денег,
1:16:57
account from, account to, и делает перевод денег со счета на счет.
1:17:04
Скажите, пожалуйста, почему это плохо?
1:17:06
Почему плохо так делать в конкретной данной реализации?
1:17:16
Нам могут прислать исключение между снятием денег и записью на другой счет.
1:17:22
Это валидно.
1:17:23
Это абсолютно валидно.
1:17:24
Но данный пример – это такой, знаете, каноничный
1:17:29
пример плохого конкуренции кода в отрыве от языка.
1:17:34
Если написать такой же код на Java, будет тоже плохо.
1:17:39
Это правда, что данный код страдает от асинхронных исключений,
1:17:42
но это далеко не его первая проблема первостепенная.
1:17:50
Аналогично, только вместо исключения компьютер выдергивают из розетки.
1:17:56
Вполне валидно.
1:17:58
В данном коде много проблем, но та, на которую я хотел бы сфокусироваться,
1:18:02
это то, что мы используем нетрассейт примитив для хранения денег на нашем аккаунте.
1:18:09
Нашу функцию transfer могут запустить параллельно из двух потоков,
1:18:13
и бог везь что, есть несколько вариантов того, каким образом
1:18:18
будет исполнена наша функция transfer в двух разных потоках.
1:18:23
Я уверен, что кажется на курсе Java такое было.
1:18:26
Возможно, у вас уже было на курсе параллелок.
1:18:29
Такой вот пример.
1:18:30
То, что использование нетрассейт примитивов в
1:18:32
реализации функции transfer – это прям суперплохо.
1:18:35
В принципе, как использование нетрассейт примитивов.
1:18:37
А я напоминаю, что EOF – это просто мутабельная переменная.
1:18:40
Она не ограждена мьютексом, нам не дается никакой
1:18:43
гарантии того, что операции над ней будут атомарными.
1:18:47
Да, там на самом деле есть функции atomic, modify и EOF, но мы и здесь не пользуемся.
1:18:53
То есть мы читаем и пишем в EOF.
1:18:56
Таким образом, использование нетрассейт примитивов
1:18:59
в Haskell и в любом другом языке программирования
1:19:02
при написании многоточных программ, точнее, программ,
1:19:05
которые могут исполняться в нескольких трудах – плохо.
1:19:10
Давайте уже исправим нашу реализацию, заменив EOF на embark.
1:19:18
И для простоты отрефакторим нашу функцию, заведем функцию debit.
1:19:24
Одна из них снимает, другая кладет деньги.
1:19:27
Соответственно, transfer – это debit from и credit to.
1:19:32
Видите ли вы здесь проблему при использовании мьютексов?
1:19:39
Кажется, та же проблема, что и говорили до этого с ошибками.
1:19:44
Да, она абсолютно валидна.
1:19:46
Помимо этого, на самом деле оно звучит немного нелогично,
1:19:52
то, что мы с вами половину лекции общались об ошибках,
1:19:55
и теперь они нам действительно везде мерещатся.
1:19:58
Но я вам так скажу, что в данном коде хочется
1:20:01
фокусироваться именно на логике программы,
1:20:04
а не на внезапно возникших исключениях.
1:20:09
Мы считаем ошибкой, что мы не проверяем достаточно денег для перевода.
1:20:14
Не считаем, не считаем.
1:20:16
Хорошо, может ли возникнуть данная программа deadlock?
1:20:29
На самом деле может, смотрите.
1:20:31
Как будто бы может, потому что никто не
1:20:33
гарантирует, что мы с одним и тем же аккаунтом...
1:20:36
Ну, то есть промо ту – это может быть один и тот же аккаунт,
1:20:39
и тогда они оба возьмут свою блокировку и не отдаст никто.
1:20:44
Да, это хороший поинт.
1:20:47
Помимо этого, есть еще представьте, если мы параллельно
1:20:49
исполняем трансфер с аккаунта А на аккаунт Б,
1:20:52
и с аккаунта Б на аккаунт А.
1:20:55
Что у нас может получиться?
1:20:56
Мы возьмем блокировку на аккаунт А и на аккаунт Б в разных функциях.
1:21:01
Получается, вот это наш первый, который взял блокировку
1:21:05
на А, он будет ждать, пока освободится мьютекс на Б.
1:21:08
А тот поток, который взял мьютекс на Б, будет ждать, пока освободится мьютекс на А.
1:21:13
Таким образом, у нас получается такое перекрестие – deadlock.
1:21:17
Первый поток ждет второй, второй ждет первый.
1:21:19
Они ждут этого бесконечно.
1:21:21
А разве так? У нас же вроде что кредит, что дебит держат
1:21:24
блокировку только на один аккаунт и сразу ее отпускают.
1:21:28
У нас нигде не берется две блокировки.
1:21:31
Смотрите, параллельно берется…
1:21:37
Здесь, кажется, проблема в том, что у нас два потока могли…
1:21:42
Снова транзакция с А на Б и с Б на А.
1:21:46
В момент, когда мы сделали takeMVAR, у нас там пусто, и
1:21:50
следующий takeMVAR, который из второй транзакции, он зависнет.
1:21:54
Мне кажется, вот из-за этого можно deadlock поймать.
1:21:57
Да, это справедливо.
1:21:58
Я, на самом деле, sorry, тут моя проблема.
1:22:01
Я действительно не особо вчитался.
1:22:02
Вот в такой реализации, если бы у нас реализация была не отрефакторенная,
1:22:06
когда мы сначала берем блокировку, а в самом конце ее отпускаем,
1:22:09
у нас действительно может быть проблема в том, что у нас заблокируется.
1:22:13
В данном случае такой проблемы нет, но все еще мы можем получить deadlock.
1:22:19
Как минимум потому, что у нас дебит и кредит – это то же самое.
1:22:22
И наш код не работает с учетом этого.
1:22:26
Короче, хочется иметь какой-то более удобный
1:22:30
примитив для работы с данными в многоточности,
1:22:36
когда мы не будем париться даже о взятии и отпускании mutex.
1:22:42
Такой примитив есть.
1:22:44
Он называется TEVAR, который расшифровывается как Transaction Variable.
1:22:50
И все это дело происходит в такой вещи, которая представлена FAST, LEMONADE и STM,
1:22:57
которая расшифровывается как Software Transactional Memory.
1:23:00
Software Transactional Memory – это такая конструкция,
1:23:04
которая позволяет нам исполнять некоторые участки кода,
1:23:08
на самом деле произвольные участки кода, транзакционно.
1:23:13
Транзакционно имеется в виду в первую очередь ATOMAR.
1:23:17
Транзакция – вы, возможно, слышали такой термин как база данных.
1:23:23
То, что оно должно удовлетворять свойствами ACID,
1:23:29
ATOMICITY, CONSISTENCY, ISOLATION и DURABILITY.
1:23:34
DURABILITY – это про то, что у нас данные хранятся на жестком диске.
1:23:39
Нас это конкретно не интересует, но свойства ATOMAR-ности,
1:23:43
изоляционности и консистентности нас интересуют.
1:23:46
Итого. На самом деле, кстати, спойлер.
1:23:50
Вы будете конструкцию Software Transactional Memory
1:23:53
изучать подробно с теоретической точки зрения
1:23:55
на курсе параллельного программирования, где-то на последних лекциях.
1:23:59
Поэтому мы сейчас не будем подробно останавливаться на том,
1:24:02
как же она реализована. Это выходит за рамки курса.
1:24:06
Нас это интересует сугубо с практической точки зрения.
1:24:08
Как применять данную конструкцию в Интерхаске.
1:24:12
Что нам позволяет делать STM?
1:24:14
STM нам позволяет брать произвольный блок кода,
1:24:23
который находится в монаде STM, и оборачивать его в функцию Atomic.
1:24:28
Что это значит?
1:24:29
Это значит, что наш блок кода будет исполняться весь, как одна атомарная операция.
1:24:35
Представьте, что у нас существуют две транзакции параллельно,
1:24:38
и вот этот блок кода называется транзакция.
1:24:41
То есть это какой-то код, который исполняется атомарно.
1:24:44
И изолировано друг от друга.
1:24:46
Представьте, что у нас существует две транзакции, вызванных параллельно,
1:24:50
которые работают над одними и теми же данными.
1:24:52
Допустим, вот в эти же самые дебиты играть.
1:24:55
И данные транзакции, если во время исполнения транзакции
1:25:00
данные были модифицированы другим потоком, транзакция умеет rollback.
1:25:04
То есть она умеет запускаться заново на уже обновленных данных.
1:25:08
И таким образом у нас гарантируется атомарность нашего действия.
1:25:12
Да, это не гарантируется хороший перформанс в данном случае,
1:25:15
потому что наши транзакции, если мы не оптимально написали код,
1:25:18
особенно применили STM не там, где нужно, наши транзакции могут много rollback.
1:25:23
Но зато нам не нужно брать никаких блокировок.
1:25:27
Мы заранее уверены в том, что весь наш блок кода,
1:25:31
который мы обернули в функцию Atomical,
1:25:36
используется параллельно.
1:25:38
Итого, смотрите.
1:25:41
Так как у нас все это дело находится в монаде STM,
1:25:44
мы уверены, что каждая из операций кредит и дебит является атомарной.
1:25:50
Это значит, что ничего не может произойти между вот этими операциями.
1:25:55
Если же, допустим, у нас вот этот аккаунт с айдишником 1
1:26:00
был модифицирован в какой-то другой транзакции,
1:26:03
то эта операция кредит rollback-ается полностью,
1:26:06
потому что была нарушена консистентность.
1:26:09
И запускается заново на уже обновленном состоянии.
1:26:13
Таким образом, мы гарантируем то, что у нас отсутствуют какие-либо датарейсы
1:26:19
или какая-то недетерминированность нашей программы
1:26:22
вследствие использования большего, чем 1 количества потоков.
1:26:28
Таким образом, STM является универсальным решением для того,
1:26:33
чтобы написать многоточечный код и абсолютно не думать о синхронизации.
1:26:38
Просто STM дает нам гарантию того, что наш блок кода,
1:26:43
который мы написали в Monado STM и который мы можем преобразить в EO
1:26:46
с помощью функции Atomical, выполнен атомарно.
1:26:51
Есть ли какие-то вопросы?
1:26:55
Не может ли быть такой ситуации, когда, например, мы вызвали функцию дебит,
1:26:59
у нас снялись деньги с счета, но вдруг после
1:27:02
этого нам прилетел какой-то exception все же.
1:27:06
От какого-нибудь, например, другого потока прилетел exception,
1:27:08
и мы не выполнили функцию кредит, и все, мы потеряли.
1:27:12
Транзакция rollbackается.
1:27:16
Гарантированно?
1:27:17
Да. То есть в STM реализован обработчик исключений,
1:27:23
который rollbackает транзакции в случае, если вы исключение не обработали.
1:27:26
Вы можете его обработать с помощью функции кедж STM,
1:27:32
которая на самом деле специализирована в функции кедж от STM.
1:27:35
Это не какая-то фундаментально новая конструкция.
1:27:38
Вы можете обрабатывать ее каким-нибудь своим образом.
1:27:41
И в таком случае не rollback транзакцию.
1:27:43
Тогда уже ответственность будет на вас, как на программистов.
1:27:45
Но по дефолту, при возникновении любой внештатной ситуации,
1:27:50
STM транзакции rollbackаются.
1:27:52
Потому что представьте, что у вас есть какой-то снимок данных,
1:27:56
изначальное состояние вашей программы, ваших данных на момент начала транзакции.
1:28:00
И эти действия, которые вы делаете в рамках транзакции, они делаются не in place.
1:28:04
Представьте, что вы куда-то копируете,
1:28:09
копируете на копии данных модификации,
1:28:11
и только если транзакция завершилась успешно,
1:28:13
вы накладываете эти изменения на актуальные данные.
1:28:16
То есть во время выполнения транзакции, по факту, ваши данные не модифицируются.
1:28:22
Потому что действительно очень сложно будет восстановить состояние вашей программы,
1:28:25
если вам где-то вот тут прилетело исключение.
1:28:28
Поэтому все это делается более хитро.
1:28:31
На самом деле там даже копия не создается, в каких-то из реализаций.
1:28:36
У STM бывают разные реализации, бывают с блокировками,
1:28:39
бывают без блокировок, но в Haskell используется реализация без блокировок.
1:28:45
Там все довольно хитро и продумано.
1:28:48
У STM это очень и очень хорошая вещь.
1:28:51
И удобная.
1:28:54
Для того, чтобы писать многоточечный код и вообще ни о чем не думать.
1:28:59
А в чем была проблема предыдущего кода, который без STM?
1:29:04
Так, давайте еще раз на нем остановимся.
1:29:08
У нас есть функция debit-credit, которую у нас использует EMWAR.
1:29:13
Утверждается то, что если у нас одновременно будет запущена...
1:29:19
Сейчас.
1:29:22
Давайте на нее еще раз поглядим.
1:29:24
Ну, как минимум, есть проблема того, что если у нас debit-credit вызовется,
1:29:28
что у нас трансфер будет с одного аккаунта, то мы бесконечно будем ждать.
1:29:35
Это первая проблема.
1:29:37
Вторая проблема того, что у нас все еще существует
1:29:39
дедлок, который я не могу глядеть глазами.
1:29:42
Он менее тривиальный, чем если бы у нас была реализация...
1:29:49
Хотя сейчас, подождите, дайте 3 секунды подумать.
1:29:52
С одним аккаунтом какая проблема?
1:29:55
Мы на него положили деньги, потому что...
1:29:57
У нас трансфер из одного аккаунта в один аккаунт.
1:30:04
Нет, на самом деле ладно.
1:30:05
У нас все более-менее нормально, потому что
1:30:07
данные действия у нас происходят последовательно.
1:30:09
Мы берем действительно take and buy, кладем,
1:30:12
потом берем еще раз take and buy и кладем.
1:30:14
Это в предыдущем могли быть какие-то проблемы, насколько я понял.
1:30:17
Я немного завис, подождите.
1:30:20
Я настолько давно не видел этот слайд.
1:30:22
А если у нас from и to – это один и тот же аккаунт?
1:30:25
Мы здесь заблокируемся на себе.
1:30:29
Окей, давайте разберемся.
1:30:30
Если from и to – это один и тот же аккаунт.
1:30:35
Мы берем и запускаем debit на from.
1:30:38
Мы берем take and buy и сразу же туда кладем.
1:30:44
У нас debit с кредитом не происходит параллельно.
1:30:48
Почему мы тут заблокируемся?
1:30:53
Две параллельные операции трансфера на одном и том же аккаунте.
1:30:58
Две параллельные операции трансфера на одном и том же аккаунте.
1:31:02
Мы заблокируемся, потом мы будем там ждать.
1:31:07
Почему же?
1:31:08
В одном потоке мы все-таки возьмем и второй поток не успеет и будет ждать.
1:31:15
Мы положим туда и второй аккаунт также возьмет.
1:31:19
У нас может получиться неконсистентное состояние,
1:31:22
что мы можем использовать debit в одной транзакции.
1:31:36
Смотрите, каждая из операций debit и кредит – она атомарна.
1:31:42
Но проблема в том, что у нас может произойти проблема,
1:31:46
пока мы отпустили лог после дебита и еще не взяли ее во время кредита.
1:31:52
То есть вот это место между строчками debit и кредит является нашей уязвимостью.
1:31:56
Потому что сам вот этот дублок не является атомарным.
1:32:00
Это makes sense? Или пока все еще не ясно?
1:32:05
Уязвимость к чему?
1:32:07
К тому, что пока мы не выполнили...
1:32:12
Смотрите, хочется, чтобы трансфер был атомарной операцией.
1:32:14
Представьте, что у нас на аккаунте первом лежит 10 рублей.
1:32:23
Мы здесь сняли какое-то количество денег, но еще не положили.
1:32:28
И в это же время, пока мы сняли деньги, но еще не положили,
1:32:31
запускается какая-то вторая транзакция параллельно,
1:32:34
которая залезает между нашим debit и нашим кредитом
1:32:38
и снимает еще раз деньги с этого аккаунта.
1:32:41
И если бы у нас тут была бы какая-то сложная логика,
1:32:43
у нас бы было бы выпрошено исключение того, что у нас типа hello, у нас нет денег.
1:32:48
Таким образом нарушается атомарность.
1:32:50
Трансфер предполагается атомарной операцией,
1:32:54
которая атомарно, то есть единым действием берет и снимает
1:32:59
деньги с первого аккаунта и кладет деньги на второй аккаунт.
1:33:01
Но в данном случае, между тем, как мы берем блокировку на первый аккаунт
1:33:07
и берем блокировку на второй аккаунт, у нас может залезть какой-то другой поток,
1:33:11
который также ждет блокировку на этот аккаунт и нарушит нашу консистентность.
1:33:15
Но согласитесь, довольно легко представить кейс,
1:33:18
когда между дебитом и кредитом залезает какой-то другой платеж,
1:33:24
который нам нафиг все рушит.
1:33:29
Только он выбросит исключение в своем потоке,
1:33:32
наш это исключение не получит и рано или поздно сделает кредит?
1:33:37
Наш кредит будет исполняться на неконсистентном,
1:33:43
у нас будет неконсистентность данных.
1:33:45
У нас делался дебит, мы хотим сразу же сделать кредит,
1:33:51
но у нас может быть такая ситуация, что мы сделали дебит тут,
1:33:55
а потом сделали дебит в каком-то другом потоке.
1:33:58
В данном случае у нас данные неконсистентные,
1:34:01
потому что мы сделали дебит с одного и того же
1:34:04
аккаунта два раза до того, как положили туда кредит.
1:34:08
Получается проблема только в этой неатомарности операций.
1:34:12
Проблемы с бейдлоками у нас нет здесь.
1:34:14
Да, это факт.
1:34:18
Проблем с бейдлоками, оказывается, нет.
1:34:20
Я перепутал пример с тем, что у нас есть такая вещь,
1:34:24
если вы помните, есть такая вещь, как в параллелках,
1:34:28
в курсе параллелок был такой пример, когда у нас аккаунт тоже дебит-кредит,
1:34:32
когда мы лочимся, когда it переводит jit, jit переводит it.
1:34:36
Я почему-то не обратил внимания на этот слайд, когда готовился к лекции,
1:34:39
думал, что это ровно тот же самый пример, но все понятно, тут deadlock.
1:34:42
На самом деле, нифига.
1:34:44
Тут проблема в отсутствии атомарности.
1:34:47
Смотрите, в том, что mutex позволяет нам
1:34:55
действие над какой-либо структурой данных делать атомарным.
1:34:59
Но если у нас имеется взаимодействие сразу с несколькими структурами данных,
1:35:03
в данном случае у нас структура данных простая, это просто коробка симптомов.
1:35:06
Но даже в таком простом случае,
1:35:08
когда наша логика оперирует
1:35:13
несколькими разными структурами данных,
1:35:15
операции над каждой из которых атомарны,
1:35:18
пусть это у нас коробки симптомов, пусть это у
1:35:22
нас concurrent очередь, пусть у нас что-то ещё,
1:35:23
несмотря на то, что операции над каждой из них атомарны,
1:35:29
нам не гарантируется того,
1:35:31
что операции над композицией фиктур данных,
1:35:33
когда мы используем эту и эту структуру данных,
1:35:35
то что какие-то более комплексные операции
1:35:37
над ними являются атомами. В этом как раз-таки
1:35:40
основная проблема использования блокировок.
1:35:44
В том, что в данном случае это решалось бы, как
1:35:47
говорилось у вас в курсе параллельного программирования,
1:35:50
грубой блокировкой. Когда мы нафиг лочим все,
1:35:53
делаем debit-credit и потом отпускаем блокировку.
1:35:56
Но это у нас значительно уменьшает процент кода, который исполняется параллельно.
1:36:03
Казалось бы, это тоже тогда получится проблемой,
1:36:06
что мы навешиваем блокировку на весь трансфер,
1:36:08
что у нас очень мало кода исполняется параллельно, и
1:36:13
все равно эти трансферы полностью блокируют систему,
1:36:17
до тех пор, пока они не завершатся со своими debit и credit.
1:36:20
Казалось бы, почему нельзя оставить атомарными только debit и credit,
1:36:27
и просто какую-то ксевдо-очередь создать.
1:36:30
Если кто-то вызвал debit, значит, надо потом после этого вызвать credit.
1:36:35
Когда-нибудь вызовем. Когда придет время, когда дойдет до этого процесса.
1:36:40
И то, что там не атомарность операций трансфер, никак на это не повлияет.
1:36:45
Но вы хотите с помощью данной очереди как раз-таки обеспечивать порядок того,
1:36:49
что после debit обязательно должен идти credit, то, что никто перед ними не залезет.
1:36:54
То есть вы хотите исполнить debit и потом в очередь
1:36:57
положить credit, который исполнится в следующем.
1:36:59
На одном потоке никто между ними не залезет.
1:37:03
На нескольких потоках, пожалуйста, пусть другие залезают, это не помешает нам.
1:37:07
Нет, есть проблема, что если у тебя, допустим, в аккаунте 0 рублей,
1:37:13
и у тебя происходит debit, то у тебя exception возникает.
1:37:17
А как раз-таки STM делает такую штуку, что он не возникнет, если операций достаточно.
1:37:26
То есть если там кредит какой-то произошел.
1:37:28
Если мне приходит debit, когда у меня на аккаунте
1:37:30
0 рублей, то явно я сам делаю что-то не так.
1:37:33
Потому что зачем мне снимать деньги, где у меня 0 рублей.
1:37:36
А может быть этот debit приходит, когда у вас 0
1:37:38
рублей из-за того, что кредит не успел исполниться.
1:37:44
Это уже проблема кода.
1:37:48
Потому что по логике вашей программы, представьте,
1:37:52
у вас есть debit-кредит и еще один debit-кредит.
1:37:56
И они исполняются параллельно.
1:37:59
По логике пара debit плюс кредит должна исполняться атомарно.
1:38:03
Если у вас залезло оно вот так вот друг на друга, это проблема программы.
1:38:07
Потому что состояние на момент второго дебита неконсистентное.
1:38:11
Потому что вам еще не успел прийти кредит на ваш счет.
1:38:16
А что если в следующем дебите он также используется?
1:38:20
И логика вашей программы рассчитывает на то, что состояние консистентное.
1:38:24
То, что трансфер исполнился полностью, но он исполнился не полностью.
1:38:30
Короче, по-моему, довольно очевидный момент в том, что мы хотим, чтобы
1:38:36
как можно больше вещей в нашей программе имела инвариант атомарности.
1:38:43
Так намного проще писать код.
1:38:44
Когда мы не задумываемся над тем, исполняется ли данный кусок атомарно или нет.
1:38:49
Также очевидно, что мы сейчас поняли, что если мы
1:38:53
используем атомарные примитивы, атомарные операции,
1:38:58
друг за другом, это не делает всю нашу последовательность операции атомарной.
1:39:04
Потому что так или иначе между ними может кто-то залезть.
1:39:07
А если между ними кто-то залезает, это плохо, потому
1:39:11
что нарушается консистентность нашей программы.
1:39:16
На мой взгляд, пример с дебитами и кредитами уже весьма репрезентативен.
1:39:21
Потому что в промежуточных состояниях у нас может быть на
1:39:24
аккаунтах лежать не то количество денег, которое должно лежать,
1:39:27
потому что не успел дойти к кредитам.
1:39:29
Но на каких-то более сложных примерах, я
1:39:31
уверен, это будет еще более и более выражено.
1:39:34
Таким образом, гол, который мы хотим достигнуть и который дает нам STM,
1:39:40
это возможность делать любой блок-кода атомарным,
1:39:44
просто обернув его в кейворд Atomical и исполнив.
1:39:51
Дошли ли мы все к консенсусу по этому поводу? Или
1:39:54
у кого-то есть еще какие-то возражения или вопросы?
1:39:59
Вопросов вроде нет.
1:40:00
Окей, да, короче, я немного извиняюсь, что я действительно перепутал примеры.
1:40:06
Думал, что тут будет пример с дедлоком.
1:40:08
Оказывается, что это пример куда более мотивирующий на использование STM.
1:40:13
Потому что от дедлока мы избавились путем рефакторинга.
1:40:16
Все, супер.
1:40:18
Таким образом, имея наши действия обернутые в монаду STM,
1:40:27
мы лишаем нашу программу потенциальной уязвимости того, что
1:40:31
между дебетом и кредитом протиснится еще какой-нибудь трансфер.
1:40:36
Потому что если же он успел протиснуться, наша транзакция просто rollback.
1:40:40
То есть все исполняется в данном случае атомарно.
1:40:44
Какие есть у нас примитивы для работы с STM?
1:40:48
Во-первых, это сама непосредственно дата-тайп
1:40:51
STM, которая является инстанцем монаду.
1:40:54
То есть код в STM мы можем писать с использованием doNotatz, как мы здесь уже видим.
1:40:59
Есть переменная Transactional Variable, TWAR.
1:41:02
То есть это переменная, которую мы используем в нашей STM-транзакции.
1:41:06
У нас есть функция newTowar, которая возвращает
1:41:08
нам товар, обернутый в STM, readTowar и writeTowar.
1:41:11
В отличие от mvar, не путать, данные у нас в STM отсутствуют в блокировке.
1:41:18
То есть STM – это код без блокировок.
1:41:21
У нас тут нет никаких mutex, нет никаких разведаний.
1:41:25
TWAR, в отличие от mvar, не может быть либо пустым, либо полным.
1:41:27
Это просто мутабельная переменная, в которой лежит какое-то значение.
1:41:30
Ровно так же, как было с EORIOF.
1:41:34
Если мы хотим писать какой-то более умный код в STM
1:41:37
и самим понимать, что у нас прошло что-то не так,
1:41:40
то есть помимо непосредственно модификации данных, модификации shared данных,
1:41:46
которые сама STM умеет распознавать самостоятельно и rollback транзакцию.
1:41:51
Если уже у нас какие-то более сложные условия, допустим, семантические,
1:41:55
когда мы понимаем, что состояние нашей программы неконсистентное,
1:41:59
мы можем заретравиться самостоятельно.
1:42:01
Именно в силу того, что мы можем заретравиться самостоятельно,
1:42:04
в STM также можно заблокироваться и выстрелить себе в ногу.
1:42:07
Вы помните изначально, когда мы разбирали exception,
1:42:09
который умеет кидать runtime в систему Haskell,
1:42:12
там же был exception blocked indefinitely on STM.
1:42:15
Вот как раз и в случае неаккуратного использования функции retry
1:42:18
можно выстрелить себе в ногу и получить бесконечную STM транзакцию.
1:42:24
Поэтому ее нужно использовать с умом.
1:42:25
Но на практике очень редко хочется использовать функцию retry.
1:42:28
Просто берем, заворачиваем наш соклодатблок Atomically,
1:42:33
или же исполняем все это в Monodext, и мы потом вызываем Atomically,
1:42:35
для того, чтобы преобразовать это в OOP, и чувствуем себя счастливым.
1:42:41
Также у нас есть функция Orals, которая принимает две транзакции.
1:42:45
Если первая из них абортится, фейлится, то исполняет вторую.
1:42:49
Также может быть полезно при написании каких-то комплексных сценариев.
1:42:53
Допустим, если мы хотим взять данные из двух разных источников,
1:42:59
первый у нас запейлился, по какой-либо причине берем из второго.
1:43:03
Также есть функции throwStm и catchStm,
1:43:06
которые просто специализированные версии функций throw, yaw и catch для Monodext.
1:43:13
То есть никакой смысловой нагрузки новой там не прибавляется.
1:43:17
Это не является еще одним фундаментально новым способом lowly exception.
1:43:21
Это просто вещи, которые удобно использовать в Monodext.
1:43:28
Есть ли какие-то вопросы по остальным?
1:43:33
Да, мне кажется странным, что она перезапускает транзакцию при изменении данных.
1:43:39
Кажется, здесь очень легко задеволочиться, даже на нашем примере с банком.
1:43:45
Давайте подумаем, как это сделать.
1:43:48
Две транзакции, одна с аккаунта A на B, вторая с B на A, одновременно запустить.
1:43:55
Первая списала деньги с аккаунта A, начинает зачислять на B, приходит вторая,
1:44:02
меняет на аккаунте B, это видит первая, перезапускается.
1:44:06
Вторая снимает деньги с B, начинает записывать на A, приходит первая,
1:44:12
видит, что ашку изменили, перезапускается.
1:44:14
Я понял, о чем вы говорите.
1:44:21
Перезапуск транзакций – это не такая тривиальная вещь, как мы с вами сейчас думаем.
1:44:27
Очевидно, шедулер потоков, так же как и шедулер, он называется VSTM,
1:44:38
это называется Transaction Manager, это механизм,
1:44:40
который ответственный за перезапуск транзакции.
1:44:42
Он достаточно интеллектуален для того, чтобы такие кейсы не допускать.
1:44:48
Он умеет давать какой-то транзакции и подождать.
1:44:51
В данном случае, согласитесь, эта проблема решается в
1:44:53
том, чтобы дать какой-то транзакции и немного подождать,
1:44:56
если же идет вот такая вот зацикленная конкуренция за данную.
1:45:02
А разве VSTM мы не навешиваем прям всю блокировку на всю операцию трансфера,
1:45:07
так что у нас не залезет транзакция друг на друга?
1:45:11
В VSTM у нас нет блокировок. В STM отсутствуют блокировки.
1:45:18
Это вещь, которая реализована на других примитивах.
1:45:22
Одна из реализаций STM, она реализована в MPP.
1:45:28
У вас, наверное, уже была такая тема, такая операция, как compare-and-set.
1:45:32
Это можно сделать без блокировок с помощью цикловайл с compare-and-set.
1:45:42
Если что-то у нас не сошлось, мы просто LBK транзакцию.
1:45:46
Тут нет блокировок от слова совсем.
1:45:51
Разве мы не давляем состояние, когда у нас произошел STM,
1:46:00
то есть мы вышли из STM, тогда мы говорим,
1:46:03
что новые потоки не успели запускаться заново.
1:46:08
Что сейчас? Смотрите, мы вышли из STM. Я просто не понял ваш вопрос.
1:46:13
Да, мы вышли из STM. Другие потоки, допустим, там, в этом STM еще находятся.
1:46:20
Мы им говорим о том, что давайте вывести все заново,
1:46:23
потому что какой-то там вышел, состояние обновилось, давайте заново.
1:46:29
Совершенно так происходит.
1:46:31
Да, это так происходит. Только мы явно никому не говорим.
1:46:34
За это механизм STM умеет это разруливать самостоятельно.
1:46:39
Смотрите, если у нас есть две транзакции, которые конкурируют за данные,
1:46:43
одна из них видит, что данные были изменены каким-либо образом.
1:46:49
Я сам, честно признаться, далеко не знаю, как в деталях реализована STM.
1:46:54
Очевидно, там условия не такие тривиальные, как просто данные изменены.
1:46:57
Там выстраиваются зависимости между данными, используются более сложные механизмы.
1:47:02
Давайте просто разбирать на примере.
1:47:04
Две транзакции. Обе из них оперируют какими-то shared данными.
1:47:09
Одна из них успеет изменять эти данные.
1:47:12
Вторая из них видит, ага, они уже изменены. Давайте-ка я rollback.
1:47:15
Таким любым образом у нас присутствует
1:47:18
постоянный прогресс в нашей параллельной системе.
1:47:21
То, что у нас не бывает такое, что обе наши транзакции рождают rollback друг друга.
1:47:28
Одна из них всегда идет дальше, а вторая перезапускается уже на обновленных данных.
1:47:32
И вторая может перезапуститься 2-3 раза, если у нас много транзакций.
1:47:37
Но у нас имеется постоянный прогресс. Отсутствует голодание.
1:47:42
По-моему, это называется, если я не забыл
1:47:43
терминологию параллельного программирования.
1:47:48
Короче, все менеджируется самостоятельно.
1:47:50
Нам, как программисту, достаточно написать doblock в
1:47:53
Monado STM и запустить это с помощью функции Atomic.
1:48:03
Есть ли еще какие-то вопросы по STM? Вроде нет.
1:48:08
Супер.
1:48:10
Да, еще немного отвлечения в сторону.
1:48:17
Нельзя не пропиарить, что Haskell является одним из достаточно немногих языков,
1:48:22
где STM реализована из коробки и присутствует,
1:48:25
можно сказать, в стандартной библиотеке.
1:48:29
Да, у нас пакет STM, это не стандартная библиотека,
1:48:32
но он входит в список библиотек, которые поставляются вместе с компилятором грешки.
1:48:37
Они называются boot libraries.
1:48:39
Haskell называется почти стандартной библиотекой.
1:48:42
Ровно так же, как пакет текст.
1:48:43
Его нет в стандартной библиотеке, но он поставляется вместе с грешкой.
1:48:47
И STM, если мне не изменяет память, есть в Haskell,
1:48:51
есть в Rust, есть в Clojure, есть в OCaml и в Scala.
1:48:56
По-моему, также есть какая-то экспериментальная реализация в плюсах на Monado.
1:49:01
Но я не уверен, что она production-ready от слова совсем.
1:49:05
Короче, так уж вышло, и в курсе параллельного
1:49:08
программирования вы также этого коснетесь.
1:49:10
То есть реализация STM очень хорошо разложится на функциональную парадигму.
1:49:16
И поэтому большинство из языков, где присутствует
1:49:18
STM, это именно функциональные языки.
1:49:20
Потому что там довольно просто реализовать вот
1:49:23
такую бы нетривиальную конструкцию, как STM.
1:49:28
Вот такие дела. И последний на сегодня пример с STM.
1:49:31
Про то, как использовать функции retry и or else.
1:49:35
Давайте заведем довольно тупой трансфер, который принимает amount from to.
1:49:40
И смотрит, что если у нас достаточно денег, чтобы снять с
1:49:44
этого аккаунта, мы делаем debit-credit, иначе мы делаем retry.
1:49:50
Данный пример абсолютно не имеет никакого практического смысла.
1:49:53
Потому что писать банк, который retry транзакцию,
1:49:58
если там нет достаточно денег, это очень наивно.
1:50:03
Данный пример нужен просто, чтобы продемонстрировать пример функции retry.
1:50:06
То есть в данном случае наша данная транзакция будет бесконечно выполняться,
1:50:12
пока кто-то другой не положит нам деньги на наш банковский счет.
1:50:17
Очевидно, что это плохой пример реализации бизнес-логики,
1:50:19
но это неплохой пример реализации функции retry.
1:50:23
Потому что обычно функцию retry нам не хочется очень часто использовать,
1:50:27
поэтому хотелось какой-то репрезентативный, но не самый умный пример.
1:50:31
Вот, собственно, есть.
1:50:33
И также, если мы хотим каким-либо образом комбинировать наши
1:50:37
тайм-транзакции, представьте, что у нас есть два товара,
1:50:42
и хотим попытаться взять либо один из них, либо второй.
1:50:51
А, господи, это у нас на самом деле не товар.
1:50:54
Товар – это такая вещь, как TMVAR.
1:50:56
Это товар еще и с mutex, который можно использовать
1:51:01
в Monado STM, и на который также можно лочиться.
1:51:08
Что мы тут делаем? Мы тут пытаемся взять первый MVAR.
1:51:12
Если транзакция у нас зафрейлилась, мы пытаемся брать второй MVAR.
1:51:16
И оборачиваем это дело либо в constructor.left, либо в constructor.right.
1:51:19
Честно вам скажу, видел в жизни достаточно
1:51:21
много concurrent кода, ни разу не видел TMVAR.
1:51:25
Это что-то из области очень и очень странного.
1:51:29
Ни разу в жизни не приходилось использовать этот примитив.
1:51:31
В основном хочется использовать либо MVAR для mutex, либо товар для STM.
1:51:36
Но такой зверек, как TMVAR, тоже существует.
1:51:39
Также есть пакет, который называется STM Containers,
1:51:42
в который включены реализацию concurrent
1:51:45
структур данных MapAsset с использованием STM.
1:51:49
Можно с ним ознакомиться.
1:51:52
В конечном итоге давайте подведем итоги того,
1:51:57
что нам дают фичи Haskell при написании concurrent программ.
1:52:05
Easier to debug.
1:52:07
Довольно спорное утверждение, потому что в Haskell нет дебегеров.
1:52:12
Но действительно отсутствие мутабельности во всех аспектах,
1:52:18
то есть имение какой-то лимитированной мутабельности только в URF или MVAR,
1:52:23
действительно делает код проще для анализа.
1:52:28
Но в чем точно мутабельность помогает очень сильно, так это в написании TRC в коду.
1:52:34
Представьте, что у нас есть какой-то MVAR, в котором лежит какая-то мапа.
1:52:38
Довольно большая структура данных, которая завернута в mutex.
1:52:45
Почему в силу того, что данная мапа мутабельна,
1:52:48
нам может быть легче писать TRC в код?
1:52:51
Потому что в Haskell мы можем взять нашу
1:52:54
мапу из MVAR и сразу же отпустить блокировку.
1:52:57
И при этом, зная, что эта мапа мутабельна, мы знаем,
1:53:00
что никто из другого потока не изменит эту мапу.
1:53:03
В другом языке программирования наивная реализация
1:53:06
будет держать блокировку на всю эту мапу,
1:53:09
или хотя бы на один из ее ключей, если мы работаем с этим ключом,
1:53:13
до тех пор, пока мы полностью не осуществим нашу операцию.
1:53:16
Потому что в любой момент до нашей мапы могут достучаться и изменить ее.
1:53:21
В Haskell мы просто на секундочку берем блокировку,
1:53:24
достаем нашу мапу и работаем с ней дальше.
1:53:26
Потому что наша мапа мутабельна, мы можем взять блокировку всего на чуть-чуть
1:53:31
и знать, что никто нашу мапу не изменит.
1:53:35
Это такой достаточно мотивирующий пример.
1:53:38
Ну и классическая байка про то, что в Haskell
1:53:40
тяжело выстрелить себе в ногу и так далее.
1:53:42
На самом деле мы увидели, что довольно легко.
1:53:45
Но утверждается, что в других языках не сложнее.
1:53:51
Также у нас, если грамотно все использовать, у нас ни датарейсов, ни блокировок,
1:53:57
если у нас используется Monado ST.
1:54:00
Короче, если сильно не хайпить Haskell и по-реалистичному смотреть,
1:54:08
я бы сказал, что киллер-фичей для конкуренции Haskell является то,
1:54:11
что его потоки достаточно легковесные и то, что присутствует такая вещь, как STM,
1:54:16
которая действительно позволяет нам очень легко писать многоточный код.
1:54:20
Вот это действительно является киллер-фичей Haskell в контексте конкуренции.
1:54:24
Байки про мутабельность, это конечно хорошо, они действительно помогают,
1:54:27
но во всех остальных языках программирования уже
1:54:30
завезли нормальную работу с мутабельными данными.
1:54:33
Этим никого не удивить.
1:54:35
А вот STM из коробки, я думаю, можно много кого удивить.
1:54:43
На этом мы с вами заканчиваем такой раздел нашей лекции, как конкуренции,
1:54:49
который про EOS-ные многопоточные программы и
1:54:53
взаимодействие между ними, синхронизацию и так далее.
1:54:57
Сейчас будем говорить про параллелизм.
1:54:59
И поговорим мы с вами достаточно быстро.
1:55:01
Есть ли у вас какие-то вопросы про раздел по конкуренции?
1:55:10
Ок.
1:55:11
Давайте тогда по-быстренькому пробежимся, как же мы
1:55:14
можем исполнять наш Haskell-чистый код параллельно.
1:55:17
И посмотрим, как это дело профайлить по-быстренькому и закончим лекцию.
1:55:25
Напоминаю, что параллельность в терминах Haskell
1:55:28
– это когда у нас есть какое-то чистое действие,
1:55:32
и мы хотим выполнить его параллельно.
1:55:34
Распараллелить на несколько потоков.
1:55:36
Для этого дела существует, вы не поверите,
1:55:39
но отдельная монада, которая называется Eval.
1:55:43
Это монада для исполнения параллельных вычислений.
1:55:47
Давайте разберем, какие у нее есть функции.
1:55:49
Есть функция runEval, которая принимает значение в монаде A,
1:55:57
значение комплексное, которое мы хотим посчитать параллельно.
1:56:00
И с помощью функции runEval доставать оттуда, запускать
1:56:04
параллельное вычисление и на выходе получать результат.
1:56:08
И есть две функции, основные, с которыми мы будем работать.
1:56:11
Это rpar и rsec.
1:56:14
Функция rpar применяется в монаде Eval, принимает какое-то значение и говорит,
1:56:19
вычисли мне его, пожалуйста, до слабой головной нормальной формы параллельно.
1:56:23
То есть создай отдельный спарк в своем трекпуле,
1:56:28
для того чтобы вычислить вот это значение до
1:56:31
слабой головной нормальной формы параллельно.
1:56:36
В спарке, если вы помните, в самом начале лекции у нас была такая диаграммка,
1:56:40
и у нас там были ядра, оэстроды, хаскельные троды и спарки.
1:56:46
Спарки — это куда более мелкие единицы, которые используются как задачки,
1:56:51
вида вычисления что-то параллельно.
1:56:53
Есть функция rpar, которая просто берет значение
1:56:56
и говорит, посчитай мне его параллельно.
1:56:58
Есть функция rsec, которая берет значение и говорит,
1:57:01
посчитай мне его последовательно, в этом же потоке,
1:57:05
и дождись его вычисления до слабой головной нормальной формы.
1:57:11
Как мы уже говорили, спарк — это просто какая-то работа,
1:57:14
которая может быть сделана, и хинт компилятору,
1:57:18
что ты можешь сделать это параллельно.
1:57:21
Вот, разберем, как это все дело у нас работает.
1:57:24
Представьте, что у нас есть функция f, и мы хотим вычислить fx и fy параллельно.
1:57:30
Что мы делаем? Мы находимся в monad.
1:57:33
yval, и говорим, пожалуйста, вычисли f от x,
1:57:37
и присвоим это дело переменной a параллельно.
1:57:40
Затем сразу же вычисли f от y,
1:57:42
и присвоим это дело переменной b параллельно.
1:57:45
И затем верни пока еще недосчитанные thunks a и b.
1:57:49
Если рассматривать все это дело как таймлайн,
1:57:51
и представить, что f от x вычисляется дольше, чем f от y,
1:57:55
то return будет вызван ровно в то же время,
1:57:59
когда у нас были запущены параллельные вычисления.
1:58:02
То есть на момент нашего с вами return,
1:58:06
вот эти thunks, пока еще не вычисленные выражения f от x,
1:58:09
чистые выражения, они все еще будут читаться.
1:58:12
Если же нам где-то, допустим, понадобится вывести их на консоль,
1:58:16
или с чем-то сравнить, то в данном моменте мы
1:58:19
остановимся и подождем, пока наш thunk довычислится.
1:58:21
Но в данном случае мы свободно можем продолжать дальше и подождать где-нибудь потом.
1:58:25
То есть мы можем вернуть эти thunks из нашей функции,
1:58:30
и они когда-то потом посчитаются.
1:58:33
И потом уже, может быть, на момент использования они уже будут досчитаны.
1:58:37
В этом прикол функции rpath.
1:58:38
То, что мы берем и просто говорим,
1:58:40
вычисли мне, пожалуйста, параллельно, и идем дальше.
1:58:42
И так же говорим, вычисли мне параллельно, и идем дальше.
1:58:45
И так как это у нас чистые значения,
1:58:48
у нас нет никаких future, нет никаких iot и прочих других обертков,
1:58:52
это просто какое-то ленивое значение, которое пошло вычисляться.
1:58:56
Вычислилось оно еще или нет, фиг знает.
1:58:58
Но если оно нам нужно, и оно не вычислилось, мы подождем.
1:59:02
Вот такие периоды.
1:59:04
Разберем, как работает RSEC.
1:59:06
Мы говорим, давай f от x вычисляй параллельно,
1:59:10
и отправили вычисляться.
1:59:11
А f от y мы хотим вычислить последовательно.
1:59:14
То есть мы хотим, чтобы на момент ретерна b уже было вычислено,
1:59:18
а a еще нет, потому что мы предполагаем, что a считается дольше.
1:59:23
Получается, ретерн будет вызван сразу после того, когда считается b.
1:59:27
И на этом, собственно, интерфейс Monado Eval заканчивается.
1:59:30
Основной интерфейс Monado Eval заканчивается.
1:59:32
Там, понятно, есть более сложные примитивы, как и с Concartly Erase,
1:59:37
для работы с всякими списками, для работы с произвольными траверсаблами,
1:59:41
фолдаблами и так далее.
1:59:42
Но все это дело можно смоделировать, представить через mpar и RSEC.
1:59:49
Если же мы хотим...
1:59:52
Смотрите, последний пример мотивирующий.
1:59:54
Мы отправляем a вычисляться в отдельный поток,
1:59:58
затем в том же потоке вычисляем b,
2:00:03
а потом все-таки хотим дождаться a.
2:00:05
Тогда ретерн будет выполнен уже после того,
2:00:07
когда у нас обе a и b будут вычислены.
2:00:10
Короче, мы с помощью mpar и RSEC можем манипулировать
2:00:13
параллельными вычислениями как нам угодно.
2:00:16
То есть мы в нужный момент можем подождать с помощью RSEC,
2:00:19
в нужный момент можем что-то отправить читаться с помощью mpar.
2:00:23
Все. То есть на этом API monad и val заканчиваются.
2:00:26
И потом с помощью run и val мы это дело достаем и получаем чистое значение.
2:00:35
Мне показалось, что там кто-то четко что-то писал.
2:00:38
Есть ли какие-то вопросы? Да, конечно.
2:00:40

2:00:41
Почему это сделано монадой отдельной и другим типом?
2:00:45
Ведь если у нас чистые функции,
2:00:47
компилятор мог бы сам неявно это все запускать параллельно и вычислять.
2:00:52
Зачем нам что-то делать?
2:00:53
Об этом мы сейчас будем говорить.
2:00:57
Потому что это делать невыгодно.
2:01:00
Хочется, чтобы программист явно указывал,
2:01:05
что мы хотим параллелить.
2:01:06
Потому что это логичное предположение.
2:01:08
У нас все чистое.
2:01:09
Почему бы не параллелить все?
2:01:11
Но на самом деле, если делать это без ведома
2:01:15
программиста и параллелить каждую операцию,
2:01:18
ну или до какого-то осмысленного момента, то может быть две проблемы.
2:01:22
Первая.
2:01:23
То, что мы наплодим с лица, это слишком много спарков.
2:01:26
Несмотря на то, что их, в принципе, можно
2:01:28
плодить очень много, мы можем с этим переборщить.
2:01:30
Во-вторых, порой оверхед на создание спарка, несмотря на то, что он очень маленький,
2:01:35
может быть больше, чем оверхед на выполнение операции.
2:01:39
Поэтому параллелить все и всегда – это невыгодно.
2:01:42
А делать какой-то conditional параллелизм – а зачем?
2:01:46
Если можно предоставить программисту удобный API?
2:01:48
Потому что, на мой взгляд,
2:01:50
Monado и VAL – это очень простая и очень удобная вещь.
2:01:53
Просто берешь RUN и VAL,
2:01:55
просто говоришь, что вычислить параллельно, что вычислить последовательно.
2:01:58
И никаких датарейсов, вообще ничего,
2:02:00
у тебя все иммутабельное, все чистое,
2:02:02
ты живешь в себе прикрывающий.
2:02:05
Лучше уж сделать вот так, чем параллелить все.
2:02:09
А уж тем более, чем грабить какие-то костыли в компиляторе,
2:02:12
чтобы он пытался догадываться, что лучше параллелить, а что нет.
2:02:16
Но это мы уже забегая вперед сказали.
2:02:19
Ну, тут у нас пример, как вычислять Fibonacci от 39 и от 38 параллельно.
2:02:27
И если же мы вдруг хотим посмотреть,
2:02:33
сколько у нас ядер процессора было задействовано,
2:02:35
сколько у нас отработал garbage collector,
2:02:38
и на другую интересную инфографику,
2:02:40
мы можем передать туда флажок event log
2:02:45
и какие-то другие флажки,
2:02:47
о которых, я думаю, нет смысла останавливаться, если что, прочитать.
2:02:51
И запустить утилиту Threadscope на файле .
2:02:55
eventlog, который был с предыдущим запуском ваших программ.
2:02:59
И увидеть, что в данном случае,
2:03:02
если вы запускаете с плюс RTS, но без минус n2,
2:03:09
то есть на один поток, вы будете видеть, что у вас всего одно ядро задействовано.
2:03:19
Это применение Monado и Val, но все еще с одним потоком.
2:03:23
А вот если же мы скомпилировали с минус n2,
2:03:25
мы увидим, что вот оно первое ядро,
2:03:27
вот оно второе ядро,
2:03:29
оба ядра были загружены.
2:03:31
Тут мы можем посмотреть какую-то интересную аналитику
2:03:33
по количеству спарков, которая была создана,
2:03:36
и много всякого интересного, которое, вполне возможно, нам никогда не пригодится.
2:03:40
Но если уж очень хочется,
2:03:42
если уж мы заботимся,
2:03:44
если нам нужно найти какой-то bottleneck в
2:03:47
performance нашей программы, оно может быть полезно.
2:03:50
Вот этот вопрос, который вы задавали.
2:03:54
Давайте просто попробуем параллелизовать все.
2:03:57
Проблема в том, что компилятор недостаточно умный
2:04:01
для того, чтобы понять, что параллелить стоит, а что нет.
2:04:03
Это, в принципе, не является ответственностью компилятора.
2:04:06
Можно очень тупо начать параллелить.
2:04:09
Вот, допустим, представьте наивную реализацию чисел Фибоначчи,
2:04:11
которая, как известно, работает за экспоненту.
2:04:13
И попытаемся каждый из веток нашей рекурсии параллелить.
2:04:16
То есть мы будем плодить экспоненциальное количество потоков.
2:04:21
Попробуем все это дело скомпилировать,
2:04:23
и будем видеть то, что ядра использованы довольно неоптимально,
2:04:27
потому что если в этом случае мы видим,
2:04:31
что все довольно плотно,
2:04:35
то каждый из ядер все время делал какую-то полезную
2:04:40
работу, потому что была сплошная зеленая полоска.
2:04:44
Здесь же мы видим, что желтый – это garbage collect,
2:04:47
то что было очень много лишних вызовов,
2:04:51
очень много каких-то лишних данных, которые сразу в garbage collect.
2:04:54
И поэтому очень часто были прерывания между нашими физическими ядрами,
2:04:58
которых четыре, а на спавне лимы потоков, простите,
2:05:02
экспоненциальное количество.
2:05:04
Это мотивирующий пример, почему параллелить каждый из действий,
2:05:09
несмотря на то, что все чистое и, казалось бы, нам это дозволено, плохо.
2:05:13
Поэтому вместо того, чтобы параллелить все,
2:05:16
в Haskell сделали удобный механизм для параллельных вычислений,
2:05:20
чтобы разработчик сам об этом задумался.
2:05:23
Если же вас заинтересовало параллельное программирование в Haskell,
2:05:27
можете ознакомиться с следующими вещами.
2:05:29
Библиотека Repo для вычислений на GPU
2:05:35
и операций над многомерными массивами, тензорами и всем остальным.
2:05:41
И также пакет DPH для вычислений численных методов на Haskell.
2:05:47
Мы также не коснулись такой вещи, как каналы в Haskell,
2:05:51
Chan и Tchan, аналогичные тому, что бывает, например, в Golang.
2:05:56
Также мы не коснулись другой монады для
2:05:59
параллельных вычислений, которая называется Plan.
2:06:00
Она более интересная, но и, как следствие, менее простая, чем монада Eval.
2:06:07
Можно ознакомиться с ней самостоятельно.
2:06:09
Можно ознакомиться с распределенным программированием на Haskell,
2:06:13
с использованием платформы Cloud Haskell,
2:06:15
которая, к сожалению, уже давным-давно умерла,
2:06:19
но мало ли кому-нибудь интересно.
2:06:23
Кому интересно, там будет ссылочка в конце про то, как работает Scheduler в VRC.
2:06:28
И также можно тюнить и дебагить программу.
2:06:31
Вот тут куча ссылочек на все это дело.
2:06:34
Если вам интересно, можете ознакомиться.
2:06:36
На этом мы заканчиваем лекцию.
2:06:39
Кажется, мы даже более-менее уложились в тайминге.
2:06:42
Есть ли у кого какие-то вопросы?
2:06:45
Зачем проверять вектора, если они и так в процессорах проверены?
2:06:54
Вы сразу о каких векторах речь? Математические.
2:06:57

2:06:58
Или тут не математические вектора?
2:07:00
Нет, тут имеется в виду многомерный вектор.
2:07:03
Допустим, если вы ML на Haskell хотите посчитать,
2:07:05
а почему вы решили, что они и так параллельно вычисляются?
2:07:08
Из-за инструкции, из-за векторов инструкции на СПУ?
2:07:13
Да.
2:07:15
Как раз-таки это библиотека.
2:07:18
Если вы представите ваш математический вектор Haskell-ным списком,
2:07:25
он не будет считаться параллельно либо на ГПУ,
2:07:28
либо с использованием векторов инструкции.
2:07:30
То есть это обертка над этим?
2:07:32
Да, это просто обертка над вызовами вот этих системных штук.
2:07:39
Haskell-ные списки плохо годятся под это дело.
2:07:41
Это просто специализированная версия.
2:07:43
Всё окей.
2:07:50
Окей, если вопросов нет, видимо, тогда заканчиваем.
2:07:53
Всем спасибо. Пока.
2:07:57
Спасибо, до свидания.
2:07:58
До свидания.
