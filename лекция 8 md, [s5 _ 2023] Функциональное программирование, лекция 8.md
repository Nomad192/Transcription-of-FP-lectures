# Text

Отлично, так. Ну что ж, всех приветствую на восьмой лекции по функциональному программированию. Сегодня мы поговорим про performance и про строгость в Haskell. План будет следующий. Мы поговорим про...

Начнем с difference-листа, того, какую он разрешает проблемку. На самом деле, он разрешает довольно маленькую проблему, такую незначительную, я бы сказал. Тем не менее, разрешает. Дальше мы поговорим про строгость. Потом про механизм предотвращения накапливания преимущественных представлений в памяти, функцию deforestation.

Поговорим про объект, который предотвращает накапливание этих представлений в памяти, это называется streamfusion. И немножко поговорим про бутабельные объекты. Начнем с difference-листа. Итак, вот есть функция Trinity. Она принимает три списка.

И, судя по тому, что написано здесь, конкретизирует их каким-то соответствующим способом. Их вообще способов здесь три строчки. Но на самом деле, конечно же, способов конкретизации два списка, их только две штуки. Вопрос номер один. Помним ли мы, какая ассоциативность у конкретизации списков? Совершенно верно, да.

Конкретизация списков у нас… извиняюсь, сейчас… Правая статья. Я просто хочу еще начать смотреть, на всякий случай, если у вас вопросы есть и так далее. Но сейчас не получается. Ассоциативность правая. По определенной причине.

Поэтому фактически ведет первая строчка в определении Trinity. Это эквивалент, на самом деле, второй. Просто такой способ не ставить скобочки, чтобы они автоматически бандились к rightmost конкретизации. Поскольку у нас, опять же, правая ассоциативность. Вопрос следующий.

А какое определение из среди этих трех, тем не менее, лучше не использовать? И почему, на ваш взгляд? Есть идеи? Последнее. Потому что мы хотим к более короткому списку прибавлять. Потому что нам нужно у последнего обновить ссылку на следующую ноду, последнего узла. Да. Я совершенно согласен с вами.

Последнее лучше не использовать по причине определения конкретизации списков, и по тому, что мы именно перемачиваем, как мы именно перемешиваем наши конструкторы, конс и так далее. Вопрос. Смысл? Да. Дефолт. Нет.

Выбирать корректное определение ассоциативности на простом. Ассоциативность правая и рейдер пятый. Потому что, вспомним определение ассоциативности. У нас конкординация ленивая по второму аргументу. То есть второй аргумент может быть, на самом деле, бесконечным.

Но первое должно быть бесконечным, чтобы можно было взять, например, n элементов из конкординации. По первому аргументу перемешиваем просто конус. Вот и все. Если мы проанализируем эти два отрывка, мы увидим, что, в принципе, на самом деле, поскольку ассоциативность ленивая, вот эта строчка, конечно, тут не будет вычислена, вот эта скобочка первая, это вычислится сначала конкординация с левым списком из n элементов, поэтому сначала будет n операций. Ну, не n, на самом деле, а, я бы сказал, n плюс 1, потому что, на самом деле, список n элементов – это n элементов плюс пустой список.

Поэтому, на самом деле, n плюс 1 операция – не важно. Плюс константы. То есть сначала будет n операций. И когда мы конкординируем левый список, по определению ровно конкординации, а потом уже мы конкординируем результат с непосредственно списком 1 и так далее, n плюс 1 и так далее, k. И вот здесь, конечно, будет уже n операций.

В итоге будет ровно n плюс 1 операция. Именно если у нас имеет место правая ассоциативность. Посмотрим тогда на левую ассоциативность и посмотрим на то, что изменится. Значит, опять же, у нас плюс-плюс строгий, де-факто, по первому аргументу. Поэтому вычислится сначала левая часть.

Безусловно, то, что я выделил, будет n операций. Это и так понятно. А вот потом, когда мы конкординируем наш жадивающий список со списком 1 и так далее, будет у нас теперь n плюс m операций. Потому что мы, опять же, потормачиваемся по результату, то есть левому списку, а этот список из n плюс m элементов. Поэтому у нас будет n плюс m плюс 1, на самом деле, операции, и того у нас будет 2 n плюс m операций в общем случае.

И, ну, как бы, вроде это все равно от n плюс m. Ну, просто мы делаем личный траверсал нашего списка. Личный траверсал, личный проходок. Личный траверсал делать, как бы, если его не сбежать, то это хорошо. Лишних траверсалов не делать.

По этой ссылочке можно перейти и посмотреть, как работают постановки всяких определений, которые вы вводите в Haskell. Только в отличие от Haskell, здесь вот по этой ссылочке, по этой интерактивной игрушке, можно будет выбрать, какие под выражения вы учисляете. То есть вы кликаете на пузырики, и там эти пузырики, и вот это вот выражение, которое можно редуцировать. У вас есть там выбор. Вы можете задать свое определение и посмотреть на то, как все редуцируется.

Если вы предпочитаете… Да, собственно, если вы предпочитаете проверить ленивость, то вы должны всегда попытаться попасть в самые левые пузырики в этой интерактивной среде. Есть такая вещь, можно какие-то попробовать, когда у вас будет время. Very fun. Вот. Итак, избегать проблемы выбора ассоциативности.

Как сделать так, чтобы у нас не было, скажем, явного выбора ассоциативности, и так, чтобы не сделать ошибку, если у человека ошибки случаются? Ошибки случаются, это бывает. Решение на следующее. Создадим такой тип данных, который называется The List. Сочиняется как Difference List. Он энкапсулирует в себе функцию из списка А в список А.

Логично было бы в рамках использования The List не экспортировать, это я уже в мысли вслух, не экспортировать конструктор DL данных, естественно, потому что основная вещь здесь будет происходить именно в этих двух функциях, From List и To List. А From List принимает или возвращает, собственно, DL от какой-то функции, и эта функция, внимание, это в точности компетенция слева. Вспоминаем, базовая синтексис Хаскелла, это называется, господи, какая это секция? Правая секция. Здесь лямбда, скажем, L', стрелка L++ L'. То есть мы добавляем L к аргументу нашей лямбды, причем L слева.

Вот это является ключевым моментом в определении From List, что мы L добавляем слева. Сейчас мы видим, что это поплечет. А как перевести тогда The List в To List, то мы просто применяем нашу функцию в кустом списке. Внимание, To List от From List, вот L, это по определению L++ кустой список. И это у нас, опять же, координация, она является моноидом, и у нас кустой список – это центральный элемент.

Поэтому L++ кустой список – это L. Поэтому To List от From List L – это L, что хорошо. Итак, смотрим теперь. Насчет обмена. У нас есть координация, и теперь мы можем произвести семигруппную операцию склеивания двух тл.

Я не помню, освещалось ли это на лекции по моноидам, которую я вел, я даже не помню свою лекцию, печально. Но там действительно есть такой теган, который называется endo, который капсулирует в себе эндоморфизм, то есть функцию из ова. Здесь то же самое, у нас операция, фактический эндоморфизм, списка в список. Операция append, которая типа добавляет два списка вместе, хотя там функция, на самом деле, казалось бы, какие списки она добавляет, у нас функции. Но это просто координация, ой, композиция функций, вот и все.

И да, у нас композиция, естественно, анастатична, поэтому L образует семиполигруппу. Более того, тут M append стоит, то есть можно подумать, а что, L образует моноид? Конечно образует моноид. Нейтральный эвент у лековой композиции – это identity, морфизм, то есть это одно, которое принимает и возвращает то же самое. Поэтому L вполне себе полноценный моноид, что классно. И вот, соответственно, два случая того, как расставить скобки.

Что они публикуют оба? Какой результат? На самом деле, забегая вперед, не анализируя подробно, что тут написано, это элементарно просто будет TL от композиции трех функций. F, допустим, наш аргумент – это X. Ну и XS, окей, XS, пока здесь. И вот F в обоих случаях, что важно. F от J, от H, от XS.

Тут, конечно, не написано. Ну, как бы тут вот T – это та самая функция, на самом деле, которая J от H. Получается F от J от H от XS. По определению M-аппенга. Тут по определению нашего даймонда.

Напоминаю, я называю это даймондом и наша полугруппная операция, астротипная. Вот. Вопросы есть? Нет вопросов пока, нет, окей. У меня чат перед полицами, поэтому задавайте, если хотите. Так.

Ну, как бы, отлично. F от J от H от XS. И что за того, казалось бы? Ну, вспомним, что мы имеем право по консенсусу нашему пользоваться исключительно from-листом, чтобы лист лифтить в контекст DL. Поэтому F – это что-то наподобие… Вот какой-то список здесь, это список F-штрих, F-штрих плюс плюс. Вот D-штрих плюс плюс – это рот тот самый L-плюс плюс, который мы определили в рамках определения from-листа.

Значит, F – это F-штрих плюс плюс, J – это J-штрих плюс плюс, H – это H-штрих плюс плюс. Итого, F от J от H от XS – вот здесь это Y или S, не важно вообще, просто аргумент – превращается вот в такую серию, в общем, в обоих случаях, в такую серию координаций. И вот теперь уже прикол в том, что именно поэтому мы добавляем определение from-лист L слева. Это поплечет, как бы мы скобки не ставили, в правоостативность координации, что, естественно, избавит нас от лишних траверсовов, потому что правоостативное выполнение операции координации поплечет наименьшее количество траверсов. Сначала пройдется по всему F-штрих, потом по всем, мы сконструируем новый список, потом J-штрих, потом H-штрих, ну и потом мы просто добавим YS и все.

Итого у нас будет ровно от длина AF-штрих плюс длина J-штрих плюс длина H-штрих в обоих случаях. Как бы мы скобки не ставили здесь. В отличие от левоостативности плюс-плюс. Там будет операции, господи, длина F плюс F плюс J плюс F плюс J плюс H. То есть это прям 3F плюс 2J плюс H.

Печаль. Это хуже, чем хотелось бы. Хотелось бы просто F плюс J плюс H. Вот. В этом прикольный difference list.

Difference list решает довольно не такую капитально значимую проблему с точки зрения time complexity, но тем не менее разрешает. И, опять же, желательно иметь меньше траверсов по нашим спискам. Вопросы по difference list. Дальше у нас… А, да. Дальше у нас немножко про sequence.

Один слайд. Вопросы слушаю, если есть. Если нет, мы пойдем дальше. Так, окей. Вот тут один слайд посвящен просто reference-у типа данных, который называется sequence.

Точнее, seq, да? С большого буквы. У нас скоро будет seq с маленьким буквы. Это разные вещи принципиально. Вот. Data sequence, точнее, типа данных seq, он реализован с помощью Finger3.

Finger3 – это такая функциональная структура данных, на которой можно реализовать двусвязный список. И вот иллюстрация того, как оно получается… Вот, короче, есть видео где-то в деблях интернета, где-то в ютубе, точнее. Можно там глянуть на то, как получить Finger3 из обычного бинарного дерева. Визуально. Спойлер.

Там, в общем, берется нода, она перевешивается, она становится, короче, root-ом. Наша нода где-то внутри дерева, то есть под дерево, да? Становится root-ом, а все остальное двигается вниз. И там, внезапно, получается такая немножко нетривиальная структурка. Но, на самом деле, Finger3 – это действительно структура не такая простая с точки зрения реализации. Может быть непонятно, как вообще реализовать двусвязный список на Finger3.

Тем не менее, можно. Поэтому, если вам интересно, посмотрите на DataSequence. Но пока мы подходим к строгости в Cascade. Итак, начинаем мы с seq. Вот вот самый, который с маленькой буквы.

Не имейте никакого отношения к sequence, о котором я только что упомянул. Seq – это вообще другая вещь, другой зверь. Sequence делает следующую вещь. Вот его модель. Она… Очевидно, неопределение, внимание.

Очевидно, это неопределение, потому что мы не можем играть в каждый параметр bottom, очевидно. Да, в Cascade bottom – это что-то подобное, defined. Вообще, bottom – это, например, error. Опять же, если мы… SignatureError – это функции строки в произвольном типе. Если стомить matlock, который у нас был весной, то там, в общем… Опять же, пустой тип void можно определить как for all a.a.

Это как undefined фактически. Тогда error – это стринг, стрелка for all a.a. То есть, по эзоморфизму Кори Ховарда, то же самое, что не строка. То есть, error – это отрицание строки. Вот, на самом деле, тип error'а.

Немножко астропемиологическое, как называется, signature error'а, как она воспринимается в чеке matlock'а. Это отрицание строки, что-то типа того. Ну, undefined – это что-то подобное bottom'а. Ну, как error, в принципе. А bottom – это что-то, что либо является непродуктивной рекурсией.

В общем случае, да. Например, infinite loop – это непродуктивная рекурсия. Либо что-то, что никогда не завершается успешно. То есть, какой-нибудь exception. То есть, потом это самокупность там.

Как и именно в двух случаях. Непродуктивная рекурсия и exception, который невозможно поймать, например. Но это, конечно, слишком строго. То есть, на самом деле, это просто любой exception. Потому что, опять же, прокопирование подобное Java, C++, Kotlin, Scala – неважно.

Все exceptions имеют тип bottom'а. Не тип bottom'а, а это является bottom'ами. Но их, естественно, можно поймать. То, что я сказал, типа, которые нельзя поймать, это, конечно, страйд, я извиняюсь. То есть, любой exception, фактически.

И непродуктивная рекурсия. Значит, это bottom, называется расходящееся вычисление. Что делает sequence? Все, переходим к, собственно, sequence'у. Вот его модель. Это не определение, просто модель.

Если слева стоит bottom, возвращается bottom. Sequence вычисляет левый аргумент до его первого аргумента. Слабая, главная, нормальная форма. Я буду говорить о какой-нибудь нормальной форме, потому что слабая, главная, нормальная форма тяжело выговаривается. Weak-head normal form.

Вот как здесь написано. Вычисляет его, но возвращает он второй аргумент. Вот это все, что делает sequence. Да, и вот его сигнатура, если она принимает a, принимает b, возвращает b. Потому что возвращает она второй аргумент, вычисляя первый до weak-head normal form.

Вот и все. Предлагаю следующий микроквиз по тому, как ведет себя sequence на разных input'ах. Начинаем. Zero, sequence, . Что вернется? .

Все наверное, вернется. Да, мы вычистим 0, получим 0, отлично, до weak-head normal form, и потом вернем . Undefined sequence, . А разве 0 не в слабоголовной форме находится? Почему 0, sequence, , вернул ? Потому что мы вычислили 0, он может уже пребывать в weak-head normal form. Это зависит от того, какой тип у нас.

Например, если у нас тут тип int hash, то он уже там пребывает в weak-head normal form. Просто возвращаем , отлично. А если это какой-нибудь, скажем, сейчас ratio, напоминаю, что сейчас rational. Rational – это ratio integer, это процент integer. То вот там вместо 0 поставится from integer 0, вместо поставится from integer , вычислится from integer 0, вот он уже вычислится, from integer 0, и вернется конструктор с процентом, тот самый, типа данных ratio.

Надеюсь, вы помните, что такое ratio – это один из нумерических типов данных, который представляет из себя division числей заменателя. Причем явно, это произведение типов. Будет вычислиться, получится там внешний конструктор процент, отлично, вычислится, все в порядке, и вернется . То есть это тоже зависит от того, какой тут тип стоит. Напоминаю, что 0 и – это просто литералы нумерические, и это синтетический сахар, from integer 0, и from integer .

Это зависит от ваших типов. Допустим, здесь int, вроде простоты. Но 0 же пребывает, we have double form, отлично, просто возвращаем . Это стало понятно? Я правильно? Ты ответил на вопрос, надеюсь, или нет? Вроде да. Что делать с undefined? Если undefined стоит в первом аргументе, что случится? Ошибка, т.

к. undefined не вычислится. Я бы сказал, вычислится, потому что он… Он выкидывает ошибку. Да, конечно. Undefined – это же bottom, напоминаю.

Bottom – exception. Just undefined sequence . . Совершенно верно, . Потому что just undefined пребывает в weakhead normal form.

Что такое weakhead normal form? Давайте напомним, что это либо внешний конструктор, и только внешний конструктор. То, что находится внутри него, если оно есть, не вычисляется. Либо это лямбда-абстракция. То есть лямбда-аргумент, стрелка и дальше тело нашей лямбда-абстракции. Здесь это конструктор just.

Нам плевать, что тут undefined стоит. Отлично, пускай стоит. Он не вычислится, потому что у нас weakhead normal form – это just. Just уже есть. Отлично, все.

Вычислили это weakhead normal form, вернули . Вот все. Маленький перк, связанный с очередным отличием data и newtype. Мы знаем, что newtype – это оберточка, а data – это просто плацентимент. В компайл-тайме newtype происходит так называемое… Сейчас, я не знаю, это корректный термин – newtype erasure.

То есть стирание конструкторов newtype. Вот в компайл-тайме так происходит. Поэтому здесь, когда мы передаем конструктор nw, это можно воспринимать как undefined sequence . Если кто-то ставит newtype. Это можно воспринимать просто как то, что я выделил.

В случае newtype. Поэтому это просто выбросится undefined. В случае data, естественно, никаких таких магий на потопе erasure конструкторов не происходит, потому что data – это не особый случай. Поэтому внешний конструктор dw – это уже weakhead normal form. То есть это как just, по-корочему говоря.

Эта часть эквивалентна вот этой части. Вот эта часть, то, что сейчас выделено, эквивалентна вот этой части. То есть без конструктора nw. Из-за newtype erasure, что-то типа того. Erasure, стирание.

Это еще один перк. Я не помню, он обсуждался или нет. Это было в самом начале курса, кажется. Разница newtype и data. А, я же определил лекцию, кажется.

Я не помню ничего. Вот. Теперь поговорим про строгости в рамках сверток. Ну, мы знаем, что у нас также есть две классические свертки – левая и правая. Например, когда мы спрашиваем список, мы можем это сделать в два способа.

И фундаментально, и синтетически, и схематически – это разные вещи. Правая свертка и левая свертка. Зависит от того, как его собирать здесь. Например, здесь плюсы и нолик. Фолдер, эквивалентин, фолдл – они все вернут один и тот же результат.

Потому что плюс – это коммутативная основательная операция, и плюс образует коммутативный манойд. Все. Это достаточно. Мы знаем, что такое коммутативный манойд. Поэтому фолдер, эквивалентин, фолдл.

В данном случае. Тем не менее. Допустим, мы захотим посчитать фолдр плюс ноль. То есть мы просто суммируем все элементы. От списка из десяти миллионов элементов.

Это будет довольно медленно. Как фолдр, так и фолдл. Оба варианта. Сейчас я на следующей стадии продемонстрирую в очередной раз определение фолдра и фолдра, чтобы можно было их отличить. Если мы вдруг забыли.

А вот если мы пытаемся посчитать это на списке из 100 миллионов элементов, то, возможно, у вас все зависнет, и ваша машина немножко поломается. Поэтому рекомендую не запускать вашу программу на гигантских структурах без верхнего предела по памяти. Как так добыть? Вдруг у нас реально гигантские списки. А как их, собственно, вычислять? Есть строгая версия. Строгая версия, например, левой свертки.

Более того, строгая версия левой свертки лучше, чем строгая версия правой свертки. Более того, я не... Называется строгая версия правой свертки фолдр-штрих, очевидно, потому что фолдр и штрих – это как бы строгостика того. Она определена в классе типа foldable. Как и фолдл-штрих, собственно говоря, они все определены в foldable.

Это можно глянуть на их предутствие там. Фолдл-штрих – это строгая версия фолдла, и мы потом выясним, в чем заключается строгость, как она отражается на редукции, как мы вычисляем наши операции. миллионов элементов вычисляется довольно быстро. 100 миллионов не ломает нашу систему, что хорошо. Из-за строгости.

Более того, я бы сказал, что тут, на самом деле, можно сделать фолдл из-за определения фолдла, из-за того, как он определяется, хоть на миллиард. Такое ощущение. Да, у нас будут довольно большие числа. Зависит от вашей памяти, как минимум. Но, чисто теоретически, на миллиард чисел ваш список тоже можно сделать за фолдл-штрих идти, короче говоря.

Да, это теория. В смысле, спекуляция. Нет, я не попробовал, не хочу сам попробовать. Тем не менее, фолдл – фолдер. Фолдл – правая сторона.

Мы знаем, что такое фолдер. Это применяем функцию f к пустому списку к голове и к пустому списку к фолдеру. А если список пустой, возвращаем так называемое начальное значение z. Оно начальное. Вот.

Фолдл – это почти фолдер, только здесь, во-первых, функция немножко другая. Из b и a в b. А тут из a в b. В функции с fb в fb. Да, кейс с пустым списком такой же, но вот этот элемент теперь в фолдле называют аккумулятором, потому что мы аккумулируем значение и делаем холостовую рекурсию, как вы можете заметить.

Именно поэтому я спекулировал, а вот вдруг можно реально сделать фолдл от списка на миллиард элементов. Вдруг это удастся. Мне кажется, сейчас. Есть ли списки из них, те же элементы, типа units или там нолик, то, наверное, да. Но если там гигантские числа, наподобие, опять же, миллиарда, то, наверное, все поломается.

Неважно. Все. Не будем говорить о списках, о количестве элементов. Но такая проблема возникает вот в реализации фолду, например. У нас аккумулируются результаты пробежуточные в нашем втором аргументе, в нашем аккумуляторе.

Мы знаем, что хаскер ленивый. Нам пока нет смысла его вычислять. Поэтому я обращусь пока к второму определению с фолдлом. Вот у нас аккумулируется на первой стадии 0,1. Он не вычисляется, очевидно, потому что его нет смысла вычислять.

Мы пока его не вернули. У нас нестройки вычисления. Потом 0,1 плюс 2. Левостативно, очевидно. Вот наш старый аккумулятор, собственно говоря.

Потом плюс 3. А потом уже мы возвращаем аккумулятор. И вот теперь на этой стадии, когда мы вернули аккумулятор, мы начинаем редукцию. Мы начинаем вычислять 0,1, 1,2 и 3,3. Мы получаем 6, очевидно.

Фолдер работает более понятно. Мы не можем пока сложить единицу с тем, что стоит справа, потому что справа у нас реквизитный вызов фолдера. И так далее, и так далее. Вот тут уже возвращаем 0. Потом уже выполняем редукцию вычисления.

4 плюс 0, 2 плюс 3, 1 плюс 5. В обоих случаях тут на самом деле возникает 7 переходов. Раз, два, три, четыре, пять, шесть, семь. Ну и проблема. Явная проблема в том, что у нас и в фолдере, и в фолдле, особенно в фолдле я даже поговорю, почему именно фолдл является критически важной функцией здесь.

Аккумулируется значение, во втором аргументе, гигантское. Это thunk, он не вычислен. И если у нас здесь возникает список из, опять же, миллионов элементов, и мы делаем fold2, у нас во втором аргументе будет копиться колоссальных размеров гигантский thunk, который не вычислен до тех пор, пока мы не прогревать по всему списку из единых миллионов элементов. Вот. Как быть тогда? Передача макетинговый запрос, маленький квиз очередной, создающий задание вопроса.

Что вернет фолдер, конъюнкция false и repeat false, это бесконечный список из фалсов, и аналогично только четко левая. Что вернет каждая из этих функций, на ваш взгляд? Чет пока мертв, к сожалению. Пишите вопросы, если у вас есть, я попытаюсь ответить. Первый фолдер вернет фалс, а фолдер будет бесконечной ситуацией. Абсолютно верно.

Фолдер, конъюнкция false, repeat false, средуцируется в, вот как по определению фолдер, на списке бесконечных фалсов всегда const стоит, фалс, конъюнкция, фолдер. Вот на текущем этапе мы вычислим конъюнкцию от фалса и фолдера. Конъюнкция от фалса делает short circuit. Короткое замыкание вычислений. Это не вычисляется, возвращается фалс.

Ну, очевидно, у нас есть конъюнкция с конъюнкцией, хотя в один фалс, то еще фалс, очевидно. Так и определен фалс фразками. И не только фразками, в принципе. Вообще, если конъюнкция ленивая, и дезюнкция тоже. Не одна из всех, но хотя бы в javac, скажем, да.

Если правильно помню. Фолдер, однако, будет аккумулировать фалс, конъюнкция, фалс, причем, очевидно, он не будет вычислен, потому что у нас нету строгости к второму аргументу, спойлеры. Он будет аккумулировать, аккумулировать, он будет аккумулировать до бесконечности. И рано или поздно ваша система умрет. Ну, надеюсь, что потом она будет оживить каким-то образом.

Главное сделать control все как можно скорее. Лучше не вызывать фолдл, конъюнкция фалса, репит фалс, никогда вообще, чтобы случайно не набороться на смертельный случай. Это смертельный номер. Вот, да, верно. Это вернет фалс, это записнет.

Правильно. Итак, в чем прикол фолдла? Вот в чем прикол фолдла. Вот здесь вместо того, чтобы аккумулировать гигантский фланг, мгновенно происходит вычисление. То есть здесь раньше было 0 плюс 1, если не помню, теперь это просто 1. Ну и дальше было 0 плюс 1 в скобочках, потом плюс 2, теперь это плюс 3.

Не плюс 3, а просто 3. А логично 6. Итого у нас всего 4 перехода. 4, потому что у нас список элементов плюс пустой список. Вот, да, логично.

Все вычисляется мгновенно. И это, между прочим, хвостовая рекурсия, что, по идее, хорошо. Собственно, как можно определить фолдл-штрих? Фолдл-штрих можно определить через sequence, который вычисляет наш вот этот вот f от a и x. Вот помните, да, это наш новый аккумулятор, который мы поставляем в фолдл-штрих, когда мы вызываемся от хвоста. Давайте его в LED binding сделаем локальную связку, произведем sequence, вычислим а-штрих до weak-head-normal-form, и потом пропихнем это в фолдл, и все.

То есть а-штрих вычисляется до weak-head-normal-form. Ну, это уже что-то. Вот уже что-то этого недостаточно. Потому что у нас, как бы очевидно, в нашем списке могут быть, не в нашем списке, а в нашем, точнее, B, у нас могут быть, ой, нет, A, в данном случае это A, более сложные структуры, наподобие пары. Что делает интересная у нас пара? Ничего, страдать.

Почему страдать? Ну, потому что у нас пара. То есть там, внешний конструктор, это запятая, уже пребывает в weak-head-normal-form. Ак плюс икс, лен плюс один не вычислятся, потому что они пребывают внутри пары, внутри конструктора запятая. А sequence вычисляет до weak-head-normal-form. Какова weak-head-normal-форм у пары? Конструктор запятая.

Нам плевать на аргументы запятой. Они не вычислятся у нас, опять же, в weak-head-normal-form. Поэтому фолдл-штрих на более сложных структурках будет работать так же, как к фолдлу. Ну, почти. Конечно, будет вычислено это выражение.

Как вы можете заметить, оно вычислено. То есть тут именно применяется функция f к паре иксу. Но вот это выражение, внутри уже пары, не вычислено. Что печально. А когда быть? А вдруг нам хочется везде все максимально строгим сделать? Даже с парой.

На помощь приходит так называемый deepseq. Что такое deepseq? Deepseq это определенная функция, которая задана с помощью другой функции. Сейчас мы увидим, какой. И эта функция, которая называется rnf, спойлеры, она вычисляет до-нормальные формы. Не слава богу, это нормальные формы.

А именно это нормальные формы. Мы вычисляем seq от этого списка. Но у нас, очевидно, в динамике конструктор. Это конструктор cons. Undefined это вообще глубже в списке.

Поэтому это верный триггер. А вот deepseq, по названию уже понятно, что это deep sequence. То есть мы вычисляем максимально глубоко до, так сказать, как корректно выразиться, до, видимо, листа нашего абстрактового статистического дерева. Правда ли, мы забыли о том, что это undefined. Пытаемся сделать, вычисляем undefined и выкинем exception.

На deepseq. Deepseq, извиняюсь. Вот. Так. Как вы считаете...

А, да, тоже довольно простой вопрос. Что будет, если вызвать sequence от repeat false в ? И аналогично с deepseq. Из тематики, которую я только что описал, про deepseq. На ваш взгляд, что случится? Парус ломается. Что значит ломается? Более детально, что это означает.

Не завершится или упадет с out of memory. А, да. Спасибо. Действительно, да. Мы попытаемся вычислить бесконечный список.

Причем бес, он бес. Вы должны бесы вычислить. По аниматории deepseq вычисляется вообще все, что стоит слева. До nf. Нормальная форма.

Правильно, да. И мы нигде не завершимся. А рано или поздно, если мы не завершим предвидительно, опять же, лучше это не вызвать специальный номер. Лучше... Не лучше, а...

Просто не вызывать вообще никуда. Упадем с out of memory. Правильно. Это наиболее приятный исход. Ну, а в первом случае что случится? Второе понятно.

А с первым? . Да, . Repeat false. Это фалс. Две точки repeat false.

Две точки. Наш лишний конструктор. Это уже выход норма форм. Отлично. Возвращение .

Правильно. Так. Все. И... Ой, что? А, да, окей.

Вот теперь определение deepseq. Начинаем с nf.data. nf.data. Это... Как я хочу пошутить.

Это прям... Чувствуется, язык пошутить. Сейчас, ладно, без шуток. Окей, без шуток. Все.

nf.data – normal form data. Не non-fungible data, но normal form. Это класс типов. Принимает a. У него есть одна функция – rnf.

Вот та самая функция rnf, которая вычисляет нормальные формы. Вот тут написано, что rnf a равен aseq unit. Ну, это... Что-то наподобие дефолтного определения rnf, который используется для примитивных типов. Наподобие int, не знаю, char, double, word.

Word, напоминаю, это unsigned integer в Haskell. Вот. Отлично. Да. Вот, по идее, если instance.

nf.data для всех них, а очевидно, для всех этих, которые только что упомянул, типов, есть instance. nf.data. Очевидно. Безусловно. Как же это? Я думаю, что там не прописывается явно определение rnf.

Просто потому, что, опять же, int, double, char, word, это все примитивные типы. Поэтому можно использовать для них дефолтное определение. Но для более сложных структур, наподобие суммы типов, представим типов data. Именно с data. Лучше определить rnf кастомным образом.

Вот пример. Начнем с maybe. Окей. Ну, мы... Что происходит? Мы здесь вычисляем до...

Явно сразу же, видимо, да, вычисляем до weakly normal form. Pattern matching по внешнему конструктору – это ровное вычисление до weakly normal form. rnf от nothing – это unit. Отлично. Мы уже вычислили левую часть, там просто nothing.

Он не принимает никаких других значений, возвращаем unit. Отлично. А вот если у нас just с x, давайте вызовемся рекурсивно. Попытаемся вычислить до нормальной формы. rnf приводится как reduce to normal form.

Что, в принципе, логично. Пропихнем rnf внутрь, попытаемся вычислить до нормальной формы x. Именно из этого возникает constraint. rnf data – a. x имеет тип a, да.

Поэтому a обязан станцировать type class rnf data. Отлично. Вот и все определение maybe. Сейчас, наверное, на время. Вот.

Death risk аналогично, совершенно прям. Эквивалентное определение. Мы вычисляем аргумент до weakly normal form явно, делаем pattern matching к логическому конструктору. То есть, в принципе, возвращаем u сразу же, нам нечего больше вычислять. И здесь у нас есть глава x и хвост xs.

Вычисляем голову. Делаем seek. Собственно, seek как раз делается, чтобы мы явно вычислили голову. Потому что, опять же, seek вычисляет левую вещь до weakly normal form. Слева стоит rnf x.

То есть, мы уже будем вычислять до нормальной формы. Поэтому seek достаточно. Вот. Да, мы вычисляем rnf x. x имеет тип a.

Опять же, из-за этого у нас имеет место constraint. rnf t от a. Ну и дальше вызываемся рекурсивно от хвоста. И, собственно, это все определяет rnf t для списка. И deep seek тогда определяется почти как seek.

Deep seek b это вычисление a до normal form seek b. Seek обеспечивает нам однозначно вычисление левой части. Потому что, если мы просто вернем b, очевидно, если мы вернем b, у нас a уже будет не вычислено. Это максимально бесполезная функция. Это flip const.

Вообще-то. А deep seek тогда был flip const. Это бесполезная функция. Поэтому поставим seek, чтобы вычислить a до нормальной формы. Вот.

И из-за этого a обязан дистанцировать rnf t. И такая такая страница. Вот. То есть, это ответ на вопрос, почему нам нужен type class для deep seek. Потому что для соответствующих типов данных кастомных, они имеют кастомную структуру.

И для соответствующих кастомных структур можно, конечно же, сейчас я уже ухожу в дебри того, что будет потом. Очень потом. Можно, конечно, на самом деле сделать кажется, реализовать какой-нибудь nf data для произвольных типов. А вообще произвольных с помощью tplate haskell'а, кажется. Кажется, в таком машинаре можно просто произвести.

Но лучше просто делать мануально, мне кажется. Мануально делать instance nf data, потому что, конечно, структуры кастомные. Ваши суммы типов, ваши определения, они все кастомные, зависит от того, сколько у вас там полей в ваших структурах. Вот всех нужно вычислить с помощью pseek'а и вызвав rnf от полей. Вот и все.

Да, вопрос есть. Нельзя, разве, через генерики, очевидно, задеравить структуру реализации nf data? Ну, типа, надо просто пройти по всем вариантам, для каждого варианта вызвать рекурсивно для всех полей. Да, ну, то, что я упоминал сейчас, это не делается на обычном haskell'е, это делается в tplate haskell'е. Я, мне кажется, это даже можно. Потому что tplate haskell'е позволяет анализировать уже в рамках языка haskell'а то, как у нас сконструированы наши типы данных.

Какие там конструкторы и какие там поля. Да, совершенно верно, вот это как бы эдскин того, как можно сделать nf data запросто, бесплатно. Пройти по всем кейсам, по всем полям, вызвать rnf от всех полей и сделать ряд секвенсов и все. Да, согласен. Это именно тот способ, который я говорю.

Но это просто сложно, там нужно использовать tplate, сложно кому-то, кому-то нет. Нужно использовать tplate haskell, а tplate haskell'е мы поговорим, не мы, а с кем-то другим, мне кажется, поговорим потом на лекции или . Сейчас пока 8. Значит, тут есть ссылочка про то, как избежать многих вызовов rnf, если у нас строгие вычисления, предпочтительные, извиняюсь. И это делать с помощью такого типа данных, который называется once.

Вот он определен по этой ссылке. Ссылка работает, там все доступно. Пойду посмотреть. Вот. Это весь deepseq.

Довольно простая вещь, довольно простой инструментарий для вычисления нормальной формы. Микро-вопрос. У всех от определений сам есть проблема. У всех у всех есть проблема. есть проблема.

В чем заключается проблема каждого? Как и с fold. Мы делали до этого, что у нас типа, если мы запутаемся на очень большом списке каком-то, то мы проиграем, потому, у нас очень трудно. Просто как в конце будет огромное, огромное, огромное выражение, которое никогда не вычисляется. Справедливо. Да, действительно.

Например, вот здесь кейс ровно fold. У нас в аккумуляторе аккумулируется пеганский фланг, который не вычислен до тех пор, пока мы не вернем его явно. Тут нечего вычислять, тут x плюс реквизитный выставка. Тут нужно ждать, пока список опустеет. Это предотвратить чуть-чуть менее тривиально, чем fold, но тем не менее можно.

А здесь, в втором случае, это описывалось в лекции по 1.0, typeclass 1.0 и т.д. Это то же самое ровно. Мы делаем плюсик, у нас сами в кастингере аккумулируются значения, и потом, когда мы делаем get сам, мы вычисляем сам. Тогда уже этот гигантский фланг будет средуцирован. Проблема в том, что там гигантские танки, которые не нужно желательно вычислять, чтобы памяти не занимать больше, чем ожидается.

Да, пожалуйста, это же самая проблема. Тут их 6, да? 6 переходов. Значит, как это можно исправить? Это просто больше инструментария в рамках языка Haskell, который позволяет делать некоторые вещи более строгими. Первая вещь, точнее, в рамках текущей секции нашей лекции, это bang by trans. Опять же, наш аккумулятор слишком ленив, мы хотим вычислять на каждой хвостовой рекурсии.

Мы можем добавить bang, то есть знак восклицания, ровно перед нашим аккумулятором. Внимание, тут не должно быть пробелов. Если нет пробелов, тогда это воспринимается как индексный оператор. То есть тут ровно не должно быть пробелов. Вообще не привык я к авторам текстов.

Значит, этот bang ставится единожды, и он вычисляет то, что стоит после него, ровно после него. То, опять же, weak headorable form. Спойлеры, опять, будут маленькие проблемы. Сейчас мы до этого дойдем. Раньше, для того, чтобы делать bang, необходимо было прописывать этот extension.

Если я правильно помню, в версии GHC 2021... Какая-то версия GHC в годе 2021. Это стало по умолчанию синтезатором Хаскова. Я не уверен в этом, но я где-то видел эту новость. Я не спермитировал, но надо попробовать.

Не писать bang patterns, а написать bang. Если у вас все скомпилируется, то да, действительно, это уже теперь по умолчанию часть синтезатора языка. Но раньше bang patterns просто расширялся в языках Хаскова, в котором можно было добавлять воскресенье ровно перед тем, что мы хотим вычислить до weak headorable form. Причем это делается единожды. И это типа-типа раскрывает что-то наподобие вот этой вещи.

Причем, да, это определение ровно эквивалентно обычному самому. То есть вычисляется это вот то же самое. Что тут написано? Тут есть guard. Guard можно опять же ставить в локальных связках без проблем. Например, в where.

Очевидно можно. Легальный синтаксис. Мы делаем seek, ack, а тут false. То есть это вернет false. Мы вычислим ack до weak headorable form, вернется false.

Undefined никогда не будет вычислен, потому что это false. Аck, guard, false, state. Отлично. Все. Вот тут уже на этом моменте ack вычислен.

До weak headorable form. Переходим в оставшиеся два кейса. Вот еще. То есть эти два определения типа-эквивалентны. На самом деле можно сделать вместо ack, ой, вместо вот такой вот машины можно сделать не guard, а написать case, ack, off, нижнее подчеркивание, стрелка, и дальше то, что стоит справа.

Потому что case expression в хаскеле, именно case, это ровно та самая синтетическая конструкция, которая позволяет вычислять до weak headorable form. Ровно case. Case это прям фундамент вычисления в хаскеле. Вот и все. Так.

Вопросы по bank-паттерну на текущий момент. Если не есть, конечно. Час, милосердце, час. Никто не пишет, ну ладно. Да, теперь пишите, отлично.

Так, окей. Больше bank-паттерна. Можно ставить банк-паттерны внутри конструкторов. Например, здесь у нас есть конструкция запятая, есть два поля. Вот я прописываю здесь банк внутри первого элемента пары.

То есть это будет что-то наподобие, сейчас скажу, g, это сахар следующий, gb, стрелка case p, ровно case p of, дальше у нас конструктор запятая, x штрих y, а потом у нас стоит банк у xа. Мы делаем что? Мы делаем case x штрих of, x стрелкой, и дальше мы возвращаем список. То есть мы явно делаем case еще, пол, внутри него элемент нашей пары. Теперь можно прописывать как глубоко, как только захотим, наши более сложные типы данных. В лет-связках то же самое.

Лет... Ну тут, да, это как жилье, только это локальная связка. Тут явный паттерн-матчинг паре, и первый элемент пары у нас будет чуть более строгим, чем по дефолту. Более того, можно ставить backpattern, извините, в лямбде. Напоминаю, это донотация, это нам проследуется в bind, вспоминаем монады, донотацию в монаде, это pop, bind, дальше лямбда x, стрелка и так далее.

Можно ставить bang в аргументах лямбды. Это как раз транслируется, лямбда x', стрелка, кейс x', off x. Мы сделаем один шаг вычисления до выходного формулы x', получим x, отлично, да, правильно. Не x, извиняюсь, а нижнее подчеркивание. У нас уже и так x' вычисляется.

То есть там просто кейс x, off. Опять же, можно ставить bang в лямбдах. На основе этого можно думать на тему того, как мы можем вычислять аргументы наших функций, когда мы передаем аргументы к какой-то функции. Помним доллар, обычная аппликация. Аппликация с bang – это строгая версия аппликации, когда мы вычисляем наш аргумент, потом вызываем функцию f.

Это строжайшая версия аппликации доллар-бэнг-бэнг. Это когда мы делаем deep-seq, вычисляем x до нормальной формы, потом уже передаем функцию f. На самом деле, вот тут, конечно, есть bang-паттерн, но я бы это написал через x-seq-fx. Потому что мне кажется, это эквивалентная вещь. Это как здесь, где deep-seq стоит, мы вычисляем x до нормальной формы.

Это то же самое, что делает bang. То есть это x-seq-fx. Должно быть абсолютно эквивалентно тому, что написано здесь. Но, тем не менее, оба варианта максимально легальны. То есть строгое вычисление аргументов и потом передаем функцию f, и строжайшее вычисление аргументов до нормальной формы, потом передаем эту функцию f.

Вот тут есть маленький примерчик, примерчик, да, русский язык, примерчик того, как мы можем использовать строгое вычисление. Мы тут униформально, что происходит? Господи, униформально, то есть uniform distribution, генерируем чиселки от 1 до . От 1 до , конечно, исключительно, если я правильно помню. У нас будет список разнообразных элементов. Делаем sum, но мы при этом вычисляем sum.

С учетом, с надеждой на то, что sum здесь тоже довольно строгий. Сейчас я скажу вещь, надеюсь, будет понятно. sum sum, первое sum это s, это вот sum, это русское sum, да, а второе sum это вот сум, сам сум. Сам сум может быть не строгим, но он вычисляется, потому что у нас доллар black стоит. Но желательно, чтобы сум был строгим.

Потому что вот, опять же, мы это уже обсудили. Соответственно, чисел желательно, чтобы было строгим. Потом мы дойдем до всех кейсов, которые мы рассматривали на протяжении, например, части лекции. Вопрос к собственно зрителям, ну и вам тоже, очевидно. Чем отличаются две функции f1 и f2? Есть идеи? Казалось бы, ничем.

Ну, потому что, когда мы решили банк паттерн, в первом случае на пару, у нас пара, как бы, запятая это уже конструктор. Ну вот, собственно, он и есть вычисленный. Да, максимально справедливо мы, да, спасибо большое, мы вычисляем запятую до выхода термоформ, получаем запятую, ничего не меняется. То есть, когда мы пишем здесь явно, на самом деле, потормачиваемся по структурке здесь, вот тут вот, да, мы вот ровно это и производим. Мы производим, как я уже говорил миллион раз вычисления до выхода термоформ.

Поэтому эти две… У меня слышно? Интернет у меня работает? У меня слышно? Алло? Да, все слышно, все хорошо. Да, мне просто написано, что интернет пропал. Окей, сори, господи. Так, спокойно. Было бы плохо, если бы интернет пропал и набегнуло в лекции.

Да, в общем, ничем они друг от друга не отличаются. Вот. А теперь поговорим про полярную противоположность bng, которая называется Lazy Pattern Matches. Раньше, вроде, как-то это имело название irrefutable pattern, что, на самом деле, с точки зрения английского языка, тоже логично. Выглядит оно вот таким вот образом.

Значит, что тут прикол? У нас есть f от пары abm. Ну да, мы делаем, опять же, паттерн-матч, мы делаем редукцию до weakly normal form, достаем этот первый элемент, делаем const 1a. Ну, const 1a вычислится до единицы, это так понятно, число. Определение const. Но, на самом деле, эта пара слишком строгая.

Казалось бы, в чем? Ну, какая разница? Ну, пускай будет строгая. Проблема в том, что если мы сделаем f от undefined, то будет undefined. Спойлер к следующей части этого слайда. f от undefined, несмотря на то, казалось бы, у нас const 1, от чего-то, неважно от чего, он выходит в единицу, если мы передадим const 1 в любой аргумент. Хочется, чтобы f от undefined означало единицу тоже.

Для этого существует, уже, если я правильно помню, именно вот часть английского языка Haskell, тильда. Похоже на bang. Опять же, пишите тильды вместе с тем, что стоит справа. Без пробела. Иначе это ух, иначе это равенство типов.

И это уже будет потом. Это будет лекция, опять же, , , . Не помню. Вот. Тильда.

Значит, что делать тильдом? Значит, я сейчас скажу... Нет, давайте я сделаю так. Я сейчас копирую функцию, у меня же открыт блокнотик. Я специально его подготовил. Тот самый, в котором я уже писал миллион раз.

Видно, да, что я пишу здесь? Друзья? Это закомментирую пока. Ну, в смысле, это не Haskell, но не важно. В общем, по что трансформируется типа вот этого вот тильда? Значит, еще раз, тильда называется lazy pattern match. Когда я пишу здесь тильду, и дальше мы делаем pattern matching явно, это трансформируется в следующую вещь. Сделаю align.

g от p. Именно от p. p это просто идентификатор. И не больше. То есть мы не паттерматимся в этом прикол.

Вот тут проблема в том, что тут стоит a. Очевидно, откуда a взялось. Тут стоит a, и не очевидно, откуда a взялось на первый взгляд. На самом деле очевидно, но не важно. Вот это вот a, это первый элемент.

Вот это вот a, это f of t, p. То есть когда мы тут заполучаем какие-то элементы в нашем pattern matching, в смысле не элементы, а поля, а это поля, пары, то когда мы делаем тильду, опять же, пары больше нет. У нас есть просто произвольный p. Его не вычисляем в этом прикол. Тут как бы стоит не f of t, а вроде как чисто более формально лямбда p стрелка кейс p of a, стрелка a.

Ну или вот лямбда кейс, давайте я сделаю вот так вот. Да, так лучше. Вспоминаем лямбда кейс, мы его проходили. Вот. Итого.

И refutable pattern, то есть lazy pattern matching, трансформирует то, что мы pattern matching в индикатор 1, тут это я назвал tp, и поля становятся то же самое, что селектор. Это селектор. Мы берем нашу пару и возвращаем левую часть. То же самое, что левая проекция нашей пары. Мы называем батлок.

Вот, это селектор. Что прикол функции j? В том, что если мы произведем здесь undefined, вот тут уже предупредим undefined для j, поскольку мы явно не pattern matching на самом деле. Тут будет undefined, const, по определению конста не вычисляет правую часть, он ленив по второму аргументу. Возвращает единицу. И написано здесь, что делает refutable pattern.

Я уже сразу не хочу больше пока что уходить по атлантику. Если непонятно, я снова вернусь по атлантику, поясню. Значит, это jp равно const 1, и тут селектор левого аргумента, левое поле p. Я уже говорил about undefined, потому что мы тут pattern matching, мы вычисляем наш аргумент по первому форму явно. В j мы не вычисляем, потому что стоит тильда.

Вот и все. List-нестройность нам, казалось бы, не очень нужна. Вот. И refutable patterns активно используют в тех местах, где у нас один конструктор, как у пары, и много полей. Вот я сказал один конструктор.

Почему важно, что там один конструктор? Вот почему. LazyHat. Смотрим на LazyHat. У нас везде refutable patterns. Везде refutable lazy pattern matches.

Приков в следующем. В этой строке, опять же, у нас стоит тильда. Тильда. .. список трансформируется в просто L.

Опять же, я отдал название идентификатору L. Фреш, например. Это трансформируется в LazyHat. fresh равно undefined. Но LazyHat.

fresh, где фреш – это просто аргумент, не вычисленный, равен undefined, уже вот здесь, на первом определении, будет возвращаться undefined на любых аргументах нашего списка. Каковый мы список не передали. LazyHat от пустого списка – undefined. Потому что LazyHat от любой, опять же, fresh state, любой идентификатор – undefined. LazyHat от списка 1.2.3 – undefined.

Вот этот кейс второй, он redundant, он ненужный, потому что второй кейс трансформируется в LazyHat. fresh равен Hat.fresh. Hat – это, опять же, перед головой. Опять же, у нас происходит кейс по всем аргументам, всем случаям сверху вниз. У нас этот кейс будет удовлетворен моментально, потому что это кейс по произвольному аргументу, там, опять же, fresh.

Давайте я буду говорить L. L списка, да? Вот. Вопрос вам. Что будет, если мы поменяем местами эти два случая? Напоминаю, что здесь undefined у любого списка. Что будет, если мы поменяем местами два случая? То есть это станет первым случаем, а это вторым.

Ваше мнение. На пустом списке паниковать будут. Как именно? Да, как именно? Ну, типа, типа, что, скажем, откуда возникает пустой список. Можно не точно, можно вербально, я пойму. Строго говоря, когда у нас пустой список, он как бы подходит как раз таки, когда мы достаём голову из нашу списка, но при этом уже не знаем, что там за голова, потому что там пустой список.

Какая-то ошибка тогда будет. Ошибка будет в том, что у нас просто будет написано non-exhaustive cases. Помним, или, сейчас, дайте я подумаю. Да. Потому что, опять же, lazy head это что-то на подобии lazy head p равен head p.

То есть lazy head от этой списка равен head. Head это частичная функция, partial function. Она не определяет до пустого списка. Ну, типа того, да. То есть, если, опять же, это кейс первый, то lazy head от пустого списка будет паниковать и с ошибкой на подобии non-exhaustive patterns.

Либо non-exhaustive patterns, то есть не все паттерны были учтены, либо вот та самая ошибка в head. Нет, неправильно. Не та самая ошибка в head. Я объясню, почему. Всё просто.

Вы видите, я тут написал fst. Написал бы тут fst, была бы одна вещь. Но здесь, опять же, lazy head от fresh равен head fresh, это некорректно. У компайлера нет доступа к стандартным селекторам. Тут не head стоит, тут стоит case a colon underscore a Вот именно поэтому возникает non-exhaustive patterns.

Один паттерн здесь. Это конс. Поэтому в случае, если этот кейс первый, у нас будет, к сожалению, non-exhaustive patterns. А если у нас голова, если у нас конс стоит, то вернее лazy head от конса. Тут уже всё просто.

Come on. То, что и должно быть, всё хорошо будет. Да. У нас паттерн удовлетворяет кейсу, который я написал в платнотике. Прямо голову, всё хорошо.

Именно из-за таких вещей lazy pattern matches не используют, и это опасно на самом деле, не используют в вот это ещё бесполезно, в сумме типов. Это используют в произведении и больше ни в чём. Это когда у нас есть дата, отдельный конструктор и множество полей. У вас были трансформеры, я знаю, у вас они были на прошлой лекции, в смысле, 2 недели назад. 3 недели назад.

Да, 3 недели назад. Вот там обсуждался стейт. И даже райтер, райтер t, стейт t. Вот там, если взглянуть на source, в стейт t используются illegal patterns, потому что там не нужна лишняя строгость в паттерн-матчике по паре. Не нужна просто.

Вот всё. У пар 1 конструктор, там множество полей, вполне себе не то, что это легальный способ использовать lazy pattern matches, так ещё и предпочтительный. Это по этой причине. f1 очень тупая функция, принимает either и int, тут написано write1, но это вообще не важно, что тут стоит. Это tilde, в этом прикол.

Во что превращается f1 tilde write1 равно ? Превращается это в f1 fresh равно . Fresh это что? Вот. То есть f1 здесь, вот это же const, реально, но это const . Игнорируем аргумент, который стоит здесь. Возвращаем .

Факт того, что мы его не вычисляем, факт того, что он ленивый, что стоит tilde, что f1 fresh, то есть underscore неважно, позволяет нам писать здесь left. Максимально элементарно. И даже пытаться выбросить ошибку в наш irrefutable pattern всё ещё вернуться в . Потому что это не вычисляется. Это lazy pattern match.

f1 fresh равно . Ну, опять же, конечно, это функция безопасная, это просто const . Но, да, тут сумма типов тоже не очень безопасна в общем случае, как с lazy pattern, да? Вот. Поэтому лучше так не делать, наверное. Или просто писать f1 равно const , раз уж приспичили.

Вопросы по lazy pattern match. Что дальше? А, окей, strict Haskell. Мы подходим к концу первой части лекции. Окей. В общем, где ещё могут использоваться bank patterns? Мы уже узнали, что могут использоваться в лето-байдингах локальных, в аргументах конструкторов внутри полей.

А также можно использовать bank patterns в самих полях типов данных. Так как здесь у нас есть конфиг, это что, просто экстракт, там есть int, есть map-settings, users и extra. Мы хотим, если мы хотим, сделать так, что у нас int и map-settings были строгими. Всегда. А элементарно давайте мы ставим bang-bang'и именно в типах, не вот перед users и extra, а именно в типах.

Тогда users и extra будут всегда вычисляться на выход-нормал-форм. Проблема в следующем. Казалось бы, у нас, опять же, у maybe есть локотструктура nothing-adjust, nothing-adjust уже прибывает выход-нормал-форм. Тут нужно пытаться понять, имеет ли смысл поставить bang в maybe. Если bang делает то же самое ровно, что делают другие bang'и.

На мой взгляд, нет. Ну, потому что мы вычисляем… Нет, ну окей, ладно. Это стретч, с моей стороны. Возможно, это имеет смысл, потому что даже, несмотря на то, что там тут stack-maybe-settings, то, что если у нас есть just от какого-то settings, он не будет вычислен, то, что just будет вычислен хотя бы до just, а не до ничего, уже что-то. Несмотря на то, что это stack-maybe.

То есть, если вдруг реально нам не нужно что-то больше, чем выход-нормал-форм, пожалуйста, ставьте ваши bang'и без проблем. А вот у всяких таких полей как int или опять же те же самые bool, char… нет, не bool, не bool. char, double, word и так далее. Вот там реально ставят bang'и. И это работает.

А если мы хотим, чтобы в нашем файле у всех типов данных были строгие поля, тогда можно просто добавить прогму strict data и не ставить bang'и. Нигде. То есть, возникает вопрос, а что, если мы хотим, чтобы во всем модуле все было строгим? Потому что мы мазохисты. Можно тогда ставить strict прогму, делать все строгим по умолчанию. Ее не используют, кажется, так часто, как возможно ожидается кем-то из вас или каким-то другим человеком.

Потому что, ну, смысла в тотальной строгости, наверное, не совсем есть. Смысл совсем есть. Более того, вы, наверное, успели познакомиться с тем, что вот есть в ваших проектах package.yaml, в которых можно указать внимание, включенное extension по умолчанию. Представьте, что вы указываете strict по умолчанию, как extension project-wide, то есть в вашем проекте. Тогда у вас весь ваш проект станет строгим.

Я никогда в жизни такого не видел, чтобы это было, и надеюсь, никогда в жизни не увидишь, потому что мало смысла в тотальной строгости Haskell. Один PR Haskell просто вперед и пропадает. Его не используют. Стрикт экстенсивно. Но strict.

id используют однозначно. И в нем есть смысл. Да. Естественно, как уже много раз обсуждалось, строгие поля позволяют избежать space leaks. Space leaks, опять же, это те самые случаи, когда у нас оказываются гигантские фанки в нашей памяти, которые вычитаются очень потом.

Это space leak. Это у вас уже наверняка было. Например, в C++, кажется. То есть это было сколько лет назад? Полтора, да? Короче, это было давно. Неважно.

Вот. Все, это strict Haskell. Да, тут, короче, есть еще блог-пост от Романа Чепляки о том, сколько занимает 8-битный интеджер в C и Haskell. В этом блог-посте еще Роман также упоминает то, как в Haskell представляются значения в памяти, да. Я это тоже себе затронул в конце лекции.

Это более интересная вещь. На самом деле, это уже slightly advanced Haskell, типа того, на уровне компилятора. Но я остальное затронул, потому что это интересно. Это все еще не компилятор, казалось бы, все еще на уровне Haskell, но более advanced штуки. Это затронул в конце лекции.

Итого, сейчас мы будем на -минутной, резюмируя, что делают, когда можно использовать strict evaluation. Вот когда у нас есть некоторые ленивые подчисления, которые, к сожалению, возвращают out of memory, ну, не с такой workflow, как тут написано почему-то, можно проанализировать вашу программу, выяснить, в каких местах у вас используются слишком ленивые подчисления, которые можно сделать более строгими. В том числе, когда у нас имеются арифметические операторы по, скажем, примитивным типам. Например, int, double, float, хоть chart, какая разница. Тогда можно использовать строгость по этим аргументам.

Например, если мы, опять же, делаем свертку, например, левую, мы можем сделать строгим наш аккумулятор. Если мы, например, сворачиваем наш список или любую произвольную структуру по сложению. В случае, когда у нас возникают всякие состояния высовывания функций внутри памяти. Из-за этого можно сразу вычислить h от x, как здесь. Вычисляем h от x, потому что тут стоит банк.

Потом мы передаем это g. Или можно ставить банк у x. Тогда x будет строгим, то есть мы вычислим x. h от x, конечно, sorry, g от h аргумента, x будет в памяти, но хотя бы у нас x вычислится. Вот эти два примера, они как бы разные на самом деле, потому что вычисляется h от x, а тут именно x.

Очевидно, кейсы фундаментально отличаются. Тем не менее, они используются. Ну и, как я уже говорил недавно, поля данных, чтобы изображать очередных кейсов офф SpaceLeaks. Вот. А, нет-нет-нет, я совсем забыл про эту часть лекции.

Да, я оборачиваю еще 6 минут, потом уйду на перерыв. Немножко про SpaceLeaks. И вот эта часть очень важная. Давайте обсудим, что тут написано. Функция pet.

Она вычисляет сумму списка, ну, сворачивает по список по сложению и нулю. И длину. Запекивает оба результата в пару. Фух. Вот этот вот SpaceLeaks, он неизбежный.

Вообще. Почему? Посмотрим следующее. Допустим, опять же, тут, наверное, возникнет сейчас, вот тут нужно подумать, есть ли недетерминизм в том, что вычисляется сначала. Я вот не знаю. К сожалению, я забыл эту часть.

Хаскова. Но, допустим, сначала вычисляется левый аргумент пары. Один из двух случаев. Отлично. Мы вычислили sum.

Чтобы вычислить sum, необходимо сделать паттерн матча к пиксу. До тех пор, пока мы не вычислим полностью нашу сумму. Чтобы это завершилось, наш список должен быть конечным. Это очевидно. Мы вычислили sum.

Дальше мы вычисляем length. Поскольку мы уже сделали кейс xs, причем полный кейс, мы полностью разанфолдили наш список, этот список сейчас будет висеть в памяти до тех пор, пока мы не сделаем length и не завершим функцию bed. То есть мы вычислим функцию sum, например. Какой бы он ни был гигантский, он будет висеть в памяти до тех пор, пока мы не вычислим length, не вернем результат и не завершим работу нашим списком. Это unavoidable space leak.

Как быть? Это мы уже обсудили, когда у нас здесь возникает типа строгий foldable по более сложным структуркам в аккумуляторе. Это мы уже проходили. Есть такая классная библиотечка от Кабриэла Гонзалеса, называется foldable. Целый пакет, в котором потеряет тип данных, сейчас я его напишу, fold, да, это fold, он принимает два аргумента a, b, и ух, сейчас вспомню. В общем, это есть экзидентальный тип, тут ставится парол x.fold и дальше три значения.

Это то, как мы сворачиваем, а это наш элемент контейнера. Например, это элемент нашего списка. Их это начальное значение, а тут просто processing. То есть, мы совершили наш fold, и дальше мы хотим вернуть просто из xа в b. То есть, это что-то после fold.

После fold, извиняюсь, после четвертки. Финальная функция, собственно говоря. Видели вот этот парол x? Вот это то же самое, что экзидентальный тип. Пока их не было, я потом упомяну еще экзидентальный тип и объясню, что это такое на следующей части лекции. Но fold это такая вот функция, ой, функция, господи, тип данных, который капсулирует переход и изгибничный переход в свертке начальное значение и постпроцессинг.

Да. Вот. И на основе этого типа данных тут реализуются всякие уже встроенные вещи, как length, sum, понимание. Вот length означает fold. И fold является функтором и аппликативом.

Fold не является монадой. Такие дела. Что принимает fold? Он принимает fold a, b, принимает f от a. f от a, помните, foldable, да? f от a до t, там было t от a. Это просто какой-то контейнер, варганизованный типом a.

Возвращает к b. Вот. И здесь, поскольку там все это как композиция функции, когда там возникает s-кабинатор, вторая аксиома в матлоге, когда там возникает первая аксиома в матлоге, это pure и app, управление есть, то там еще функции. Это все в итоге получается довольно строгим. Там, кажется, какие-то есть элементы фолда, которые вообще-то с bang'ами, я не помню, какие, я забыл.

Блин. Кажется, начальное значение с bang'ом. Вообще логично, да? Неважно. В общем, да. И это просто позволяет для типа произвольных структур делать приколюхи связанные с обработкой структуры, свёртки и так далее.

А, ну это свёртка, собственно говоря. Fold, между прочим, это левая свёртка. Написано fold, но на самом деле это fold'у по фолду. Короче, рекомендую посмотреть видео Габриэлы. Она обсуждает вот реализацию фолда, но моноидальной реализации фолда.

То есть у нее там другие определения типа данных через моноид. Но моноид конкретно тому, что вот в фолду. Там всё довольно просто. Очень классный данный. А ещё финальная финалочка, да? Да, финалочка.

Всё. Вот немножко про то, как визуализируется Spacelix. Вот здесь две картинки перед вашими глазами. Слева по вертикальной шкале у нас байты, алоцированные с правой секунды. А логично с правой части.

Здесь всё это хаскилные функции. Сейчас надеюсь, что это всё видно. Я не знаю, что зависит от качества трансляции. Это всё хаскилные функции. Можно заметить здесь, что тут локация варьируется, но примерно константная на самом деле, потому что там всё учитывается в левой части.

Там всё по релевантным аргументам строгое, поэтому там не разрастаются фанки линейно. Как это делается справа? Можно заметить, что справа у нас есть линейная зависимость от секунд и от байтов. Внимание, вот здесь слева мой кристалл виден, я даже вижу его. Тысяча байтов. Тут миллионы, более того, тут сотни миллионов.

Вот здесь это уже примерно гигабайт. Потому что миллиард байтов. Да, правильно. Типичный пример спейслика. Вот тут у нас разрастается фанк, который у нас начислен.

Внимание, вот тут приколчик возникает с питфоллом. Это гигантская пропасть. Это что? А это завершение нашей функции. Наша функция завершается, производится вычисление фанка, он начинается довольно быстро, там всё вычисляется в уже одно значение, и аллокация теперь уже более адекватная. Поэтому этот питфолл это непосредственно вычисление аргумента после завершения функции.

Явно тут графы, а не тут линейные. Но в зависимости от того, какого space complexity именно space complexity. Вот графы может быть хоть как парабола выглядят, хоть как логарифм, хоть как logstar. Я никогда в жизни не видел алгоритм, у которого бы space complexity был logstar. Никогда в жизни я не видел такого алгоритма.

Я не знаю, как это работает, и есть ли такой алгоритм, у которого logstar space complexity. Но, тем не менее, наверняка можно придумать. Короче говоря, шейп вашей зависимости отражает то, как у вас разрастаются ваши танки. Тут это линейная зависимость. Во всех функциях почти.

Вот. Да. Вот как вы детектите space leak. Смотрим по батикам. Смотрим на то, какой у вас граф.

Желательно, чтобы там у вас все, конечно, было константное. То есть все прочиталось мгновенно по релиматным аргументам. Все. Окей. Эта часть лекции завершилась.

Давайте уйдем на перерыв. Я пока завершу запись. Чпок. Окей. Вторая часть будет посвящена мутабельным объектам и дефористейшну.

И как резолвить дефористейшн. Ой, как резолвить, наоборот, дефористейшн — это способ резолвить промежуточные представления в памяти. Итак. Собственно, дефористейшн — это механизм, который позволяет предотвращать или... Да, правильно.

Предотвращать промежуточные структурки в памяти. У нас есть несколько типичных примеров промежуточных структур, наподобие следующей ситуации. Более того, ситуация первая с мапами. Я ее упоминал, я помню, что я упоминал ее в лекции по type-классам, которые... То есть она сейчас затрагивала то, что у type-классов есть некоторые правила.

Вот эти некоторые правила как раз таки можно использовать, чтобы избавиться от промежуточных представлений в памяти. А что это такое? Откуда возникают промежуточные представления? Посмотрим на левую часть. В левой части у нас есть mapf. mapr. Мы придаем список, по нему один раз применяем функцию, по нему второй раз применяем функцию.

Когда мы применяем функцию g, то мы заотводили весь список, весь список у нас теперь находится в памяти, и там ко всем элементам функция g применена. Она будет висеть в памяти, пока мы не применим функцию f, не завершим работу с нашими двумя мапами. Это два траверсала одного и того же списка. Потому что или два, список будет оставаться, это прям как в ситуации с собственно, бетом, с первым бетом. Из-за того, что у нас два траверсала списка, у нас из-за этого возникает промежуточное представление списка в памяти.

Только здесь оно именно промежуточное. Потому что результат, это должна быть композиция функции f и g. Поэтому это называется промежуточная представление. Потому что мы пока что применим только функцию g, а нужно применять еще функцию f. Мы знаем, что есть функциональный ло, который говорит о том, что mapf.

mapj равен mapf.j. Перк этого правила в том, что у нас один траверсал, один проход по списку, мы сразу применяем элементную функцию f от g, применяем g, потом f. И все. Мы ничего не храним в памяти промежуточного и лишнего, у нас один траверсал. Это хорошо.

По идее, аналогичная вещь в самом. Мы приезжаем по списку, потом делаем сам. Мы проехали по списку, а потом мы свернули список. И когда мы прошли по списку, у нас есть список в памяти, который мы потом сворачиваем. Зачем хранить список в памяти, если мы его рано или поздно сворачиваем? Можно ведь это сделать сразу же.

И скоро будет алгоритм, как сделать из вот такой вот страшной вещи, наподобие того, что написал здесь, вещь, которая избавляет нас от промежуточных представлений. Вот следующий слайд. А пока затронем еще третью строку от filterp. mapf. Мы опять же приезжаем по списку, применяем функцию f, потом фильтруем наш список, оставляем только те f от x, которые реально притягают у p.

Причем, опять же, эта функция filterp. mapf работает еще и для бесконечных списков, по причине того, что все ленивое. У нас, например, список бесконечный, он всегда не пустой. Мы из мапы вытаскиваем gold, потом этот gold обрабатываем фильтром. И, например, если мы делаем take от filterp.

mapf. l, то надо, чтобы у нашего бесконечного списка было хотя бы элементов f от x, которые притягают у p. А мы хотим сделать аналогичную функцию, которая тоже будет работать для бесконечных списков, но в которой один треверсал. Тут треверсалов, опять же, два. Хочется, чтобы у треверсалов была одна штука.

Чтобы не было, опять же, прогружечных представлений наших списков. А прикол в финальной строке в том, что мапа, а потом фолдер, можно заменить на фолдер от композиции. Ровно она и есть. Причем ровно в таком виде. f – это функция из fb, f – это функция из b, функция из cfc.

f.g – это функция из a, функция из cfc. Та же самая сигнатура. Фолдровская, так сказать. Поэтому композиция вполне валидная. И более того, мы сразу же сворачиваем наш список.

Что удобно. Опять же, у нас один треверсал по списку. Перед тем, как мы перейдем к алгоритму, мануальному алгоритму произведения Deforestation, давайте мы перепишем map немножечко. Ну, map определяется каноническим образом по паттерн-матчингу по второму аргументу, конечно же, нашему списку. конечно, паттерн-матчинг по аргументу сразу же – это на самом деле четный потопей сахара к кейс-экспрессиону.

У нас, как я уже говорил, кейс-экспрессион, кейс-форажение – это фундаментальная составляющая, которая вычисляет наши значения. Именно кейс-форажение это производит. И, на самом деле, эта запись, которая здесь, она, естественно, эквивалентна записи вот этой те же самые записи. Но эта запись более похожа на ту запись, которую вы можете найти, если вы скомпилируете Haskell в его первое промежуточное представление. У Haskell'а в мультикомпиляции есть несколько представлений.

Первое из них называется core. Core – это такой язык внутри Haskell, очень-очень маленький, у него очень минимальный. И вот это почти core, на самом деле, только тут у функций в core нету списка аргументов. Есть, опять же, lambda f стрелка, lambda l стрелка, то есть там лямбда и по одному аргументу. Ну, как в обычных функциях.

Мы знаем, что в Haskell у нас все функции по одному аргументу. И тут нету инфиксных кооператоров, тут все применение функции префиксное. Немножко про core, язык внутри Haskell. Это похоже на core немножечко. И вот это определение мапа, мы будем его использовать, когда будем делать differentiation под этой функцией.

Мы здесь применяем функцию умножить на ко всем элементам, потом сворачиваем по плюсу и нулю. То есть мы делаем sum. Как мы должны сделать, значит, опять же, в чем прикол? Прикол в том, что мы делаем два траверсала. Хотим делать один траверсал. Один проход по нашему списку, чтобы не было промежуточных списков в памяти.

Шаг нулевой. Мы делаем это экспансию. Это экспансия, это мы добавляем аргументик. У нас аргумент ожидается, да? Вот эта композиция, да? И потом unfolding определяем композиции. Композиция в точке – это просто аппликация.

Это мы знаем. Очень просто. Тут шаг нулевой. Это мы просто берем, явно аргументы вставляем и живем спокойно. Дальше мы вставляем определение фолдера.

Похоже на определение мапа, только там тот андроид через кейс у фолдера, да? Мы вставляем определение фолдера, и мы его inlining определяем фактически. Что такое фолдер? Мы делаем кейс к нашему списку. Вот наш список. Это весь наш список, которым мы делаем кейс. Если const, то мы плюсуем x и потом вызываем рекурсивность.

Рекурсивно. Мы просто делали inlining определение фолдера. Это ничего больше. А потом мы делаем inlining определение мапа. Опять же, мап, мы определяем мапу, как мы потормачиваемся по списку L.

Пустой список – это пустой список. А если const, то смотрите, мы применяем функцию к y, производим бета-редукцию. Поставляем y на нашу функцию, получаем y умножить на . Вот, все. А потом вызываемся рекурсивно на ys.

Окей. На текущем этапе может быть непонятно, что делать дальше. У нас есть кейс внутри кейса. Можно ли с этого избавиться? Можно ли сделать кейс внутри кейса, как-то его извлечь? Конечно, можно. Называется case-of-case transformation.

Он позволяет внутренний кейс сделать внешним, а внешний кейс делать на уровень глубже, короче говоря. Смотрите, внешний кейс теперь – это внутренний кейс. Вот он, кейс L и так далее. Вот, раз и два. Это ровно внутренний кейс.

Извините. А теперь, кейс на уровень глубже – это кейс по результату, по пустому списку. И дальше у нас есть опять же, вот тут написано, это ровно ой, это разные фрагменты. Вот это ровно эта вещь, этот фрагмент кода и этот фрагмент кода. Он дублируется.

Опять же, мы внутренний кейс сделали внешним. И тут можно заметить одну классную вещь. Видите, кейс пустой список, of и дальше кейсы. Если заглядывать немножко в операционную семантику, вот она обычно определяется для языков программирования, small step semantics. Когда мы делаем кейс, и у нас уже паттерн совпадает моментально.

Вот как тут у нас паттерн совпадает, кейс пустой список, of пустой список. Вот тут паттерн совпал. Мы возвращаем ровно тот бренд, который соответствует пустому списку. Это логично. Поэтому этот вот кейс редуцируется, то есть один шаг в small step semantics в нолик.

Опять же, логично. Мы матчим пустой список, получаем у нас уже есть кейс пустому списку, получаем нолик. Вот и все. Аналогично вот с этим кейсом. Мы делаем матчинг по консу.

Вот конс, вот еще один конс, наш branch релевантный, x у нас просто это y умножить на . Производим шаг в нашей операционной семантике, получаем вместо этой вещи вот эту вещь. Вместо xs мы подставляем вот эту вещь map функции ys. А вместо x здесь мы подставляем y умножить на . Я все релевантные части выделил.

Мы делаем кейс по консу. Казалось бы, больше ничего сделать мы не можем. Мы сделали все, что могли. Мы проанализировали наш список внутренний l, сделали case of keys transformation, произвели шаг в семантике. И теперь смотрите, видите этот фолдер? Такой же в точности этот фолдер.

Не правда ли? Тут вместо l стоит ys. Использовать этот фолдер это нехорошо. Опять же, потому что у нас все еще есть фолдер и мэп. Все еще два траверсала. Мы хотели сделать один траверсал.

Но без проблем. У нас этот фолдер это фанк от ys. Финальная стадия это поставить реквизитное определение. Все наше правое вызов наше правое фолдер и мэп это фанк. И вот теперь наш фанк, это простая функция, ее можно было на самом деле использовать по свойствам, которые были на предыдущей лекции.

Тем не менее, фанк теперь проходится по списку единицы. Мы гранино применяем умноженное к оберегу и складываем с реквизитным вызовом. Эта часть тоже очень важна. Если мы оставим фолдер от мэпа, еще раз, у нас будет два траверсала списка ys. Что это делает фанк? Мануальный дефористейшн.

Прошу не поджаловать. Вопросы по этому слайду есть? В нашем приоритете сделать так, чтобы у нас было минимальное количество проходов по списку. Вот так, окей. А вот, да, все. Это весь пример дефористейшна мануального.

Дефористейшн, который я бы сказал автоматизированный, на самом деле. Типа того. Стримфьюжн это название типа данных, которые реализуют предотвращение формирования промежуточных, ну, давайте скажем, списков. На самом деле там списки. Вот.

Стримфьюжн работает в следующем образом. Начнем мы изучать стримфьюжн с примитивных попыток. Вот как и было в предыдущих инстанциях, мы делаем фактически один шаг. В фанке мы делаем один шаг. Помните, да, фанк, который был на слайде до этого? И там, по идее, был один шаг вычисления и регустированных вызовов.

Прикол фьюжна в том, что тут тоже один шаг фактически. Работает списка. Лист это тип данных, он принимает а, инкапсулирует функцию из списка а в мебе вот а из списка. Эта функция похожа на uncons. uncons, значит, берет голову, если есть голова, то он ставит голову и хвост, оборочит это в just, иначе это nothing, потому что в списке нет головы, очевидно.

Это похоже на uncons, то есть cons наоборот. При этом, более того, это похоже на, на самом деле, state. State transformer, я бы сказал. У нас есть стрим токенов, мы, типа, берем первый токен и оставшиеся токены и оборачиваем это в мебе. То есть мы можем закончить и тогда там будет nothing.

Вот, похоже на стрим токенов. Вот, и это один шаг. Просто что мы хотим анализировать. Окей, обработался списком. Можем ли мы генерировать map1? Попробуем, окей.

f это функция из списка в мебе. h тоже. Значит, h, так, сейчас. Да, значит, h принимаем в список f', и здесь мы придаем f' функции f, на самую функцию f в листе. Если у нас nothing.

just, мы пропихиваем функцию j внутрь нашего, собственно, первого элемента. Это не работает вообще ни в каких обстоятельствах. Как вы считаете, почему? Причины здесь много. Мне нужна хотя бы одна причина. Почему не работает? У нас по типу не сходится.

Наверное, что-нибудь по типу. Мы просто, как бы, я так понимаю, что ожидали s', это лист типа a, список типа a. А потом мы его почему-то запихнули в результат нашей функции h, хотя она должна быть листом типа списка b. Правильно, да. h принимает в список типа b, а мы передаем f в список типа b, а f ожидает в список типа a.

Да, это первое замечание, совершенно справедливо. Еще одно замечание. Вот тут функция, видите, j. Очевидно, что уже на этом этапе будет проблема. Тут type-checking не сработает.

Если еще дальше идти, вот тут функция j принимает аргумент, тут будет значение типа b, но здесь вот допустим, у меня тип список a. Тут все еще список b. Все еще, короче говоря, проблема того, что тут все слишком блин, сейчас скажу, конечно, фразу слишком однотипно. У нас везде что-то типа a, и из этого мапы не сделать никаким образом вообще. Он невозможен.

Ну, возможно просто сделать тогда здесь этоморфизм из a в a, тогда без проблем. Но это тогда не мапа, это тогда я не знаю, номов какой-то, припов какого-то мапа. Хочется, чтобы у нас мап был ровно таким же, ну, каким, какой ожидается. Поэтому эта наивная реализация Stream Fusion не работает, которая one-step. Но вторая версия работает нормально.

То есть мы для этого, для этой фигни можем сделать однозначно мап просто потому, что вот это уже, вот это уже, это state. У нас вместо состояния это stream, вместо monad это maybe, и b это наше значение, которое меняется. У нас будет тогда функция с b в c, лист a в b, ссылка лист a в c. Очень элементарно. И наш stream имеет один тип, и он не меняется.

Окей. Есть еще проблема. Когда мы обрабатываем список, мы хотим иметь информацию о изначальном списке. Да, мы хотим иметь в владении то, с чем мы работаем. Вот у нас как бы есть один степ.

Что-то, что представляет один степ. Но сам список тоже был. Давайте мы добавим. Добавили список. Теперь это не new type, а data.

Отлично. Потому что у нас есть два поля. Все. Добавили список. Текущая проблема реализации в том, она уже нетривиальная.

Нужно немножко подумать. У нас есть функции, работающие с списком, которые могут изменять наши части списка. Голову, хвост и так далее. Но maybe это слишком строгий тип. Слишком ограниченный.

Что тут говорит maybe? Maybe говорит о том, что у нас есть либо как голова, так хвост, либо ни голова, ни хвост. Вспомним фильтр. У нас фильтр может отбрасывать элементы. Голову, да, и возвращать хвост. То есть фильтр, один степ в фильтре, это кейс тот самый, в котором есть хвост, но нет головы.

Maybe это не инкапсулирует никаким образом. Maybe, опять же, это либо голова и хвост, либо ничего. Поэтому нужен другой тип. Не maybe. Который допускает только хвост, но может допускать голову.

Это первое замечание. Второе замечание. А нужен ли нам тип нашего прям железный тип нашего стрима, нашего списка? То есть нужно ли его здесь передавать? Я бы сказал, что нет. Я бы сказал, что его можно абстрагировать. Я бы сказал, что его можно квантифицировать с помощью for all.

StreamFusion – это вот этот вот тип данных. Он экзистенциальный. Тут стоит for all перед стримом. Сейчас я объясню немножко. Это будет потом в лекции 2010-й.

Не помню. Чуть-чуть объясню про экзистенциальный тип. for all s. Называется экзистенциальный. Давайте я его скопирую на всякий случай и создаю в блокноте.

Быстренько. У стрима тогда, если узнать тип стрим, именно у концентра данных стрим, будет иметь тип for all s. s, стрелка step, s, а, стрелка s, стрелка, стрим, а. Вот его тип. Ровно такой тип будет у стрима.

Я не знаю, обсуждали ли вы с Дмитрием Юрьевичем Штукинбергом на матлоге способ трансформации экзистенциального, квантера for all в квантера exists. Но давайте я сейчас вместо этой стрелки сделаю коррирование и поставлю Я объясню, почему я так делаю. Сейчас, видно, запятую. Я делаю коррирование. А теперь смотрите, что делает for all s? Он зажирает все, что есть справа.

Опять же, не знаю, обсуждали ли вы это с Дмитрием Юрьевичем Штукинбергом. Мы сказали, что for all x. phi сделка psi эквивалентно Я поставлю его таким вот образом, чтобы было понятно. Эквивалентно Господи! Ой, что происходит? Все в порядке. Эквивалентно exists x.phi сделка psi.

Внимание, сколько теперь станет вот таким вот образом. То есть, тут for all сожрал всю аппликацию, а тут x. phi сожрал только аргумент. А вот теперь я применю этот трюк. Причем, более того, этот трюк вспоминаемый интуитивной логикой.

Этот трюк конструктивный. Он оказывается, например, в коке, или в вине, или в аксе, или в баронде, или в индресе, неважно. Оказывается, это конструктивный факт в интуитивной логике. Давайте сделаем теперь то же самое со стримом. Что у нас имеется, stream, и тут стоит x.

phi и s. Скобки теперь стоят вот таким образом. Вот так вот. И вот так. То есть, стрим принимает тип, он принимает тип, типовый параметр, и принимает дальше, собственно говоря, пару из степа, из функции, и нашего самого стрима.

Именно поэтому стрим называется экзистенциальным. Потому что вот этот фурорчик в настоящей сигнатуре стрима эквивалентен этому экзистцу. Экзистцу, при том, что его нет в Хаскеле, потому что он не нужен. У нас есть фурор, его достаточно, и так понятно, когда тип экзистенциальный, когда он стоит перед конструктором. Вот.

Экзистцу. То есть, стрим де-факто, и это на самом деле отражается в коре, в тот самый, привычный язык первой рекомендации. Стрим принимает типовый параметр, и принимает две функции, из s в степ sa и s. Поэтому он называется экзистенциальным. Вот.

Двигаемся теперь снова к стриму. А что такое стрим? Авторогируемся мы от типа нашего контейнера, нашего списка. Это произвольный s. Вот и все. Функция из s в степ sa – это наш вот один степ.

Вот. В чем прикол? Видите, мы в степ добавили skip. Вот skip – это тот конструктор, которого нам не хватало в maybe. Если мы уберем skip, у нас будет степик maybe от пары, не эквивалентный, а есть аморфен, maybe от пары sa. А skip нам нужен, он важен для фильтрации, например.

Поэтому у степа есть тренинг-конструктор done – мы завершили наш список, завершили обработку списка. Yield – у нас есть голова, есть хвост. И skip – мы пропустили гол. Это называется string fusion. Да, вот просто экстрактор, то есть это один степ в нашем стриме, один шаг в обработке нашего списка.

И сам стрим кодируется вот в таких вот двух полях нашего конструктора. Мы можем задать функции, которые приводят в список а в стрим а. Вот. Как этот список работает в стриме? Это наша функция xs. xs – это список а.

Значит, стрим принимает типовый параметр, вспоминаем сигнатуру стрима конструктора, и две функции. Раз стрим принимает типовый параметр, давайте мы передадим стриму s равен список от а. Вот и все. Теперь next имеет ровно эту сигнатуру. Функции список а в степ список а и а.

Что делает next? Next отпустил список до дал, мы закончили обработать наш список. А от конца мы возвращаем наш x и хвост xs. Вообще, в принципе, это похоже на генератор. Он не является генератором в Python, очевидно. Типа похож на него.

Типа того. У нас есть шаг, который генерируется степ бай степ, и это все такое прикольное. Мне кажется, генераторы там хрустово представляют. А тут просто стрим фьюжн. Не суть, I digress.

OnStream принимает стрим а, возвращает список а. Здесь, конечно, стрим принимает типовый параметр и next он полиморфный. То есть next имеет функции из s в степ а. Вот наш next. Но давайте, собственно говоря, просто вместо s, опять же, поставим список а.

Ой, что? Сейчас. А, нет-нет. Sorry, я сейчас подумаю. Да, я тупой. Нет, next это все еще список господи, функции из s в степ с а.

s0 это все еще s. go это наша рекуссивная функция, которая будет обрабатывать следующую вещь. Face s0. Тот самый стрим, который мы сохранили, потому что, собственно, сама информация о нашем стриме, она важна. Итого, go определяется таким образом.

Мы смотрим на наш шаг, один шаг. Если мы закончили обработку, мы делаем пустой список. Без проблем, очень просто. Если у нас есть skip, то есть мы пропускаем какой-то ребят в нашем стриме, то мы просто вызываемся рекуссивно, пишем go. А если у нас есть yield, мы добавляем явно a с помощью конца и рекуссивно вызываемся go.

То есть работает go так, как мы ожидаем. Мы проезжаемся по всему нашему контейнеру, нашему s, а s это просто что-то. Вот. И строим список, исходя из результатов next-ов. Каждый раз, когда мы вызываем go, вызываем next.

Next со next-ом. Мы строим список обратно. Вот. Это и есть unstream. Вопросы по этим функциям? Если у вас есть, то я слушаю.

Окей. У нас есть очень простые функции, наподобие мапа и фильтра. Начнем с мапа. Функция next это функция из s в степ s a. Функция next-это функция из s в степ s b.

То есть s не изменяется вообще. А next-зависит от next-а. xs имеет тип s, очевидно. done, done, skip s, ничего интересного. А вот yield мы возвращаем f a.

То есть мы пропихиваем функцию f для аргумента a. И не изменяем этот стрих. Ну, потому что, опять же, это просто отдельный степ. Главное узнать, что происходит с этим значением. В нашем стриме.

Фильтр. Теперь важно. У нас есть предикат. У нас есть стрим next-s. Next опять же функция из s в степ s a.

Next опять же зависит от next-а. Первые два случая абсолютно они, конечно, информативные, но они тривиальные. Еще внимание на yield. Допустим, next в нашем стриме вернул a. Применяем предикат a к p.

Если a p от a true, то мы сохраняем его. Иначе мы пропускаем его. Здесь вот skip важен. В этом случае мы используем и ignore нашего элемента. Мы продолжаем обрабатывать наш оставшийся стрим.

И это отражается в том, что у нас есть skip здесь. Я подумал сейчас мгновенно. А если у нас есть в том самом определении, в том третьем, если вместо b поставить maybe b? Что будет работать? Да, будет. Ничего себе. Можно, конечно, поставить maybe b, тогда это будет почти из аморф в стриме.

Но тут слишком много всего. Maybe от maybe некрасиво. Эти конструкторы в степе говорящие. Лучше использовать просто стрим. Короче, рекомендую попробовать folder s, который как фолдер, только тут стримы, а не списки.

На доступе, если вам удастся, это будет здорово. Релизовать фолдер через стримы, на основе стримов. А теперь map, который на списках, обычный, это композиция. Map применяет f. Stream делаем из списка a, stream a.

Потом делаем map s от f, делаем от stream a, stream b. Потом делаем от stream, получаем обратно список b. Это весь map. Все. Три функции.

Unstream, map s, stream. Их можно декомпозировать. Да, фильтры тоже самое. Их можно декомпозировать. Пожалуйста.

У нас есть map show и filter even. Мы по определению мапы и фильтры поставляем вместо фильтра, фильтра s, стрим, вместо map s, стрим, вместо map s. Так. Казалось бы, у нас есть следующий фрагмент. Stream.Unstream.

Stream. Unstream это все еще вызов функции и, к сожалению, занимает память и время. Но! Мы можем от этого избавиться. С помощью так называемого rewrite rule. Rewrite rule это вот такая вот прагма, которая вставляется в ваш модуль.

Прагма rules. Дальше тут название вашей прагмы. И дальше правило. Для любого стрима... Причем именно так.

Это фактически что-то подобное... Ладно, я, конечно, сейчас скажу дичь. Но это что-то подобное того, что мы можем ввести в наших интерактивных сетах. Что-то подобное зависимости. Это не является зависимыми типами.

Это просто такой способ задать правила. Это не зависимые типы ни в коем случае. Это просто синтаксис, очевидно. Для любого стрима S Stream. Unstream это S.

Хорошо бы это доказать. Для произвольного стрима S. Это можно... Мне кажется, можно делать в тех же самых языках наподобие Coq, Lean, Acta, Rnt, Idris и так далее. Причем.

.. Наверное, я этим займусь сегодня. Это будет уликательно. Нужно параллельно доказать, что на самом деле стрим Unstream это реально стрим, из которого мы и начали. Насколько это стримерливо, я пока сказать не могу.

Честно, не знаю. Другой вопрос. Попробую сегодня это сделать на суген, в Coq. И, собственно, теперь у нас система Unstream, это будет Id, фактически, и тогда map.s.show и filter.s. even станут соседними, фактически.

Типа того. Есть package.stream. fusion, в котором это все реализовано, все эти функции, наподобие. И, кажется, вместе с rewrite. rule тоже.

ByteString – это стрим. fusion для ByteString. Так, это все? А, ну, собственно, representation автоматически. Мы переводим наш список в stream. fusion.

Делаем rewrite. rules, которые релевантны, наподобие вот этой вот вещи. И это образует differentiation, то есть избавление от состояния. Почему избавляется эмоциональное состояние? Ну, потому что у нас теперь получается прикол в одном степе. Один степ инкапсулирует один шаг.

Вместо двух шагов это один шаг, короче говоря. И, собственно, тогда мы просто включаемся в список один раз в рамках стрима, и это хорошо. Автоматизация, то есть вся главная информация заключается в этом next, в этом степе. Это building-блок нашего stream. fusion.

Все. Вопросы по stream. fusion, по тому, как его начать, как он будет работать, в реализации. У нас все равно, мы хотели же избавиться наоборот от лишних проходов по списку, но у нас все равно уже остались лишние проходы по списку. Какие лишние проходы остались? Потому что мы принимаем композицию map-as-show и filter-as-even.

Это два прохода по списку будут. Значит, по стриму? Да, по стриму. У нас, например, все ленивое, поэтому мы проанализируем сначала, если у нас список, например, не пустой, голову, мгновенно наша голова поставится в наш map-as-show, мгновенно результат поставится в filter-as-even, и потом мгновенно мы просто сконструируем стрим. Короче говоря, там из-за ленивости все делается мгновенно. На самом деле там стрим как бы да, он делает для нас стрим из списка, а потом просто по ленивости мы мгновенно поставляем голову из гилды или скипа в наши функции map-as, в filter-as, обрабатываем все.

Получается новый, более сложный степ, да, а потом мы делаем онстрим по этому более сложному степу. То есть это просто композиция двух степов. Двух next, да? Помните next, который был там? Просто их типа не композиция, а как бы это сказать, суперпозиция, то же самое. Нормально сказать. В общем, они вместе, да? Они не прям один, потом другой, они вместе.

Это просто будет наверное наглядно видно, если попытаться это сделать. О, кстати, тут же есть сайты которые в начале лекции, которые с пузыриками. Мне кажется, если произвести, надеюсь, что там есть саппорт экзистенциальных типов, я не проверял. Возможно, там можно привести мануальную ленивость, как это все вычисляется, да, ленивое вычисление, и посмотреть, действительно ли там проход по списку один раз происходит. Но он должен, иначе нет в общем этом смысла.

Ожидается, что там будет проход по списку один. Иначе, опять же, в этом всем нет смысла. Ну и да, я, собственно, как я уже говорил, я ожидаю, что там просто будет композиция этих вот next-ов. Более сложный next из двух составляющих. А next, что один степ, это ровно как было с тем самым фолдом, пусть да, фолдер от мапа.

Вот там один степ – это вот y на плюс регуссивный вызов. Это как и здесь, фактически. Сейчас, что тут происходит? Фигурация, потом шоу. В одном степе. Что хорошо.

Так. Все. Теперь мы поговорим про мотабельные объекты. Мы завершили разговор о strictness и performance. Немножко, я не знаю, мотабельные объекты как-то не совсем затрагивают.

Нет. Затрагивает, очевидно, performance. Потому что в некоторых мотабельных контейнерах есть процесс слайсинга. Возьмите, я под контейнера, и он за 1 делается, что прикольно. Некоторые просто тоже прикольные контейнеры, которые являются айо-рэями.

В общем, мотабельные объекты. Да, они мотабельные, во-первых, что интересно. Вот у нас есть айо-рэй. Айо-рэй – это, собственно, массив, именно массив, который живет в айоманаде. Не айоманаде, а айотипе данных.

Короче, он живет в айо. Он живет в чем-то, что инкапсулируется гипотетически нечистые вычисления. Ну да, айо потому что. Гипотетически здесь оно важно. Мы создаем new array.

Новый array создаем. У нас индексация от 0 до 100. И заполняем наш аррэй чиселками . Вот наш аррэй. Считываем в позиции 1 а, записываем в позицию 2 а плюс и считываем позицию.

Фактор позиции в нашем новом аррэе. Умеем получать, умеем записывать, умеем создавать массивы. В чем проблема айо-рэя? Довольно на поверхности эта проблема на самом деле возникает, и она устранимая, конечно же. Есть идей проблемы айо-рэя. Айо-рэя это максимально легальный аррэй, и можно пользоваться когда угодно.

Инконвиниент, так сказать. Нет идей. Он довольно прочный. Чистота? Что, чистота? Наоборот, не чистота айо-рэя. Казалось бы, да, ведь мы там что-то обновляем, мы там что-то чистим.

Проблема в том, что он живет в айо. Мы не хотим делать вещи в айо, которые могут быть не в айо, а такие есть. И, значит, просто айо-рэй живет строго в айо. И, например, когда мы делаем какие-то действия над нашим аррэем, мы не можем выйти из айо не использовав тот самый небезопасный unsafeperform-айо, помните, тот самый из айо. Чтобы достать там значение чистенькое, которое в spoiler можно сделать с помощью других типов, которые сейчас мы выясним, что они есть, делается с помощью unsafeperform-айо, что не очень хорошо.

Поэтому нужно каким-то образом от айо избавиться, или хотя бы, спойлер, это будет почти возможно, там мы избавляемся от айо, а делаем другую монаду. Не сделаем, а ее используем. Ну, в общем, есть такой тип данных, который называется st. Здесь написано, что это датам. Я только имитирую, что это stx, stmonad, проводинг, support и так далее.

А s здесь. Это так называемый state thread. Или просто состояние. st иногда называют state transformer. Внимание! Не стоит путать state transformer, который stt, помните, stt, который я даже напишу.

Важно, что я перейду к платформе, потому что я буду писать вещи, связанные с st. Мы помним, что у нас есть type state t, которое принимает состояние ma, и от этого стоит t, от run стоит t, который, что он принимает, он принимает s, возвращает m от пары. Это тоже state transformer. s, это наше состояние, тоже может быть мутабельным, оно может изменяться. Только тут мутабельность, она не фразка, а функция просто в этом плане мутабельная.

Вот. А st тоже new type, между прочим. Тут нету m, во-первых. Это тоже состояние. Называется state thread.

State thread. Да, state thread. Это thread, это внутренние вещи, там есть целая статья по st. Вот, кажется, сами напомнили Джонсона, который создал jhc, компайлер таскал, и вроде как сам таскал часть. Я не помню, где забыл.

В общем, помните ли вы, как определен IEO? Прямо как он определен, помните его определение? Оно было на слайдах лекции 6. Господи, отстань. Помните, да, IEO? Ну, так условно. Помните, что там у IEO была такая фигня, как state hash real world стрелка, такой вот страшный тупол из state hash real world, помните такого страхолюденного? Внутри определение IEO. Это был new type IEO от этой вещи.

Ну, вы живы, господа? Как вас зовут? Мы живы, но, если честно, я не помню уже такого слова. Да, в общем, IEO это реально похоже на state, IEO это state фактически. Вот у нас есть состояние, оно подблизовано магическим real world, это примитив и это магический примитив. При этом он boxed. Ой, господи, lifted.

Сейчас, я забыл, он boxed или lifted. Может быть, опа, boxed и lifted. Сейчас я потом объясню, что я имею в виду. Получается вот такая вот пара, это похоже на tuple, но когда называется unboxed tuple. Unboxed, то есть tuple представляет, что это не pointer heap object.

Помните, да, у нас, кажется, в Java и в Kotlin мы можем создавать объекты на heap s, потому что там u и т.д. и т.п. в Scala тоже. По умолчанию все типы данных, у них все представления, это pointer в какой-то heap объект. Unboxed tuple это не pointer в heap объект.

Это прям tuple, они вот типа стоят рядышком в регистрах. У меня очень много с AVM'ом, AVM-бельников это знают гораздо лучше, чем я, в тысячу раз. Но я примерно так. Там есть регистры, регистрики прикольные и т.д. Unboxed tuple отличается в том, что у него представление другое.

Это не pointer, это прям tuple. Это в памяти рядышком, короче говоря, стоит. Но это все еще tuple, все еще пара. Она обыкновенная сочетание того, что она себе представляет и т.д. Вот.

И опять что IO это вот такая вот функция. И стоит hash real world вот в пару стоит hash real world а. Внимание! st это ща я сделаю магию, скопирую то, что я тут выделил, и вместо real world поставлю s. Что такое st? st это как IO, типа того, только более общий. У нас s это наш state thread, это наше недоступное не при каких обстоятельствах типовый параметр.

Сейчас мы выясним, почему он недоступен не при каких обстоятельствах. И просто что-то наподобие такой вот функции. С одного состояния в другое, и вот наш а. Вот. Это st.

То есть IO это типа the fact and just в случае st. Это st от real world. У нас есть функция, извиняюсь, прям определенная st to IO, которая принимает st real world а, возвращает IO а. Определенно максимально просто. Достаем функцию, одну перекидываем в IO.

Вот. Итак, st. Она строгая. Строгий state transformer. О нём можно назвать state transformer.

Потому что st это реально как state. Просто s это не состояние, а это что-то параметризованное, что-то, что параметризует state hash самый, называется state thread. Вот опять то самое run state, у меня там конечно было именно run state t, она была transformer, а здесь именно run state без трансформеров. Run st, однако, вот таким вот образом. Первый аргумент это sts a, где s это призвольный тип.

Чтобы получить a, это читная функция, во-первых. Тут нет никакого IO. А во-вторых, благодаря тому, что стоит for all s именно в аргументе, именно это обеспечивает недоступность наших программ недоступность наших программ информацию о том, какой у нас state thread. Какой у нас, короче говоря, тип, который параметризует st. Он недоступен и ни при каких обстоятельствах.

Что хорошо, нам не нужна информация об s. Так же как нам нужна информация о real world. Это что-то внутрикомпайлерное и неналивантное с точки зрения нами производимых вычислений, например. Run st. Получаем sts a, возвращаем a.

У нас есть IO ref. Наверняка он обсуждался в IO. В лекции по IO на шестой лекции. Естественно, у нас есть stref. Референс, который живет исключительно в st-монаде.

st это монада, очевидно. Потому что st это state. Конечно же это монада. IO тоже монада, потому что IO это state в буквальном смысле. Но не изоморфно.

Да, это разные вещи. Очевидно. stref живет в st. Можно создавать новый strf, можно читать, можно писать, можно модифицировать. Все то, что там с IO, только это st, и это можно экстрактить с помощью run st.

Вот пример. Мы хотим заполучить собственно нашу сумму, списка. Ок. Давайте мы тогда будем уже жить в st типе данных в этом блоке, потом сделаем run st. В этом блоке нам не доступна информация о нашем s.

Никаким образом. Господи, время так летит быстро. У меня только не мало остается. Кошмар. Ок.

Давайте создадим новый strf. В нем будет жить чиселка нолик. Потом мы пройдемся по нашему списку с помощью for, underscore. Это обсуждалось в лекции по foldable. И traversable тоже.

Обе лекции. А потом мы просто модифицируем наш n, добавляем туда x. Потом просто считываем. В конечном итоге тут будет тип st, s, а. Ой, нет, сейчас.

Да. Потому что плюсик это полиморфная функция, очевидно. Вот поэтому мы вернем значение суммы в нашем списке. Более того, тут есть маленькая проблемка, которая решается уже чем-то, что в крайнем ходе данной лекции. Из того, что у нас имеются монады, это же пайнт, пайнт 1, функция 2.

Тут тоже пайнт, это же n, это n-пайнт. Это невозможно параллелизовать, потому что это просто гигантская функция. Это не параллелизуемо. В этом проблеме монад в общем случае, там невозможно сделать параллелизм. Из-за того, что это одна гигантская функция, там ничего невозможно заспрыгивать практически.

Я вам явно модифицировать какие-то строчки, чтобы сделать параллелизм. Это невозможно. Это у нас монады. Все слишком секвенциально, короче говоря. Есть инструментарий, который должен делать параллелизм.

Он заходит в данную лекцию, но это есть, это прикольная тоже вещь. Называются линейные типы. Все, двигаюсь дальше. Вопросы по этому слайду. S3 тип данных – это очень прикольный тип данных, похож на IO, опять же, тот самый.

И он эскейпабл. Именно вот из-за этой вещи. Окей, теперь у нас есть целый класс типов, который называется MRA. Для таких M, где M, внимание, это монада состояний. То есть это монада, которая, наподобие, либо стоит, либо IO.

В основном это стоит. S3, S3, S3, S3, извиняюсь. Я, наподобие, S3, не стоит, а S3. E – это тип наших элементов. A – это тип нашего массива.

A имеет вот такой comment, который я выделил только что. Именно type, arrow, type, arrow, type. То есть, например, в случае starray, starray принимает s, s – это тот самый state thread. Вот написано. State variable for the st type.

I – это тип индексируемых, короче, тип индекса, да? Индекс индексируется из класс-типов AX. AX – это подкласс орда. AX – это тоже прикольный класс типов. Обычно это int. Но это могут быть еще и пары из двух AX.

То есть можно комбинировать multi-dimensional индексацию. Тоже прикольно. Можно еще раз узнать, для чего тип M в MRA? Да, потому что у MRA есть такие функции, наподобие, как здесь, где M – это та самая монада, в которой живут значения наших arrays. Эта монада M упоминает s. Где s? А, нигде.

Ладно, короче. Эта монада M – это монада, в которой живут все мутабельные вычисления, и в основном монада st. То есть, в инстанциях MRA, если вклинать на список, вместо M будет подправляться почти во всех случаях, если не в 100%. sts. То есть M – это sts.

В очень многих инстанциях. Но тут пометризуется M, потому что вдруг там есть другое. А, внимание, вдруг там есть IO. Ну, why not? IO тоже может быть, как оказалось бы, если нам приспичить, мы можем поставить вместо M IO. Это как st, только там real world.

Вместо s. Вот. И тогда там не st array, а IO array. Так. То есть M – это монада, в которой живут мутабельные результаты.

Sorry, не мутабельные, а просто результаты мутабельных вычислений. В основном это st. Так. Да, есть st. Пойду назад, чтобы не торопиться.

st array, да. st – это наш saved thread. st i – это тип индексов и тип элементов. st u array – это мутабельный array, как st array, только для unboxed элементов. Значит, boxed – типы данных.

Это типы данных, представление которых – это pointer в heap-объект. Ну, это boxed. .99998753 – это рандомное число. Процентов всех типов данных в Haskell – это boxed типы данных. Они в основном используются.

Boxed типы данных. Но unboxed тоже есть. Unboxed – это не pointer в heap-объект. Это прям что-то в регистрике. Int – это pointer, к сожалению, в heap-объект.

Но int энкапсулирует значение типа int hash. И имеет представление, вот в регистрике это int, -битный, в регистрике. Unboxed type. Вот в чем отличие. Unboxed – не boxed.

Pointer в heap-объект или что-то в регистрике. И не только, там еще есть tuples, помните, unboxed tuples. Вот это тоже unboxed. stu.array может инстанцировать m.array, но только для очень ограниченного количества типов e. Если взглянуть на инстанцию m.array, для stu.

array e может быть либо int, либо word, либо char, либо double, либо float, либо pointer, либо функциональный pointer, fun pointer, либо stable pointer, либо там что-то еще. Очень ограниченное количество элементов stu.array может инстанцировать m.array. Только те, у которых есть unboxed representation. Может быть, да? Int, word и т. д., double, float.

А stu. array геопроизводит каких угодно элементов. Поэтому желательно использовать stu. array если вам хочется работать с нитами, там нету pointer в heap-объекте, там просто регистр и т. д.

В общем, функции, те самые re-array, которые записываются в нашей array, записывают как в writer, считывают, да, вот и я, пожалуйста, дашь этот элемент тот самый. new array, вот он создает наш a, вот a тот самый имеет kind, type, arrow, type, arrow, type. Вот, ровное. То есть stu. array может быть поставлен вместо a.

Вот так, вот так вот. Это все, да? А, да, все. Вопросы в этой части. Тут, да, довольно сложная машинерия есть под капотом, если глянуть на, опять же, там очень много используется примитивных функций с хэшами на конце года. Довольно сложно, на первый взгляд.

Еще раз. m – это монад, в котором живут все вычисления, в основном это st. s – это тот самый sv для st, тот самый state thread. i – это тип индексов, e – это тип элементов. a, вот здесь a, это тип array.

В случае stu. array, это stu.array принимающий s. Еще пару секунд. Держу слайд. А, можно вопрос? У нас функции newArray, readArray, writeArray, у нас получается newArray создает просто новый массив? Или что вот здесь он делает? Да.

Хороший вопрос. NewArray принимает пару из двух индексов, это lower bound и upper bound. Внимание, что интересно, индексы могут быть какими угодно. Мы привыкли от 0 до n-1. Ну, до n, не включая n.

Может быть, хоть от минус 100 до 100. Поэтому есть маленькая такая свобода в newArray. Эти lower, upper bound – какие угодно. Главное, чтобы они сницировали ax. Значения могут быть какими угодно.

Хоть от числа грэма до числа грэма плюс 1. Как хотите. И заполняются все эти индексы e. Одним элементом. ReadArray подсчитывает по позиции e, writeArray запихивает в позицию i элемент e.

Unit, потому что тут прикол. Можно вернуть старый элемент, то есть m, e. Но тут ничего, видимо, продуктивного не возвращает в writeArray, кроме unit. NewArray заполняет все индексы от этого i до этого i элементами этого e. Да, возвращается действительно array в m, в который производится все вычисления и только там.

Next. Векторы. Векторы похожи на array. На самом деле, вектор определен, как array. Immutable vector это просто вектор, который понимает только a.

Mutable, поскольку это mutable, нам выгнан стоит thread. То есть m-вектор имеет s в качестве параметра и, конечно же, вот это там под капотом используют очевидное st. Наконец-то! У нас индексация в векторах O, A, T. Наконец-то! Мы использовали листы на протяжении 20000 лет. Теперь мы можем использовать векторы с индексацией в constant time complexity.

Finally. Еще у векторов константный slicing. Тоже классно. То есть взять под вектор. Он константный.

Это из-за определения array. Тут написаны страшные вещи. Прим монот какой-то страшный. m-вектор еще есть класс типов. v это тот самый мутабельный вектор.

Тип. Прим монот. Сейчас я задумался. Это, короче, класс. Да, класс.

Прим монот m. Поэтому m это монот, очевидно. И у него есть примитив, который называется примитив. Да. То есть не примитив, а функция.

Тип примитива неизвестен, к сожалению. Он не прописан в библиотеке. Бывает. И прим монот, короче говоря, это фактически иерархия положенности трансформеров. То есть есть прим монот например, t, e, m.

Если есть прим монот m. То есть есть instance. Есть instance аналогичный с чукок-чукок, с господи writer t. Тут стоит w. С reader, reader t.

Тут стоит e, environment. Такой вопрос. А какой прим монот base case? Какая там база? Сможете ли вы попытаться угадать, какая там база у прим монот? Просто угадать. Это неочевидно вообще, но поскольку мы работаем с мутабельными векторами, какая база может быть у прим стоит у instance у прим стоит ой, господи, прим монота. База – это прим монот iom, а также прим монот sts.

То есть база у прим монота, базовый instance, это instance для тех типов данных, у которых есть мутабельные вычисления или iom. Ну, простейшие мутабельные вычисления, то есть более сложные. Это потом, это другая лекция. Это base case. То есть мы можем строить nested transformers, мы знаем, как строить ложные трансформеры.

Главное, чтобы там в base case был st или iom. Есть функция retry, это то же самое grow, freeze, внимание, принимает мутабельный вектор, то есть обычный. А есть ли, короче говоря, функция, которая принимает и мутабельный вектор, но возвращает в мутабельный? Есть, да. То есть freeze – это заморочить, да? Что обратно, freeze – это saw. То есть tighter, заморочить for и определённый в модуле ta.

vector.mutable. Потом из этих модулей. И да, saw делает из и мутабельного в мутабельный. То есть можно делать из одного и другого ещё без проблем. Мы знаем, что у нас есть insertion sort.

Определённо максимально просто мы вставляем x, такой готовый. Он меньше всех ловеров. Может быть, больше правильных всех рейтеров. Ой, стоп. Наоборот, он больше всех ловеров.

Может быть, меньше правильных всех рейтеров. Да, другое дело. Вставляем его. Дебилитный insertion sort. Ничего интересного здесь нет.

И он на списке, что как бы не очень. Time complexity у insertion sort, конечно же, это, как минимум, квадрат. Ну, как минимум. Здесь, наверное, даже побольше просто в том, что это копирование объектов, перекидывание концев и так далее. Неважно.

В общем, квадрат, причём, плохой такой. Да, можем сделать insertion sort на основе stu. array без проблем. Ну, вот смотрите, у нас есть тип элементов int. И индексация int.

У нас есть instance stu.array для int, у которого элементы это int. Потому что int, это у него есть unboxed representation. Это то, что находится внутри int. Сделаем то же самое, мы делаем новый list. array от нуля до, ну, от нуля, потому что мы привыкли к нулю стартовать, от list.

array-1. Я только что понял, что list. array-1 это ровно включительно последний индекс. Он включительно. Вот.

Вот всё. И получается, сейчас, да, делаем из списка int.array. int. array это stu.array. Дальше ещё, собственно говоря, мы приезжаемся по списку 1, по списку 2, у нас есть два индекса, меняем местами, ой, сейчас, да, правильно, меняем местами.

Мы запомнили курс, запомнили next. Если курс больше, чем next, мы меняем местами. Вот всё. А потом это getElements достаёт нам, как называется, список. И он начинает пребывать в monodest.

Поэтому runstyle нужно указать. Можно через вектор даже делать, без проблем. Вот, тот самый thaw. Мы делаем и мутабельный вектор, а потом делаем мутабельный вектор с помощью thaw. То же самое алгоритм, совершенно.

Тут ещё jscan. Что такое jscan? Я забыл. Функция, да? Да, это функция. Вот. Потом мы делаем freeze, потому что мы можем получить список из мутабельного вектора.

Вот он, мутабельный. И потом делаем return. Опять это всё патронно ставим. Это финалочка, да? Да, это финалочка. Мы сейчас завершим лекцию.

Запись идёт? Да, идёт. Есть много способов реализовать всякие прикольные алгоритмы в мутабельном хаскеле. Это всё очень-очень sequential. То есть, это невозможно распараллелить, потому что там всё где монады, и это очень трудно сделать. Если бы я сказал невозможно.

Наверное. Везде bind и так далее. Всё гаскофункционально, фактически. Но это возможно, да, с помощью тех самых arrays и так далее. st – это ваш друг.

Используйте его, если вы хотите сделать мутабельные вычисления и сделать escaping из них значение а, то есть чистым его, его заэкстрактить. st – это ваш друг. Можно измерять время с помощью set++, можно измерять секунды. Ещё есть такой пакетчик, который называется criterion. И в самом конце список почти всех, всё за то, что было сегодня, в том числе, между прочим, всего осталось людей.

Четыре человека, да? Три человека, окей, класс. Я уже миллион раз референшу книгу Мирана Лимбабачи «Learn the USSR for Great Wood». А тут фреск-лист обсуждается в чаптере . И все остальные, собственно, ссылочки про streamfusion, про мутабельные объекты, backup-presentation тоже можно почитать, всё доступно. Я, кстати, завершил.

Нам всем большое спасибо. Рекординг останавливаем. 