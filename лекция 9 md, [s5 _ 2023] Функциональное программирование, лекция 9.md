# Text

На сегодняшней лекции мы поговорим, как писать многопоточный код на Haskell, какие есть примитивы для синхронизации потоков, какие есть библиотеки для работы с этим, потому что работа с низкоуровневыми примитивами имеет свои проблемы, и так далее. Вот потихоньку небольшой план лекции. Сначала мы обсудим, как писать многопоточные программы в Haskell с использованием легковесных трудов. Потом научимся синхронизировать эти потоки между собой и поймем, какие в Haskell бывают базовые примитивы синхронизации. Поговорим немного об эксепшенах в очередной раз, потому что там, где обычно возникает конкуренция, возникают и эксепшены непременно.

Затем поговорим про библиотеку Async, самую популярную в Haskell для работы с многопоточным асинхронным кодом. Затронем немного такую вещь, как STM – Software Transactional Memory. Затем в конце лекции поговорим про параллелизм. Важное замечание, конкретно в рамках данной лекции, да и в принципе, насколько мне известно, по общепринятой терминологии, конкуренция – это про взаимодействие потоков между собой, по тому, как они работают с каким-то shared ресурсами, как их синхронизировать и так далее. То есть это всегда про эошный код в терминах Haskell.

Параллелизм же, напротив, это когда у нас есть какая-то чистая функция, и мы хотим ее распараллелить. Мы сначала первую половину лекции, даже большую часть, будем делять именно конкуренцией, а затем коснемся параллелизма. С параллелизмом в Haskell все весьма и весьма просто. И в конце немного затронем на то, какие есть утилиты для того, чтобы профайлить многопоточный код, если вдруг оно кому-то пригодится. Тут почему-то не грозит картинка.

Тут должна быть картинка про сравнение количества памяти, которую потребляет Haskell интернет, в сравнении с ирландовским процессом и джавовским и сишным петредом. Спойлер – Haskell интернет занимает что-то типа… Ладно, я не буду врать, сколько конкретно по памяти, но меньше всех. Уж, по крайней мере, на момент создания этой презентации это было так. Из чего мы делаем вывод? Что Haskell – довольно удобный язык в терминах уж конкретного потребления ресурсов для написания многопоточных программ. На диаграммке это можно представить следующим образом.

То, что у нас есть ядра нашего процессора, над ними идут OS-трэды, так называемые трэды операционной системы, которые непосредственно исполняются на ядрах. Над ними у нас есть Haskell легковесные трэды, или, как по-другому говорят, green-трэды, которые также есть во многих других языках. Они не обязательно один в один мапятся к OS-трэдам. То есть на одном OS-трэде можно запускать много-много Haskell легковесных трэдов. И самая мелкая, самая гранулярная единица – это так называемые спарки.

О спарках мы будем говорить, когда будем говорить о параллелизме. Спарк представляет собой маленькую задачку из fork-drawing-pool Haskell, которую мы хотим запустить в отдельном потоке. То есть если трэдов в Haskell можно наспавнить достаточно много, потому что они не обязательно один в один мапятся к OS-трэдам, потому что они достаточно легковесные, то спарки – это куда более и более мелкая единица, которой вообще можно тысячами плодить и никаким образом от этого не страдать. Ну, разберем базовую функцию в Haskell, которая нужна для того, чтобы создать новый трэд. Она называется fork.io.

Она принимает какое-то риошное действие и возвращает трэд-айди, открывает его. Что такое трэд-айди, мы поговорим немного попозже. Точнее, немного попозже мы поговорим, что с ним можно делать. Трэд-айди – это просто какой-то идентификатор конкретного Haskell-грин-трэда. Здесь мы видим пример, как можно работать с функцией fork.io.

Например, мы в мейн-функции спавним следующее вычисление, описанное do-блоком в новом потоке. В нем мы ждем одну секунду, трэд-дилей принимает дилей в микросекунду. Соответственно, тут мы ждем одну секунду, печатаем в консоль, что fork-thread awake. А в мейн-трэде, после того, как мы запустили, мы ждем две секунды и печатаем мейн-трэд finish. Замечание.

По дефолту, если мы компилируем Haskell-модуль через GHC, не через stack, не через compile, то нам нужно указывать при компиляции определенные флешки, для того, чтобы наша программа скомпилировалась для использования в многоточном режиме. Для этого нужно использовать флаг min-threaded. Также при запуске нашего экзешника, результирующего, мы должны передать туда определенные флешки. В Haskell есть вещь, которая называется RTS, или же runtime system. Это библиотека, которая линкуется по итогу к вашему объектнику, чтобы получился финальный экзекютабл.

То есть Haskell-код, как мы знаем, компилируется в машинный код, и там нет виртуальной машины, или там в отличие от Python, от JavaScript нет интерпретатора, и весь необходимый вспомогательный код, например, garbage collector или scheduler потоков, он находится как раз-таки в этой библиотеке. И когда мы запускаем нашу Haskell-программу, мы можем, начав с плюс RTS и закончив минус RTS, если мы потом еще хотим передать какие-то другие опции, перечислить опции runtime system. В данном случае мы ставим флажок минус n2, что означает, что используем два потока. Мы тут не пишем минус RTS, потому что у нас после ничего не идет. Если бы мы хотели еще передать какие-то аргументы командной строки, мы бы закончили минус RTS.

Исполнение программы довольно интуитивно на двух потоках, потому что сначала, так как у нас forked thread ждет меньше, печатается это, а затем печатается main thread finish. По дефолту, если мы опять же компилируем через GHC, без стека, без кабала, без каких-то вспомогательных еще команд, которые указаны в стеке кабала в файле, у нас многопоточность выключена. Но, тем не менее, данный код будет работать. И ваше предположение, почему, во чем будет работать, без явного включения многопоточности? И как это будет происходить? Ну, какое-то внутреннее представление языка многопоточности, наверное, происходит. На самом деле все используется.

Только в питоне был. Когда-то очень давно. Ну, в питоне все-таки, насколько мне известно, есть так называемая вещь Global Interpreter Log. И там, чтобы запускать отдельные потоки, люди исхитряются, по крайней мере, до каких-то старых версий питона довольно сильно исхитрялись. Тут же все будет, на самом деле, весьма прозаично, потому что все действительно запустится на одном потоке.

Просто будет использоваться простой шедулер однопоточный, который будет запускать действия по round robin, так называемому, то есть по очереди. Какое-то действие минимальное прогоняется у первого потока, потом у второго, потом опять у первого, потом у второго, так по очереди, используя всего лишь один настоящий поток. Поэтому, несмотря на то, что результат исполнения конкретно в данном случае не изменится, но важно понимать, что если мы явно не подключим многопоточность, при указании соответственных флажков, хаскельный код будет работать в один поток. Есть еще такой забавный спецфект. Насколько я помню, его нет дальше в презентации.

Как раз таки про то, как работает однопоточный шедулер в хаскеле. Это если мы запустим два тардана, каждый из которых будет с помощью putstrln печатать строчку, одновременно, то есть без разных дилеев, то мы будем видеть, если мы отключим буферизацию в выводе, чтобы не флаттался у нас output после конкретного куска, чтобы каждый символ выводился по одиночке. Мы увидим такую забавную картину, что выводится по одной букве из первой строки, чередуясь по одной букве из второй строки. Что как раз таки будет явно иллюстрировать то, как работает однопоточный шедулер в хаскеле. Он работает довольно тупо.

Мы помним, что строка – это на самом деле список символов, поэтому он просто будет по одному элементу от этого списка откусывать и печатать консоль. И, соответственно, если у нас будет putstrln aaa, потом bbb, мы увидим ab, ab, ab. Забавно, что если мы будем использовать оптимальные хаскельные строки, такие как текст или байтстринг, это не будет работать таким образом, потому что они представлены не с помощью списка, а более эффективной реализацией, и там они будут печататься полностью. Это было такое лирическое отступление. На данном слайде видно то, что я проговаривал минуту назад, по поводу того, что вот у нас есть хаскельный исходник, с помощью jhc мы его компилируем, получаем какой-то объект, файл с расширением .op.

Затем он линкуется с runtime-системой, которая называется libhs-rts.op. Там находится гербыш коллектор, там находятся шедулеры и другие вещи, необходимые для того, чтобы программа, которая написана вами, работала. И также это линкуется с библиотеками, например, с библиотекой base, которая подставляется с каждым исходным кодом на хаскель. И таким образом после линковки всего этого дела мы получаем executable, который мы уже можем запустить. Вот в данном случае тест является executable.

А если мы захотим вдруг в интерпретаторе хаскеля jhc запустить многопоточный код? Он запустится в отдельном потоке или в том же потоке, что и jhc, и будет так же, как раунд Робина, гоняться по кругу? Насколько я помню, при jhc можно также указывать флешки. Возможно, они выглядят по-другому, но данное поведение также специфицируется. Не могу на самом деле вам конкретно ответить на данный вопрос. Никогда не экспериментировал с запуском многопоточки в jhc. Но я уверен, что данное поведение также регулируется соответствующими флешками RTS, которые можно установить, допустим, специальными директивами, как мы ставим extension.

Через команду doi.js мы также можем, вероятно, установить какие-то опции RTS, которые нам необходимы. Но вопрос хороший. К сожалению, точного ответа на него не имею. Раунд Робин – поток работает с основным, да? Вместе? То есть с главным. Да, да.

Это будет все работать в мейн-потоке. То есть мейн-поток будет по очереди исполнять код, который мы написали здесь, то есть в самом мейн-потоке, и который мы якобы форкнули в отдельный поток. Но так как отдельных потоков у нас нет, это поток всего лишь один, мейн-поток будет исполнять по очереди действия как из первого, так и из второго. То есть если, допустим, там было бы три потока, а у нас только два потока запущены, то у нас мейн-поток бы координировал бы еще, допустим, каких-то два дополнительных потока. Мейн-поток бы уже более хитрым образом координировался между двумя.

Очевидно, какая-то доля работы падала бы на мейн, но не обязательно. То есть, если я вас правильно расслышал, вы сказали, что мейн-поток координировал бы два дополнительных, это неверно. Скорее, два потока координировали бы действия на трех потоках. Что уже, на самом деле, довольно, я бы не сказал, что нечасто встречающаяся ситуация, потому что у нас часто во всех этапах программирования есть такая вещь как трекпул, где задач всегда больше, чем потока в этом пуле. И у нас так получилось в данном случае, что у нас трекпул из двух потоков на три задачи.

Они каким-то образом зависят от шедулера и его оптимизации, и будут эти задачи шериться между данными двумя потоками. Ок. Есть ли еще вопросы? Там в чате один человек написал, что не может зайти, возможно, его надо впустить. Мне почему-то не видно. Обычно у меня всплывает такая штучка.

Давайте я сейчас посмотрю. Там справа, снизу. Multiple people want to... А, господи, реально. Почему-то в этот раз у меня не всплыл.

Обычно такая отвлекающая вещь всплывает. Может, кто-то поменял настройки митинга из коллег. Всем новоприбывшим, здравствуйте. Давайте продолжать, если нет еще вопросов. Мы пока что разобрались, как в Haskell фортнуть Thread.

Спойлер, это можно сделать с помощью функции fork.io. Тут ничего примечательного нет. Ничего интересного мы не пропустили. Давайте продолжать. Раз уж мы умеем уже плодить на токе, хорошо было бы научиться их синхронизировать.

Сейчас разберем основной примитив синхронизации потока в Haskell. Он называется mvar. mvar расшифровывается как mutex variable. Это какая-то мутабельная переменная, защищенная mutex. Сейчас разберемся, какой у нее API и как с ней работать.

Есть функция new empty mvar, которая создает пустой mvar, то есть коробочку, в которой ничего не лежит. И, понятно, данная функция, как и в случае с URF, мутабельной переменной, которая в отличие от mvar не thread safe, мы получаем наш результат в O. Мы не можем в чистом ходе создать mvar. Есть функция put mvar, которая принимает mvar какое-то значение и кладет значение в mvar. Соответственно, не возвращает ничего в URF контексте.

И также есть функция take mvar, которая берет наш mvar и возвращает значение, которое в нем лежит, обернутое в O. mvar работает следующим образом. Это какая-то коробочка, в которой лежит значение типа A. Данная коробочка может быть либо полная, то есть там лежит какое-то значение, либо пустая. Если мы хотим положить значение в коробку, которая уже полная, мы ждем.

Наш thread получится, пока какой-то другой thread не заберет оттуда значение с помощью take mvar. Наш thread будет ждать. После того, как какой-то другой thread заберет, наш thread положит и продолжит исполнять. С take mvar ситуация аналогичная. Если мы хотим взять значение из коробки, в которой ничего не лежит, мы залочимся, пока никакой другой thread не положит туда значение.

Действительно, можно представить себе в голове, как она более-менее реализована в терминах обычных mutex, которые используются в других языках. Давайте посмотрим пример, как мы можем использовать mvar. Кстати, большинство из того, о чем мы будем говорить на сегодняшней лекции, находится в стандартной библиотеке в модуле control.concur. Помимо библиотека SYNC и SAM, которые не находятся в стандартной библиотеке, control. concurrent – это base.

Также мы сегодня осветим вещи, в которых не присутствует base. Для начала мы создаем две пустые коробочки и спавним до отрыда. Первый thread ждет какое-то время и в первую коробку кладет числовое значение. Второй тоже ждет какое-то время и кладет сроковое значение во вторую коробку. Затем в данном main потоке мы ждем, пока оба из потоков завершат исполнение.

То есть в данном случае мы заспавним эти два отрыда и здесь будем ждать, пока первый поток ждет секунду, мы эту секунду будем ждать, пока наша коробочка не наполнится. То же самое со второй коробочкой. То есть это аналог так называемого join, который есть в других языках. То есть для того, чтобы подождать, пока поток завершится. Только в Haskell работа с этим происходит через mvar и его API.

По итогу мы дождались результатов обоих наших потоков и просто выгоним их в конце. То есть take mvar, он именно ждет, пока сам mvar не поменяется или что-то не заполнится. Если вдруг будет пустая коробка, то он будет ждать, а не бросит какой-нибудь exception, что пустая коробка и я ничего не знаю, что там лежит. Именно функция take mvar будет ждать. Есть также в модуле control.concurrent функция try take mvar, которая возвращает iobull.

Получилось или не получилось взять значение. Точнее, она, помимо результата, который обернут в API, она возвращает еще boolean сложок, насколько я помню. А если в этот mvar никто ничего не положит, то поток будет ждать бесконечно долго? Да, это будет deadlock. Сейчас мы как раз таки разберем пример с deadlock и то, какие именно в Haskell есть приколюхи, связанные с этим. Действительно, если мы создадим программу, просто main.

run.do, создадим mvar и попытаемся его взять, то наша программа должна работать бесконечно. Спойлер. Рантайп система Haskell умеет детектить некоторые кейсы deadlock. В основном, конечно, самые простые. И в данном случае в Haskell будет кинуто исключение по поводу того, что у нас deadlock.

Но далеко не все случаи deadlock в рантайп-системе Haskell умеет ловить. Есть еще вопросы по mvar? Когда мы положим значение, допустим, в tm1, у нас два потока ждут tm1. У нас получится только на одном, да? Обычно это называется, кажется, честность в терминах многоточности. То есть, какой первый начал ждать, в порядке FIFO, такому и вернется. То есть, да, второй будет ждать.

Могут ли два потока одновременно изменить mvar или mvar – это thread safe? mvar – это thread safe. Чтобы изменить mvar, конечно, есть в модуле control.concurrent функция update. mvar, но на самом деле она работает через put.mvar и take.mvar. Соответственно, чтобы изменить mvar, нужно ее сначала взять, каким-либо образом изменить значение и обратно положить. Несмотря на то, что для этого есть обертка, она реализована именно так.

Давайте представим ситуацию, что два потока одновременно хотят изменить mvar. Так или иначе, какой-то первый из них возьмет и прочитает значение с помощью take.mvar из коробки. Второй в таком случае залочится, потому что, переводя на аналогию из других языков программирования, будет взят mutex на данную переменную. Поэтому второй поток будет ждать, пока первый не положит обратно, и второй возьмет уже обновленную версию. Поэтому mvar – это третий примитив.

Спасибо. Супер. Давайте продолжим. Как уже говорилось, mvar – это просто значение, защищенное каким-то mutex. И там, где обычно у нас возникают mutex в concurrency, у нас возникают и deadlocks.

Давайте разберем самый простейший пример deadlocks. Как мы уже обсуждали ранее, давайте напишем main, в котором создается mvar, и мы будем бесконечно ждать mvar. Никаких других потоков в нашем приложении не существует. Очевидно, что данный случай является простейшим примером deadlock в Haskell. В данном случае, в силу того, что рантайм-система Haskell умеет определять такие базовые кейсы deadlocks, мы не будем ждать бесконечно, а наш main поток завершится заключением, что thread blocked indefinitely in mvar operation.

Рантайм-система Haskell довольно умная и умеет распознавать такие кейсы. Но не стоит над ним полагаться. Если у вас есть менее тривиальный код, вполне возможно, что обычным reference count это не задетектируешь. Можно представить, как оно реализовано в Haskell. Мы будем просто на каждый mvar считать количество потоков, которые ее ждут, которые ждут для того, чтобы оттуда взять, и которые ждут для того, чтобы туда положить.

И если у нас не сходятся эти значения, например, один поток ждет, чтобы оттуда взять, но ноль потоков туда кладут. Очевидно, в данном случае возникает deadlock. Есть еще подобные исключения. Например, blocked indefinitely on mvar, blocked indefinitely on stm. Также есть исключение deadlock.

Я его, кстати, ни разу не видел. Это, видимо, deadlock, который возникает без использования mvar с другими приоритетами синхронизации. Но сам факт, что такие исключения для Haskell не редкость, и на самом деле оно довольно полезное. Иногда можно действительно добыть и допустить какую-то базовую ошибку, которая в рамках системы Haskell сразу отловит. С mvar на этом закончили.

И поговорим же теперь, что можно делать с значением threadId, который возвращает у нас функция forKeo. Делать можно, на самом деле, более-менее одну вещь. Можно послать исключение в данный поток oid. Делается это с помощью функции throwTo. Она принимает threadId, принимает какое-то e, которое является instance класса exception.

То есть мы исключение с вами касались на лекции про его. И ничего не возвращает. Также есть оберточка killThread на функции throwTo, которая просто данному threadId кидает исключение threadKilled. Но можно кинуть какое-то другое исключение. То есть произвольный datatype, который является instance класса exception.

Давайте разберем, как это можно делать. Мы спавним какое-то тяжелое вычисление, которое может идти потенциально долго. И хотим реализовать timeout. Такой паттерн timeout, когда мы хотим ждать максимум одну секунду. Иначе убивать данный поток.

Потому что мы не хотим ждать больше. Давайте продолжим. Соответственно, мы хотим реализовать timeout в одну секунду для какого-то действия, которое потенциально может идти больше. Что для этого можно сделать? Мы форкаем наше вычисление потенциально тяжелое в отдельный поток, запоминаем его threadId, ждем секунду. И если же секунда прошла, а данный поток не завершился, мы его убиваем.

Соответственно, если данный поток уже завершился, killThread не будет ничего делать. Для этого нужна функция killThread. Но на самом-то деле механизм забегает вперед. Немного скажу, что это называется асинхронное исключение. Асинхронное исключение отличается от обычных, которые мы с вами разбирали на лекции про ИО.

Допустим, когда мы читаем из файла, и файла не существует, вылетает исключение. И так как это исключение возникло в том же потоке, в котором мы работаем, оно называется асинхронное. Асинхронное исключение – это исключение, которое один какой-то поток бросает другому потоку. Это очень похоже на механизм сигналов в линуксе. Только вместо того, чтобы бросать какую-то чиселку между разными процессами, в нашем случае потоками, мы бросаем какие-то произвольные данные.

И на самом деле, так как мы умеем ловить эксепшены, с помощью функции throwTo можно не только убивать поток. То есть killThread – это один из видов того, как можно использовать асинхронное исключение. На самом деле, если нам очень захочется, на практике никто так, конечно же, не делает, можно с помощью асинхронного исключения реализовать полноценный механизм коммуникации между платформами. То есть можно какие-то осмысленные данные класть в наш эксепшен, кидать его в какой-то поток, в данном потоке ловить эксепшен, и как-то обрабатывать эти данные. Делать так, конечно же, не стоит, но сам факт, что механизм асинхронных исключений, он не про то, как убивать потоки.

Он про то, как посылать другому потоку какое-то сообщение, какие-то данные. А уж как этими данными распоряжаться, за это ответственный поток куда мы посылаем. На практике это куда более сильный механизм, куда более мощный механизм, чем просто взять и кинуть thread. Иногда пригождается каким-то образом с этим исхитриться. Давайте рассмотрим еще пример.

На то, как в нашем консольном приложении делать gracefully handle, то есть каким-либо образом обрабатывать осмысленно control-c, то есть seek-interrupt от пользователя. Так как это эксепшен, который летит в наш мейн-поток. Мы помним, что для того, чтобы ловить исключение, у нас есть функция catch, и также есть ее аналог, функция handle, которая на самом деле flip-catch, то есть это кетч с флипнутыми аргументами. Напишем такую функцию как inter-hander, который понимает async-exception. Давайте здесь несем ясность, что данная async-exception – это просто тип данных, то есть это просто какой-то тип суммы для популярных и синхронных исключений, которые определены в стандартной библиотеке.

Например, user-interrupt – это когда пользователь нажимает control-c в нашем приложении. Но данная async-exception и в принципе концепция асинкронных эксепшенов, которые возникают при общении разных потоков между собой – это разные вещи. Потому что мы можем создать какой-нибудь myException, который не является типом async-exception, и брать его в другой поток. Просто для удобства, для популярных, часто встречающихся асинкронных исключений в стандартной библиотеке заведем дата-тайп. Одним из конструкторов async-exception является user-interrupt, в который непосредственно конвертится seek-interrupt, который летит в наш main-поток.

Что же мы, собственно, делаем? Мы запускаем какое-то длинное, долгое вычисление в нашем main-потоке. Мы идем по числам от 1 до 1000, на каждом из них ждем секунду, и печатаем кодсоль, что завершили обрабатывать. Если же пользователь во время этого нажмет control-c, у нас работает наш handler, то есть в наш main-поток прилетит user-interrupt, и мы каким-либо образом можем этот user-interrupt обработать. Например, в каких-либо более умных случаях мы могли бы сделать clean-up каких-то ресурсов, которые наша программа аллоцировала, чтобы не было никаких утечек. Получается, в случае user-interrupt мы пишем кодсоль, что наша программа завершается, так как ее проработал пользователь, иначе мы пишем, что поймали какое-то другое асинкронное исключение.

Есть вопросы по эксцепционам, асинкронным? Да-да, слушаю. Можете сразу задавать. А ThreadId – это ID-шник потока OS или внутри приложения? Внутри приложения. В модуле control-concurrent есть функция, которая называется OSThreadId, которая возвращает IoInt или IoThreadId, которая непосредственно возвращает ID-шник OS-ного потока, на котором запущен наш ThreadId. Но ThreadId – это ID-шник конкретного легковесного green-thread-а хаскального.

Спасибо. Окей, давайте продолжать. И сейчас немного резюмируем наши знания об исключениях, которые у нас имеются из лекций про Io и из сегодняшней лекции. Для того, чтобы кидать асинкронные исключения, мы знаем, что существует две функции. Есть функция throwIo, которая кидает исключения в Io-шном коде.

И есть функция throw, которая кидает исключения в чистом коде. Например, throwIo используется в стандартной библиотеке, в функции openfile, которая реализована через какой-то C-шный код. Нам это не важно. Абсолютно. Мы видим, что здесь используется функция throwIo, которая кидает какое-то Io-шное исключение.

В случае, допустим, деления на 0, мы кидаем чистое исключение, потому что в чистом коде мы также хотим уметь кидать исключения. Для этого существуют функции throw и throwIo. Может ли мне кто-нибудь напомнить, какие функции бывают для того, чтобы ловить исключения? Handle на предыдущем слайде. Handle и catch. Да, Handle и catch.

Они Io-шные или чистые? Handle равно-равно catch. Можно с точностью до перестановки аргументов. Давайте рассматривать catch. Это Io-шная или чистая функция? Io-шная. Отлично.

Теперь давайте пофилософствуем над вопросом. А если же мы хотим... Вот у нас есть какой-то чистый exception, допустим, в случае деления на 0, и мы хотим в чистом коде обработать наше исключение, то есть деление на 0. Но функции для того, чтобы это сделать, нет. Есть всего одна функция для того, чтобы ловить исключение.

Это catch. Вопрос, а как с этим жить? Правда лишь, что если вся логика моей программы чистая, я не могу поймать исключение. Видимо, это значит, что у вас деление на 0 захардкошено в исходном коде, вы его не снаружи получили. Значит, с этим уже поздно что-то делать. Поздно ловить, нужно в другом месте исправлять.

Ну, давайте возьмем какие-то более хитрые случаи возникновения чистых исключений, которые у нас появляются в чистом коде. Но я хочу в своей программе его словить, чистое исключение. Но проблема в том, что у меня вся программа чистая. Представим, что логика всей моей программы чистая. Я не могу словить исключение.

Правда ли? Тут в моем вопросе есть небольшой подвох. Просто он довольно сильно открывает глаза, этот вопрос на происходящее. Хотел бы, чтобы указали на подвох. Кажется просто, что если у нас летит исключение, значит у нас, скорее всего, какое-то нечистое действие. Максимум, что мы можем сделать из чистого такого, что бросит нам исключение, это как раз-таки какая-нибудь именно логическая ошибка, которую мы просто сами должны ручками отхандлить.

Например, разделение на ноль – это просто заефать. Если, условно говоря, что-то еще происходит, что-то очень страшное, то это просто заефать или вынести в отдельную функцию. Ну, это как опция. Я согласен. На самом деле функции error и undefined, с которыми вы хорошо знакомы, они реализованы через функцию throw.

Допустим, функция error реализовывается через throw, так называемый error call. Это один из конструкторов exception. Но хочется все-таки их ловить, и давайте уже я тамить не буду. На самом деле подвох в моем вопросе заключается в том, что вся моя программа не может быть чистой. У меня точка входа в программу – это main, который так или иначе ушли.

Поэтому если уж мне очень хочется поймать exception, который я кинул в чистом коде, я это могу сделать только в ближайшем иошном коде, который вызывает мой чистый код. В хаскале по-другому никак. То есть в чистом коде нельзя ловить exception, только в иошном. Но в крайнем случае, если уж нам очень хочется, в любой программе есть иошный код – это main, и там мы можем поймать исключение. Вот в этом суть.

А если в программе нету main? Допустим, если вы пишите библиотеку, так или иначе вы будете ее использовать в конце концов в каком-нибудь экзекютабле. И там есть main. Если же вы пишете библиотеку, в которой нет никаких иошных функций, допустим, это библиотека для арифметики, где трудно себе представить ее, то действительно поймать exception, который вы кидаете из этой библиотеки, можно только в программе, которая импортит вашу библиотеку в ее main. Ну или в другой ее иошной функции. Но мы здесь рассматриваем программу в хаскале непосредственно как полноценное приложение с точкой входа.

То есть написание библиотек на такие вещи мы не делим. Потому что так или иначе вашу программу плюс чью-то библиотеку можно рассматривать как одну программу. Окей, давайте пойдем дальше. И сегодня мы с вами изучили еще один способ бросать исключения. Это функция throwTool, которая бросает асинхронные исключения.

Важная ремарка, что с точки зрения рантайм-системы хаскаля, эксепшены синхронные и эксепшены асинхронные оба представлены type-классом exception. То есть нет никакого различия для рантайма хаскаля, является ли данный эксепшен синхронным или асинхронным. Различие между этими эксепшенами сугубо семантическое по происхождению исключения. Произошло ли оно в том же потоке, то есть является ли оно асинхронным или асинхронным. Рантайм-системе хаскаля на это наплевать.

Итого, мы имеем три способа кидать исключения, два из которых кидают синхронные, одно из которых кидает асинхронные. И ровно один способ, как эти исключения ловить. Таким образом, небольшой самый нашей работы с эксепшеном. Как ловить асинхронные исключения с помощью функции handle представлена на примере. Ровно так же мы ловим наши асинхронные исключения.

Между ними никакой разницы нет. Можно вопрос? Да. А у нас исключение кидается в момент ожидания? Не совсем понял вопрос. Вы имеете в виду, допустим, исключение в контексте эмбарго, когда мы ждем какой-то mutex или что? Да. То есть в какой-нибудь Java, например, у нас исключение из потока в поток кидается в момент ожидания.

То есть thread sleep или thread wait. Какой-то такой потуз. То же самое? В Haskell асинхронное исключение может прилететь в любой момент. То есть он может прервать какую-то операцию, если она не атомарна. Когда мы пишем concurrent код в Haskell, мы должны держать в голове всегда, что во время любой нашей операции нам может прилететь асинхронное исключение, которое нам по-хорошему бы обработать в терминах очистки ресурсов.

То есть просто навесить хендлер на нашу программу. Допустим, когда мы открыли файл, во время того, когда у нас файл открыт, нам может прилететь асинхронное исключение. Если мы не повесили хендлер, наш поток просто умрет. Вот мы никаким образом не заглянапали ресурсы. Поэтому в Haskell дело стоит так, что абсолютно в любой момент исключение прилетает.

Понял, спасибо. Давайте разберем немного примеров с исключениями. Как их можно кидать и как их можно ловить. Первый пример достаточно простой. Мы с помощью функции throw его кидаем какой-то myException, который мы определили и реализовали для него instanceException.

Мы его кидаем, сразу же ловим с помощью функции catch, и печатаем в консоль, что мы поймали эксепшен. Здесь все довольно тривиально. Затем разберем чисто эксепшен и, допустим, деление на 0. Здесь мы используем функцию when. When, как мы помним, это монетическая функция, которая принимает какое-то условие и выполняет действие, если это условие верно.

Если это условие не верно, ничего не выполняется. Иными словами, происходит return в пустой скубочке. Это просто такая обертка на default в бенче else в пустой скубочке. Таким образом мы форсим данное выражение вычислиться до слабой головной нормальной формы, чтобы проверить, истинно или ложно условие. Ловим исключение с помощью функции catch.

В данном случае бросится исключение типа it's exception, а именно его конструктор divide by 0. Мы его ловим и печатаем в консоль, что поймали, также с помощью функции catch, уже чистое исключение. И в конце концов разберем, как кидать и как ловить синхронные исключения. Соответственно, мы форкаем какое-то вычисление в отдельный поток, в нем мы ждем, и печатаем в консоль, что дело сделано. И навешиваем на это действие хендлер.

То есть этот хендлер относится к этому действию. То есть он идет после форкового. Точнее, он относится к действию, которую мы форкнули в отдельный поток. В catch мы также ловим наш myException и печатаем, что мы его поймали. Ждем какое-то время, меньшее, чем на что это работает, и кидаем myException на стред.

То есть здесь просто для примера было разобрано, что API для работы для того, чтобы кидать и ловить синхронные исключения, довольно похож. То есть ловим мы их все одинаково, а кидаем просто используя разные функции. То есть интерфейс exception в Haskell более-менее унифицирован. Если есть какие-то вопросы по исключениям, давайте, иначе пойдем дальше. Супер, видимо, нет.

И поговорим про сложности и трудности, которые у нас бывают во время очистки ресурсов. Представим себе такой код. Наш main – это какое-то действие со следующим handler. То есть мы ловим какой-то произвольный exception. Кстати, напомнит ли мне кто-нибудь, как в Haskell, используя функцию catch, можно поймать абсолютно любой exception? То есть здесь мы видим, что мы матчимся по myException.

Это значит, что функция catch, сигнатура ее хендлера, то есть сигнатура ее второго аргумента – это myException, стрелка и о, пустые скобочки. А как нам поймать любое исключение? То есть любое значение является представителем класса типа catchException. Мы это разбирали на лекции про EO. Можно-то, по-моему, ловить catchException. Проблема в том, что exception – это declass.

Создадим класс, который является instanceException, это exception и что-то такое. Мы здесь писали раньше чуть выше instanceException, myException, только теперь мы сделаем instanceException, exception его назовем, и все. Это ничем не будет отличать. Во-первых, конфликта имен у вас, кажется, все-таки не будет, потому что это type класса, это data type. Потому что в худшем случае у вас будет здесь конфликт нейминга, но в лучшем случае у вас абсолютно ничего не изменится, потому что ваш exception отличается от myException только именем.

То есть мысловой нагрузки оно не несет. То есть exception – это не какое-то магическое слово, которое позволяет в Haskell ловить произвольные исключения. Давайте, если никто не помнит, я немного напомню, что у нас есть такой data type, который называется someException. Сейчас напишу в чате. Это коробочка, которая умеет содержать внутри себя любое произвольное исключение.

И у нас в type классе exception существуют функции fromException и toException. И с помощью функции fromException можно привести someException, то есть какое-то произвольное исключение, мы пока не знаем, какое. То есть какое-то наше исключение, которое лежит в коробочке. Мы с помощью функции fromException можем попытаться скальфить это произвольное исключение к нашему. Можно с помощью функции fromException попытаться привести someException к myException.

Функция fromException разрешает maybe. То есть либо нам удалось распаковать someException, и там лежит то, что нам нужно, либо там лежит что-то другое. В данном случае нам вернется nothing. Таким образом, если мы хотим в нашей функции поймать произвольное исключение, но каким-либо конкретным образом обработать, допустим, fileNotFound и divideByZero, условно говоря, мы ловим someException, пытаемся достать из него arithException, то есть divideByZero. Если нам удалось, мы каким-либо образом в специфичном обрабатываем.

Затем, если нам не удалось, мы пытаемся достать оттуда ioshnyException pro fileNotFound. Если нам удалось, мы каким-либо образом чистим ресурсы или делаем что-то еще. И в каком-то общем кейсе, если там лежит что-то, что нам неизвестно, какое-то произвольное исключение другое, которое нам не удалось достать, мы каким-то последним случаем это обрабатываем. В чем фундаментальная проблема? В том, что тип нашего хендлера, вот этот аргумент, он называется хендлер. То есть это обработчик с исключением.

Он должен иметь какой-то конкретный тип. Мы здесь можем ловить только какой-то конкретный exception. Допустим, myException или ourException. Мы не можем тут поймать какой-то е, который exception. И вот для того, чтобы уметь поймать что-то произвольное, придумали такую вещь, как самException.

В него runtimeHaskell умеет запаковывать исключение, которое мы бросили. Которое мы потом на стороне ловли можем распаковать. На самом деле довольно важный аспект. Если кто не помнит, я советую пересмотреть это дело, пересмотреть слайды в лекции про IO. Мы там довольно подробно на этом остановились.

Сейчас это было просто в качестве напоминания. На чем мы остановились? Мы остановились на том, какие у нас подводные камни могут быть вот в таком ходе. То есть мы запускаем экшен, ловим с помощью него какой-то exception, печатаем ошибку в консоль и делаем какой-то cleanup. Видите ли вы какой-то подвох в этом ходе? Что может быть не так? Учитывая то, что для нашей программы, представьте, критически важно почистить ресурсы. Прям очень важно.

Ошибка во время cleanup. Да, либо ошибка во время cleanup. Или, допустим, эта ошибка может быть как синхронная, так и асинхронная. Вряд ли функция printError умеет кидать синхронное исключение, по ее логике, если мы ее нормально написали. Но вполне возможно, она может произойти асинхронное исключение.

Давайте попробуем сделать так. Но на самом-то деле, если присмотреться, лучше не становится. У нас возникает бесконечная лесенка из кечей, вложенных в каждом из которых может произойти исключение. Сейчас мы разберемся, как с этим бороться. У нас есть такая замечательная функция mask.

Вообще, существует две вариации функции mask. Есть функция просто mask, она более сложная. Мы разберем более простой случай, mask с нижним подчеркиваем. Это функция, которая принимает какое-то иошное действие и оборачивает его таким образом, что оно защищено от асинхронных исключений. То есть, в данном случае, пока наше действие замаскировано, если можно так выразиться, то его не может интерактнуть асинхронные исключения.

То есть, мы намеренно преграждаем, как будто образуется очередь из исключений, если они туда летят, и перед ними ставится такое. Но если это визуализировать, то можно сказать, что мы блокируем проникновение exception в наш поток. Блокируем, чтобы наш exception прервался в поток. К сожалению, функция mask – это довольно опасная штука, потому что таким образом у нас появляется... Если же во время действия этого, которое мы оборачиваем с помощью функции mask, наша программа внезапно зацикливается, то с ней ничего нельзя делать, кроме как кинуть ей seek kill.

Потому что ни на какие асинхронные исключения, ни на всякие seek interrupt, которые конвертятся в haskell на user interrupt, она не реагирует. То есть, лучшее, что мы можем сделать с этой программой – это ее кинуть. Поэтому функцию mask нужно использовать с осторожностью. На какие-то минимальные действия, допустим, на чистку ресурсов, в которых мы точно уверены, что там не может произойти никакого зацикливания или бесконечного ожидания. Потому что если мы в отчистке ресурсов хотим ходить куда-то по сети, где возможен потенциальный тайм-аут, мы не хотим этого делать.

Поэтому для таких случаев функцию cleanup мы оборачиваем функцию mask. И если же наша функция cleanup достаточно минималистичная, то есть просто поудалять какие-то файлики или что-то еще, хотя это тоже может быть небезопасно, мы пользуемся функцией mask. Есть ли какие-то вопросы, может быть? А если исключение прилетит во время принтерора, то мы тоже должны обернуть маску? Да, можно написать. По-хорошему надо было, наверное, раз уж мы говорим о худшем случае, то действительно по-хорошему обернуть весь дублок в маску. Также потому что исключение действительно может прилететь во время принтерора, пока наше действие еще не стало замаскировано.

Можно еще раз быстренько? Что такое mask? Это функция, которая оборачивает наше действие какое-то иошное и возвращает новое иошное действие в так называемом masked state. То есть, на самом деле, если лезть по трахаронтайм-системе в Haskell и посмотреть состояние, какие бывают у потоков, он может быть запущен, он может ожидать, и вот одно из этих состояний называется masked. Это значит, что данный поток не может быть прерван асинхронным исключением. Представьте, что все асинхронные исключения, которые летят в наше действие, которые находятся под маском, они туда не долетают. Таким образом, оборачивая какое-либо действие с помощью функции mask, мы делаем это действие непрерываемым нашими асинхронными исключениями.

Какая может быть проблема? Проблема может быть в том, что если вот это действие, которое мы обернули в функцию mask, содержит в себе потенциальную бесконечную рекурсию или что-то еще, или там какое-то долгое время исполнения, если мы идем куда-то по сети, нам нашу программу становится никаким образом непрерывательным. Потому что на seekInterrupt условно оно не будет реагировать, потому что seekInterrupt представлен в Haskell с соответствующим исключением – userInterrupt. Лучшее, что мы можем сделать, и единственное, что мы можем сделать в нашей программе, это посылать туда seekKill, потому что для него нет обработчиков. Поэтому функцию mask нужно использовать осторожно, только в критически важных и минимальных местах, когда нам нужно почистить ресурсы. Вот такая мораль.

Но на самом деле, слава богу, нам не приходится в реальной жизни использовать функцию mask, потому что за нас придумали более высокоуровневые обработчики способа работы с ресурсами. Мы уже на лекции про IO разбирали такие функции, как bracket и final. Функция bracket представляет собой реализацию идиомы RAI в Haskell. Это когда мы сначала берем, acquire-им какой-то ресурс с помощью нашего первого аргумента, мы предоставляем туда какое-то действие, которое своим результатом дает нам какой-то ресурс. Например, descriptor файл или соединение с базой данных.

Вторым аргументом мы принимаем вычисления по освобождению нашего ресурса. То есть функцию из A в IO B, которая принимает наш ресурс A, который был рожден первым действием, и каким-либо образом с ним работает, закрывает его. Допустим, закрыть соединение с базой данных, закрыть сокет, закрыть файловый дескриптор, что-то в этом духе. И третьим аргументом мы принимаем вычисления, какое-то действие, которое запускается между ними. То есть мы сначала acquire-им ресурс, потом запускаем действие, потом release-им ресурс.

Функция bracket, вторая операция по релизу ресурса, на нее навежен маск. То есть в явном виде маск мы практически никогда не применяем. Потому что для работы с ресурсами, как правило, в Hustle наиболее лучшей практикой является использование функции bracket. Поэтому функция mask на самом деле просто находится под капотом нашей функции bracket, которую мы юзаем в повседневной жизни. Но мы коснулись функции mask просто для того, чтобы понять, почему именно функция bracket так хороша.

Во-первых, у нее довольно удобный интерфейс, во-вторых, она защищает нас от эксепшенов во время освобождения ресурса. Также есть функция finally, она не такая популярная, но тем не менее. Это представляет собой аналог finally блока в той же Java, только в Hustle это функция. То есть мы принимаем какое-то вычисление и принимаем следующее вычисление. Я всегда говорю про иошные действия, я всегда говорю вычисления.

Просто привычка, то есть очевидно у нас любое действие в Hustle это какое-то вычисление. То есть мы принимаем какое-то иошное действие и затем принимаем действие, которое будет выполнено после него. Даже если в данном случае будет кинутые исключения. Это literally, finally из какой-нибудь Java. То есть finally отличается от bracket тем, что у нас нет первого действия, которое дает нам ресурс, которым мы пользуемся.

Ну и да, мораль всей басни. Использование mask может быть проблематичным, с ним очень легко ошибиться и получить программу, которая становится unresponsive к каким-либо исключениям и сообщениям. Лучше взять bracket. Вторая мораль. То, что каким-либо образом пытаться восстановить состояние нашей программы от асинхронных исключений, это плохая идея.

Потому что мы помним в голове, что асинхронное исключение может прилететь всегда. То есть очень тяжело в каждом моменте нашей программы, на каждой строчке нашего кода думать о том, а как же мне восстановить мое состояние от асинхронного исключения. Всегда делаю так. Если нам прилетает асинхронное исключение, мы просто чистим ресурсы и выходим нафиг. И ничего больше не делаем в нашем потоке, пусть это асинхронное исключение его убивает.

С этим становится жить намного и намного проще. И последнее, о чем мы уже проговаривали с вами. То, что асинхронные и синхронные исключения в трехчетверении runtime системы Haskell не различимы. Если же мы хотим, чтобы они были различимы в терминах хотя бы типов данных. Вот, например, помните, у нас был UserInterrupt, который завернут в AsyncException.

Где же он был? Где-то он был. Вот этот DataTypeAsyncException определен не в стандартной библиотеке, а в пакете SafeExceptions, который не дает ничего принципиально нового, а просто нужным образом классифицирует эксепшены, часто встречаемые для того, чтобы было удобнее их ловить. Вот такая общая басня работы с эксепшенами в Haskell. На первый взгляд кажется, что эксепшены в Haskell это что-то очень непонятное и странное, но на практике это довольно удобно. Также можно почитать какой-то блог-пост, насколько я помню.

Да, это пост на fpcomplete про исключения, довольно хороший. В свое время его читал. Есть ли у вас какие-то вопросы по исключениям? А мы вообще вот именно mask, который без underscore мы будем где-то в курсе использовать? Или это слишком опасная вещь для нас? Я бы сказал, что не будете использовать. Даже mask, который с нижним подчеркиванием, вам вряд ли пригодится. Поэтому в какой-нибудь домашке у вас будет работа с файлами, или, допустим, на практике у вас были таски для работы с файлами, там можно использовать bracket условный, и это вполне себе ок.

Таски на многопоточность, я надеюсь, у вас будут в этом году в домашках, но там mask не нужен. Окей, давайте продолжать. Продолжим со слайда, который имеет довольно интригующее название. Никогда не используйте форкуео. И сейчас мы разберем, почему форкуео – это достаточно низкоуровневый примитив, и почему, используя форкуео, можно довольно легко выстрелить себе в ногу с помощью такого примера.

Давайте заведем функцию, которая называется async. exec, которая будет принимать еошное действие и возвращать результат нашего еошного действия, обернутый в mvar. То есть мы принимаем какой-то action, создаем пустую коробочку, запускаем наш action и кладем его результат в mvar. И возвращаем mvar. То есть это на самом деле обертка над boilerplate, который раньше у нас был, если мы запускали поток.

Помните, у нас была функция, когда мы разбирали mvar, мы там для каждого из потока писали такой boilerplate. Сейчас мы его просто абстрагировали в отдельную функцию. И таким образом сделали удобный примитив для того, чтобы исполнять наше действие асинхронно в отдельном потоке и возвращать его результат. Потому что форкуео так делать не умеет, для этого нужно делать mvar, что мы, собственно, и сделали. И запускаем параллельно два действия.

Первый из них кладет в первый mvar результат, второй из них кладет в второй mvar результат. Затем удобно с помощью аппликативов достаем результат в пары. То есть мы могли, как раньше, res1 достать с помощью takemvar, res2 достать с помощью takemvar, все это переместить в пару. Но зачем, если это можно сделать с помощью конструктора пары, поднятого в аппликативы. Довольно удобно.

Таким образом у нас получается пара из результатов двух наших действий, которые выполнены асинхронно. И мы выводим в консоль эти результаты. Что же может пойти не так, по-вашему, зная о том, что после того, как мы с вами порядка минут говорили об исключениях? Логично, бросится какое-то исключение. Конкретно в данном случае никакое исключение не бросится, потому что наши действия, которые мы исполняем в потоках, довольно тупые. То есть мы просто ждем и возвращаем какое-то значение.

А вот что, если действия у нас будут какие-то умнее? Например, действия будут более интеллектуальные, с какой-то более сложной логикой, которая чисто в теории может бросить exception. Будем делить на 0. Да, если в начальном потоке что-то бросим, то основное, похоже, никогда не дождется. Да, все верно. Потому что представьте, что во время нашего экшена, допустим, мы бросим myException во втором потоке.

Таким образом, мы в нашей функции asyncExec, когда запустим действие forClose, наш поток, в котором исполняется вот это действие, просто умрет, и мы никогда не дождемся того, что putMvar отработает. Таким образом, мы вернем пустой mvar. То есть функция asyncExec вернет пустой mvar для второго действия. Соответственно, данный mvar будет пустой, и мы бесконечно заблочимся. Собственно, это мы и увидим.

И, конечно же, абсолютно не хочется, чтобы такое происходило. Потому что мы хотим как можно меньше париться о синхронизации потоков при наличии исключений, о потенциальных дедлоков, и хотим иметь какие-то более высокоуровневые примитивы для удобной работы с многопоточностью и эксепшенами. Для этого у нас существует библиотека, которая называется async, в которой уже есть функция, которая называется concurrently. Сейчас мы ее разберем более подробно. Concurrently принимает два иошных действия, исполняет их параллельно и кладет результат в пару.

И в библиотеке async все спроектировано так, что если вылетает какой-то эксепшен в одном из наших дочерних потоков, он перепробрацивается в наш main поток. Что довольно логично. Потому что мы, если запамнили какой-то поток, мы потенциально хотим знать, что если что-то в том потоке пошло не так. Потому что если мы используем farqua, нас абсолютно никто не предупредил о том, что наш дочерний поток умер и наш mvar всегда будет пустым. В случае библиотеки async это не так.

Таким образом, здесь вместо trend blocked indefinitely in mvar мы получим myException, который был кинут в дочернем потоке. Здесь мы могли его каким-либо образом поймать и обработать. Если у нас какое-то второе вычисление недосчиталось, положить на худой конец nothing и продолжить исполнение программы. Это один из пойнтов, где farqua довольно опасен для использования. Мы его разобрали сугубо в ознакомительной цели, чтобы понимать, какой самый низкоуровневый примитив в Haskell для спавна потоков.

Но в реальной жизни им никто не пользуется. Давайте уже разберем библиотеку async. В принципе, в простых кейсах использование библиотеки async можно ограничиться буквально двумя функциями. Это функции concurrently и функции race. По их названиям и сигнатурам довольно интуитивно понятно, что они делают.

Функция concurrently берет два иошных действия и запускает их параллельно, возвращая результат в пару. Функция race берет два иошных действия и возвращает изр из ab. То есть она возвращает результат того действия, которое завершилось первым. Что также бывает довольно удобно. И с помощью farqua нам придется градить целый огород, чтобы это сделать.

А уж тем более, чтобы это все работало при наличии асинхронных заключений. Вообще, библиотека async, помимо этого всего, в отличие от farqua, вот эти функции спроектированы таким образом, что наше ио-действие умеет возвращать какой-то результат. Что уже довольно большой прорыв, потому что функция farqua, как мы помним, принимает иошное действие, которое не возвращает результата. И нам приходилось ручками писать boilerplate, которое создает embar и кладет результат. Библиотека async делает это за нас.

Также библиотека async человеческим образом поступает с exception, интуитивно понятна программисту, в отличие от нативного использования farqua. И также в библиотеке async есть множество примитивов полезных, которые мы сейчас коротко коснемся, для более тонких моментов обработки состояния наших асинхронных вычислений. Но пока что остановимся на функции concurrently erase. Давайте создадим функцию worker, которая принимает какой-то int, будет ждать какое-то время, зависящее от нашего int прямо пропорционально, и возвращать n квадрат. И с помощью функции concurrently можно запустить два worker параллельно.

Или же с помощью функции erase можно запустить также два worker параллельно. И тут очевидно, что вернется всегда left, потому что левый по логике нашей функции ждет меньше. Также, помимо функции concurrently erase, на самом деле функция concurrently erase является некоторым баггерсом, для того чтобы реализовать некоторые более сложные функции. То есть с помощью функции concurrently можно реализовать функцию map concurrently, которая принимает список каких-то действий и запускает каждый из них в отдельном потоке. Здесь мы понимаем и вспоминаем, что мы используем хаскельные грин трейды, которые можно также вкладить сотнями или даже тысячами, и наш программ не будет от этого плохо.

То есть сотни трейдов – это вполне себе окей. Конечно же, с этим лучше не борщить. Если на каждый чик создавать отдельный поток, перформанс нашей программы очень и очень сильно просядет. Но обработать какой-нибудь список из сотен элементов в параллель ничего нам не мешает сделать. Для этого существует функция map concurrently.

Но для того, чтобы моделировать какие-то кастомные условия, многопоточные вычисления, мы хотим запустить три потока и вернуть пару к первым элементам, которые являются изр. Мы хотим, чтобы первым элементом этой пары был либо первый, либо второй поток. Кто из них первый завершит. И также третий поток, который будет работать с ними параллельно. Короче, какие-то более нетривиальные кейсы, которые выражаются, конечно же, через concurrently erase.

Но мы хотим иметь для этого более гибкое возможность. Или мы хотим запустить четыре потока, первый со вторым, или первый с третьим, второй с четвертым. И все это дело параллельно. Нам помогает new type, который называется concurrently. Concurrently – это просто обертка над иошным действием, который может быть скомпозирован с другими экземплярами типа concurrently, с использованием инстансов этой класса, аппликатив и альтернатив.

И на самом деле инстанс аппликатива – это то же самое, что функция concurrently. То есть она берет и оборачивает. То есть мы с помощью инстанса аппликатива можем взять и скомбинировать два наших действия, чтобы они выполнялись параллельно. То есть функцию concurrently можно легко реализовать с помощью аппликативного инстанса. Это просто мы берем конструктор пары, применяем к нашему первому действию, применяем к нашему второму действию и вызываем run concurrently, как просто разворачивая.

То есть я сначала говорил, что new type concurrently – это более общая вещь, с помощью которой можно выразить concurrently erase более удобным образом. Функцию erase также легко выразить через new type concurrently. Что мы делаем? Мы берем наше первое действие, запаковываем его в конструктор left и через альтернативу комбинируем с вторым действием, которое заворачивается в конструктор right и выполняется там worker 2000. И в конечном итоге мы распаковываем все это дело с помощью run concurrently, и у нас получается ровно то же самое, что функция erase. Но это что-то более гибкое, потому что можно легко сделать это для тюкла из трех или четырех элементов.

Или для нашего какого-то кастомного дата-тайпа, каждое поле которого вычисляется в отдельном потоке. То есть мы можем более-менее произвольным образом, с помощью двух данных инстанцев, композировать параллельное вычисление. Есть ли какие-то вопросы по этому поводу? Окей, я надеюсь, что отсутствие вопросов, потому что все более-менее понятно, а не потому что ни черта не понятно. Это один момент. То есть мы тут можем только… То есть это как бы обертка над concurrently erase, да? Скорее наоборот.

Скорее newtype concurrently позволяет… Смотрите, функции concurrently erase – это частные случаи работы с newtype concurrently. Почему? Потому что вот мы на примере явно показали то, как с помощью newtype concurrently и конструктора пары или же конструкторов изеров смоделировать данные функции. Но newtype concurrently – это что-то более общее. Представьте, что у нас есть API для того, чтобы, имея два действия иошных, либо запускать их параллельно и ждать оба, либо запускать параллельно и ждать один из них. И с помощью этого мы можем более-менее произвольную цепочку, произвольное дерево наших concurrent вычислений смоделировать.

Мы можем это сделать также с помощью функции concurrently erase. Никто не спорит. Но в данном случае это будет просто какой-то огород из пар и изеров, обернутых друг в друга. В случае же newtype concurrently мы можем использовать абсолютно что угодно. Вот здесь мы используем конструктор пары.

А представьте, что у нас есть какой-то юзер, что у нас есть какой-то datatype юзер, каждый из полей которого мы вычисляем в отдельном потоке. В данном случае мы могли бы вместо конструктора пары применить сюда конструктор юзера и запустить не два потока, а три. В случае с concurrently нам бы пришлось страдать, у нас бы появилась вложенная пара из пар, потому что первый элемент у нас один, а тут у нас два элемента, потому что мы запускаем конкурентли внутри конкурентли. Короче говоря, это более гибкий примитив для конструирования произвольных параллельных вычислений, которые могут результировать в абсолютно произвольный дататайп, какой вашей душе угодно. Просто у нас есть два оператора.

Вот такой вот для того, чтобы запустить параллельно и ждать оба, и вот такой вот для того, чтобы запустить параллельно и ждать один из них. Что после этого делать? Что вашей душе угодно. Можете собрать любое абсолютно дерево, конкурент вычислений. Получается, если бы мы там, допустим, конструктор листа применили, то мы могли бы там бесконечное количество элементов считать. Ну, оно бы у вас никогда не досчиталось, если вы имеете в виду бесконечный список взять и запустить параллельно.

Наверное, вы имели в виду произвольное количество. Да, действительно, мы можем запустить какое-то произвольное количество вычислений здесь и обернуть это все в конструктор списка. Почему нет? Таким образом реализовав как раз-таки map concurrently. Все, понял, спасибо. Ну, видимо, пойдем дальше.

И теперь разберем более детально то, что предоставляет нам библиотека Async. То есть первое, что мы разобрали, это функции concurrently erase, как самый-самый базовый API. В самых базовых случаях его может хватать. В случае, если нам нужно конструировать более сложные деревья из наших параллельных вычислений, мы используем new type concurrently. Сейчас мы будем говорить про то, если нам нужно очень внимательно следить за состоянием нашего асинхронного вычисления, которое мы запустили в отдельном потоке.

Для этого существует функция visasync, которая принимает наше иошное действие, вторым аргументом принимает функцию из так называемого async. a, которая представляет собой вот это действие, которое запущено асинхронно в новом потоке, и его результатом является тип.a. То есть это какое-то действие, которое мы запустили. Непонятно, оно еще завершилось, оно еще не завершилось. Но прикол функции visasync в том, что мы в каждый момент времени с помощью функции wait, cancel, pull, которую мы сейчас разберем, можем проследить за состоянием вычисления, которое мы запустили.

С помощью той же функции for.co и асинхронных исключений это можно было бы сделать, просто запустив в отдельный поток и пытаться до него достучаться с помощью асинхронных исключений. Спросить, как ты там вообще выполняешься, собираешься ли ты завершаться или нет. В библиотеке async, конкретно с помощью функции visasync, у нас реализован удобный API для контроля за асинхронными вычислениями, которые мы запустили. Еще раз, наше вычисление, наше действие, которое мы запустили асинхронно в другом потоке, представляется дататайпом async.a. Это просто какое-то действие, которое запущено в отдельном потоке в данный момент, которое вернет результат.

Как мы используем функцию visasync? Давайте сразу разберем на примере. Мы используем функцию visasync и скамливаем туда какое-то действие getUrl. Таким образом, наш get запрос по данному URL будет исполняться параллельно. И вот в этой функции, которая передается вторым аргументом, мы можем оперировать вот этим дескриптором нашего вычисления, которое выполняется параллельно. Мы можем его подождать с помощью функции wait.

Мы можем его отменить с помощью функции cancel. Мы можем сделать call, то есть спросить его, правда ли ты завершился. Если завершился, то ты завершился с исключением или с результатом. То есть если оно не завершилось, оно вернет nothing. Если оно завершилось с исключением, оно вернет just, left some exception.

Если оно завершилось с результатом, оно вернет just, right результат. Таким образом, у нас можно писать более сложные программы, которые оперируют действиями, исполняющимися в разных потоках. Допустим, мы хотим, чтобы наше действие не выполнялось слишком долго. Мы можем тут подождать сколько-то там и сделать cancel. Ровно так же, как мы делали с помощью функции call, но более удобно.

Итого, разбираем наш пример. У нас есть два урла. Мы хотим параллельно из них отправить get-запрос по этому урлу и получить два byte-стринга как результат. Для этого у нас есть функция getUrl. Мы используем функцию visasync.

Запускаем первое вычисление параллельно. Получаем descriptor первого нашего вычисления, которое запускается параллельно, в переменную a1. Затем сразу же мы запускаем второе вычисление в отдельном потоке, асинхронно, и получаем его descriptor. И вот, имея эти descriptors, мы можем с ними делать что угодно. Но в данном примитивном случае мы просто берем и ждем оба из них и возвращаем пару.

То есть на самом деле данная функция не несет ничего нового, ничего не делает умнее, чем конкартный. Но сам факт того, что мы, имея данные вот эти штучки типа async, могли бы делать с ними вещи произвольной сложности. В отличие от функции concurrentlyErase, где мы запустили, и бог весть, когда оно досчитается. То есть функции concurrentlyErase, как и datatype. concurrently, они про то, когда мы что-то запускаем в отдельный поток, и не хотим особо это контролировать.

То есть когда-то оно досчитается, и нам это вернется. Функции же visasync позволяют нам контролировать то, что происходит в отдельном потоке. Есть ли по этому поводу какие-то вопросы? Окей, давайте тогда продолжать. И разберем баянистый пример, который, мне кажется, каждый из вас видел большое количество раз. Представим, что у нас есть...

Можно? Можно? Один вопрос. У нас перерыв будет? Давайте сейчас немного окину глазами, сколько у нас осталось. По ощущениям... Осталось немного. Нет, на самом деле немного.

Короче, нет. Я думаю, что нам осталось где-то полчаса. Потому что самый сложный материал мы уже прошли. Я бы эти полчаса провел без перерыва, и мы бы разошлись. Как вам? Как вам такой вариант? Я больше за то, чтобы не было перерыва.

Если не будет возражающих, давайте так и сделаем. Потому что, да, несмотря на то, что у нас слайдов многовато, последние 5-6 слайдов мы вообще не будем использовать. Они есть для тех, кто интересуется. Нам осталось разобрать транзакционную память и параллельность. И все.

Если не полтора часа, я за. Да, да. Ну, давайте понадеемся, что мы все-таки закончим быстро, потому что, опять же, самые сложные вещи мы уже прошли. Давайте разберем в сотый раз пример, который вы видите уже, наверное, в сотый раз на разных курсах. Это перевод денег с одного счета на другой.

Заведем такой дататайп-аккаунт, который ERF, который представляет собой просто мутабельную переменную с значением типа Integer. ERF, который мы разбирали на лекции про EO. И заведем функцию transfer, которая принимает количество денег, account from, account to, и делает перевод денег со счета на счет. Скажите, пожалуйста, почему это плохо? Почему плохо так делать в конкретной данной реализации? Нам могут прислать исключение между снятием денег и записью на другой счет. Это валидно.

Это абсолютно валидно. Но данный пример – это такой, знаете, каноничный пример плохого конкуренции кода в отрыве от языка. Если написать такой же код на Java, будет тоже плохо. Это правда, что данный код страдает от асинхронных исключений, но это далеко не его первая проблема первостепенная. Аналогично, только вместо исключения компьютер выдергивают из розетки.

Вполне валидно. В данном коде много проблем, но та, на которую я хотел бы сфокусироваться, это то, что мы используем нетрассейт примитив для хранения денег на нашем аккаунте. Нашу функцию transfer могут запустить параллельно из двух потоков, и бог везь что, есть несколько вариантов того, каким образом будет исполнена наша функция transfer в двух разных потоках. Я уверен, что кажется на курсе Java такое было. Возможно, у вас уже было на курсе параллелок.

Такой вот пример. То, что использование нетрассейт примитивов в реализации функции transfer – это прям суперплохо. В принципе, как использование нетрассейт примитивов. А я напоминаю, что EOF – это просто мутабельная переменная. Она не ограждена мьютексом, нам не дается никакой гарантии того, что операции над ней будут атомарными.

Да, там на самом деле есть функции atomic, modify и EOF, но мы и здесь не пользуемся. То есть мы читаем и пишем в EOF. Таким образом, использование нетрассейт примитивов в Haskell и в любом другом языке программирования при написании многоточных программ, точнее, программ, которые могут исполняться в нескольких трудах – плохо. Давайте уже исправим нашу реализацию, заменив EOF на embark. И для простоты отрефакторим нашу функцию, заведем функцию debit.

Одна из них снимает, другая кладет деньги. Соответственно, transfer – это debit from и credit to. Видите ли вы здесь проблему при использовании мьютексов? Кажется, та же проблема, что и говорили до этого с ошибками. Да, она абсолютно валидна. Помимо этого, на самом деле оно звучит немного нелогично, то, что мы с вами половину лекции общались об ошибках, и теперь они нам действительно везде мерещатся.

Но я вам так скажу, что в данном коде хочется фокусироваться именно на логике программы, а не на внезапно возникших исключениях. Мы считаем ошибкой, что мы не проверяем достаточно денег для перевода. Не считаем, не считаем. Хорошо, может ли возникнуть данная программа deadlock? На самом деле может, смотрите. Как будто бы может, потому что никто не гарантирует, что мы с одним и тем же аккаунтом...

Ну, то есть промо ту – это может быть один и тот же аккаунт, и тогда они оба возьмут свою блокировку и не отдаст никто. Да, это хороший поинт. Помимо этого, есть еще представьте, если мы параллельно исполняем трансфер с аккаунта А на аккаунт Б, и с аккаунта Б на аккаунт А. Что у нас может получиться? Мы возьмем блокировку на аккаунт А и на аккаунт Б в разных функциях. Получается, вот это наш первый, который взял блокировку на А, он будет ждать, пока освободится мьютекс на Б.

А тот поток, который взял мьютекс на Б, будет ждать, пока освободится мьютекс на А. Таким образом, у нас получается такое перекрестие – deadlock. Первый поток ждет второй, второй ждет первый. Они ждут этого бесконечно. А разве так? У нас же вроде что кредит, что дебит держат блокировку только на один аккаунт и сразу ее отпускают.

У нас нигде не берется две блокировки. Смотрите, параллельно берется… Здесь, кажется, проблема в том, что у нас два потока могли… Снова транзакция с А на Б и с Б на А. В момент, когда мы сделали takeMVAR, у нас там пусто, и следующий takeMVAR, который из второй транзакции, он зависнет. Мне кажется, вот из-за этого можно deadlock поймать. Да, это справедливо.

Я, на самом деле, sorry, тут моя проблема. Я действительно не особо вчитался. Вот в такой реализации, если бы у нас реализация была не отрефакторенная, когда мы сначала берем блокировку, а в самом конце ее отпускаем, у нас действительно может быть проблема в том, что у нас заблокируется. В данном случае такой проблемы нет, но все еще мы можем получить deadlock. Как минимум потому, что у нас дебит и кредит – это то же самое.

И наш код не работает с учетом этого. Короче, хочется иметь какой-то более удобный примитив для работы с данными в многоточности, когда мы не будем париться даже о взятии и отпускании mutex. Такой примитив есть. Он называется TEVAR, который расшифровывается как Transaction Variable. И все это дело происходит в такой вещи, которая представлена FAST, LEMONADE и STM, которая расшифровывается как Software Transactional Memory.

Software Transactional Memory – это такая конструкция, которая позволяет нам исполнять некоторые участки кода, на самом деле произвольные участки кода, транзакционно. Транзакционно имеется в виду в первую очередь ATOMAR. Транзакция – вы, возможно, слышали такой термин как база данных. То, что оно должно удовлетворять свойствами ACID, ATOMICITY, CONSISTENCY, ISOLATION и DURABILITY. DURABILITY – это про то, что у нас данные хранятся на жестком диске.

Нас это конкретно не интересует, но свойства ATOMAR-ности, изоляционности и консистентности нас интересуют. Итого. На самом деле, кстати, спойлер. Вы будете конструкцию Software Transactional Memory изучать подробно с теоретической точки зрения на курсе параллельного программирования, где-то на последних лекциях. Поэтому мы сейчас не будем подробно останавливаться на том, как же она реализована.

Это выходит за рамки курса. Нас это интересует сугубо с практической точки зрения. Как применять данную конструкцию в Интерхаске. Что нам позволяет делать STM? STM нам позволяет брать произвольный блок кода, который находится в монаде STM, и оборачивать его в функцию Atomic. Что это значит? Это значит, что наш блок кода будет исполняться весь, как одна атомарная операция.

Представьте, что у нас существуют две транзакции параллельно, и вот этот блок кода называется транзакция. То есть это какой-то код, который исполняется атомарно. И изолировано друг от друга. Представьте, что у нас существует две транзакции, вызванных параллельно, которые работают над одними и теми же данными. Допустим, вот в эти же самые дебиты играть.

И данные транзакции, если во время исполнения транзакции данные были модифицированы другим потоком, транзакция умеет rollback. То есть она умеет запускаться заново на уже обновленных данных. И таким образом у нас гарантируется атомарность нашего действия. Да, это не гарантируется хороший перформанс в данном случае, потому что наши транзакции, если мы не оптимально написали код, особенно применили STM не там, где нужно, наши транзакции могут много rollback. Но зато нам не нужно брать никаких блокировок.

Мы заранее уверены в том, что весь наш блок кода, который мы обернули в функцию Atomical, используется параллельно. Итого, смотрите. Так как у нас все это дело находится в монаде STM, мы уверены, что каждая из операций кредит и дебит является атомарной. Это значит, что ничего не может произойти между вот этими операциями. Если же, допустим, у нас вот этот аккаунт с айдишником 1 был модифицирован в какой-то другой транзакции, то эта операция кредит rollback-ается полностью, потому что была нарушена консистентность.

И запускается заново на уже обновленном состоянии. Таким образом, мы гарантируем то, что у нас отсутствуют какие-либо датарейсы или какая-то недетерминированность нашей программы вследствие использования большего, чем 1 количества потоков. Таким образом, STM является универсальным решением для того, чтобы написать многоточечный код и абсолютно не думать о синхронизации. Просто STM дает нам гарантию того, что наш блок кода, который мы написали в Monado STM и который мы можем преобразить в EO с помощью функции Atomical, выполнен атомарно. Есть ли какие-то вопросы? Не может ли быть такой ситуации, когда, например, мы вызвали функцию дебит, у нас снялись деньги с счета, но вдруг после этого нам прилетел какой-то exception все же.

От какого-нибудь, например, другого потока прилетел exception, и мы не выполнили функцию кредит, и все, мы потеряли. Транзакция rollbackается. Гарантированно? Да. То есть в STM реализован обработчик исключений, который rollbackает транзакции в случае, если вы исключение не обработали. Вы можете его обработать с помощью функции кедж STM, которая на самом деле специализирована в функции кедж от STM.

Это не какая-то фундаментально новая конструкция. Вы можете обрабатывать ее каким-нибудь своим образом. И в таком случае не rollback транзакцию. Тогда уже ответственность будет на вас, как на программистов. Но по дефолту, при возникновении любой внештатной ситуации, STM транзакции rollbackаются.

Потому что представьте, что у вас есть какой-то снимок данных, изначальное состояние вашей программы, ваших данных на момент начала транзакции. И эти действия, которые вы делаете в рамках транзакции, они делаются не in place. Представьте, что вы куда-то копируете, копируете на копии данных модификации, и только если транзакция завершилась успешно, вы накладываете эти изменения на актуальные данные. То есть во время выполнения транзакции, по факту, ваши данные не модифицируются. Потому что действительно очень сложно будет восстановить состояние вашей программы, если вам где-то вот тут прилетело исключение.

Поэтому все это делается более хитро. На самом деле там даже копия не создается, в каких-то из реализаций. У STM бывают разные реализации, бывают с блокировками, бывают без блокировок, но в Haskell используется реализация без блокировок. Там все довольно хитро и продумано. У STM это очень и очень хорошая вещь.

И удобная. Для того, чтобы писать многоточечный код и вообще ни о чем не думать. А в чем была проблема предыдущего кода, который без STM? Так, давайте еще раз на нем остановимся. У нас есть функция debit-credit, которую у нас использует EMWAR. Утверждается то, что если у нас одновременно будет запущена...

Сейчас. Давайте на нее еще раз поглядим. Ну, как минимум, есть проблема того, что если у нас debit-credit вызовется, что у нас трансфер будет с одного аккаунта, то мы бесконечно будем ждать. Это первая проблема. Вторая проблема того, что у нас все еще существует дедлок, который я не могу глядеть глазами.

Он менее тривиальный, чем если бы у нас была реализация... Хотя сейчас, подождите, дайте 3 секунды подумать. С одним аккаунтом какая проблема? Мы на него положили деньги, потому что... У нас трансфер из одного аккаунта в один аккаунт. Нет, на самом деле ладно.

У нас все более-менее нормально, потому что данные действия у нас происходят последовательно. Мы берем действительно take and buy, кладем, потом берем еще раз take and buy и кладем. Это в предыдущем могли быть какие-то проблемы, насколько я понял. Я немного завис, подождите. Я настолько давно не видел этот слайд.

А если у нас from и to – это один и тот же аккаунт? Мы здесь заблокируемся на себе. Окей, давайте разберемся. Если from и to – это один и тот же аккаунт. Мы берем и запускаем debit на from. Мы берем take and buy и сразу же туда кладем.

У нас debit с кредитом не происходит параллельно. Почему мы тут заблокируемся? Две параллельные операции трансфера на одном и том же аккаунте. Две параллельные операции трансфера на одном и том же аккаунте. Мы заблокируемся, потом мы будем там ждать. Почему же? В одном потоке мы все-таки возьмем и второй поток не успеет и будет ждать.

Мы положим туда и второй аккаунт также возьмет. У нас может получиться неконсистентное состояние, что мы можем использовать debit в одной транзакции. Смотрите, каждая из операций debit и кредит – она атомарна. Но проблема в том, что у нас может произойти проблема, пока мы отпустили лог после дебита и еще не взяли ее во время кредита. То есть вот это место между строчками debit и кредит является нашей уязвимостью.

Потому что сам вот этот дублок не является атомарным. Это makes sense? Или пока все еще не ясно? Уязвимость к чему? К тому, что пока мы не выполнили... Смотрите, хочется, чтобы трансфер был атомарной операцией. Представьте, что у нас на аккаунте первом лежит рублей. Мы здесь сняли какое-то количество денег, но еще не положили.

И в это же время, пока мы сняли деньги, но еще не положили, запускается какая-то вторая транзакция параллельно, которая залезает между нашим debit и нашим кредитом и снимает еще раз деньги с этого аккаунта. И если бы у нас тут была бы какая-то сложная логика, у нас бы было бы выпрошено исключение того, что у нас типа hello, у нас нет денег. Таким образом нарушается атомарность. Трансфер предполагается атомарной операцией, которая атомарно, то есть единым действием берет и снимает деньги с первого аккаунта и кладет деньги на второй аккаунт. Но в данном случае, между тем, как мы берем блокировку на первый аккаунт и берем блокировку на второй аккаунт, у нас может залезть какой-то другой поток, который также ждет блокировку на этот аккаунт и нарушит нашу консистентность.

Но согласитесь, довольно легко представить кейс, когда между дебитом и кредитом залезает какой-то другой платеж, который нам нафиг все рушит. Только он выбросит исключение в своем потоке, наш это исключение не получит и рано или поздно сделает кредит? Наш кредит будет исполняться на неконсистентном, у нас будет неконсистентность данных. У нас делался дебит, мы хотим сразу же сделать кредит, но у нас может быть такая ситуация, что мы сделали дебит тут, а потом сделали дебит в каком-то другом потоке. В данном случае у нас данные неконсистентные, потому что мы сделали дебит с одного и того же аккаунта два раза до того, как положили туда кредит. Получается проблема только в этой неатомарности операций.

Проблемы с бейдлоками у нас нет здесь. Да, это факт. Проблем с бейдлоками, оказывается, нет. Я перепутал пример с тем, что у нас есть такая вещь, если вы помните, есть такая вещь, как в параллелках, в курсе параллелок был такой пример, когда у нас аккаунт тоже дебит-кредит, когда мы лочимся, когда it переводит jit, jit переводит it. Я почему-то не обратил внимания на этот слайд, когда готовился к лекции, думал, что это ровно тот же самый пример, но все понятно, тут deadlock.

На самом деле, нифига. Тут проблема в отсутствии атомарности. Смотрите, в том, что mutex позволяет нам действие над какой-либо структурой данных делать атомарным. Но если у нас имеется взаимодействие сразу с несколькими структурами данных, в данном случае у нас структура данных простая, это просто коробка симптомов. Но даже в таком простом случае, когда наша логика оперирует несколькими разными структурами данных, операции над каждой из которых атомарны, пусть это у нас коробки симптомов, пусть это у нас concurrent очередь, пусть у нас что-то ещё, несмотря на то, что операции над каждой из них атомарны, нам не гарантируется того, что операции над композицией фиктур данных, когда мы используем эту и эту структуру данных, то что какие-то более комплексные операции над ними являются атомами.

В этом как раз-таки основная проблема использования блокировок. В том, что в данном случае это решалось бы, как говорилось у вас в курсе параллельного программирования, грубой блокировкой. Когда мы нафиг лочим все, делаем debit-credit и потом отпускаем блокировку. Но это у нас значительно уменьшает процент кода, который исполняется параллельно. Казалось бы, это тоже тогда получится проблемой, что мы навешиваем блокировку на весь трансфер, что у нас очень мало кода исполняется параллельно, и все равно эти трансферы полностью блокируют систему, до тех пор, пока они не завершатся со своими debit и credit.

Казалось бы, почему нельзя оставить атомарными только debit и credit, и просто какую-то ксевдо-очередь создать. Если кто-то вызвал debit, значит, надо потом после этого вызвать credit. Когда-нибудь вызовем. Когда придет время, когда дойдет до этого процесса. И то, что там не атомарность операций трансфер, никак на это не повлияет.

Но вы хотите с помощью данной очереди как раз-таки обеспечивать порядок того, что после debit обязательно должен идти credit, то, что никто перед ними не залезет. То есть вы хотите исполнить debit и потом в очередь положить credit, который исполнится в следующем. На одном потоке никто между ними не залезет. На нескольких потоках, пожалуйста, пусть другие залезают, это не помешает нам. Нет, есть проблема, что если у тебя, допустим, в аккаунте 0 рублей, и у тебя происходит debit, то у тебя exception возникает.

А как раз-таки STM делает такую штуку, что он не возникнет, если операций достаточно. То есть если там кредит какой-то произошел. Если мне приходит debit, когда у меня на аккаунте 0 рублей, то явно я сам делаю что-то не так. Потому что зачем мне снимать деньги, где у меня 0 рублей. А может быть этот debit приходит, когда у вас 0 рублей из-за того, что кредит не успел исполниться.

Это уже проблема кода. Потому что по логике вашей программы, представьте, у вас есть debit-кредит и еще один debit-кредит. И они исполняются параллельно. По логике пара debit плюс кредит должна исполняться атомарно. Если у вас залезло оно вот так вот друг на друга, это проблема программы.

Потому что состояние на момент второго дебита неконсистентное. Потому что вам еще не успел прийти кредит на ваш счет. А что если в следующем дебите он также используется? И логика вашей программы рассчитывает на то, что состояние консистентное. То, что трансфер исполнился полностью, но он исполнился не полностью. Короче, по-моему, довольно очевидный момент в том, что мы хотим, чтобы как можно больше вещей в нашей программе имела инвариант атомарности.

Так намного проще писать код. Когда мы не задумываемся над тем, исполняется ли данный кусок атомарно или нет. Также очевидно, что мы сейчас поняли, что если мы используем атомарные примитивы, атомарные операции, друг за другом, это не делает всю нашу последовательность операции атомарной. Потому что так или иначе между ними может кто-то залезть. А если между ними кто-то залезает, это плохо, потому что нарушается консистентность нашей программы.

На мой взгляд, пример с дебитами и кредитами уже весьма репрезентативен. Потому что в промежуточных состояниях у нас может быть на аккаунтах лежать не то количество денег, которое должно лежать, потому что не успел дойти к кредитам. Но на каких-то более сложных примерах, я уверен, это будет еще более и более выражено. Таким образом, гол, который мы хотим достигнуть и который дает нам STM, это возможность делать любой блок-кода атомарным, просто обернув его в кейворд Atomical и исполнив. Дошли ли мы все к консенсусу по этому поводу? Или у кого-то есть еще какие-то возражения или вопросы? Вопросов вроде нет.

Окей, да, короче, я немного извиняюсь, что я действительно перепутал примеры. Думал, что тут будет пример с дедлоком. Оказывается, что это пример куда более мотивирующий на использование STM. Потому что от дедлока мы избавились путем рефакторинга. Все, супер.

Таким образом, имея наши действия обернутые в монаду STM, мы лишаем нашу программу потенциальной уязвимости того, что между дебетом и кредитом протиснится еще какой-нибудь трансфер. Потому что если же он успел протиснуться, наша транзакция просто rollback. То есть все исполняется в данном случае атомарно. Какие есть у нас примитивы для работы с STM? Во-первых, это сама непосредственно дата-тайп STM, которая является инстанцем монаду. То есть код в STM мы можем писать с использованием doNotatz, как мы здесь уже видим.

Есть переменная Transactional Variable, TWAR. То есть это переменная, которую мы используем в нашей STM-транзакции. У нас есть функция newTowar, которая возвращает нам товар, обернутый в STM, readTowar и writeTowar. В отличие от mvar, не путать, данные у нас в STM отсутствуют в блокировке. То есть STM – это код без блокировок.

У нас тут нет никаких mutex, нет никаких разведаний. TWAR, в отличие от mvar, не может быть либо пустым, либо полным. Это просто мутабельная переменная, в которой лежит какое-то значение. Ровно так же, как было с EORIOF. Если мы хотим писать какой-то более умный код в STM и самим понимать, что у нас прошло что-то не так, то есть помимо непосредственно модификации данных, модификации shared данных, которые сама STM умеет распознавать самостоятельно и rollback транзакцию.

Если уже у нас какие-то более сложные условия, допустим, семантические, когда мы понимаем, что состояние нашей программы неконсистентное, мы можем заретравиться самостоятельно. Именно в силу того, что мы можем заретравиться самостоятельно, в STM также можно заблокироваться и выстрелить себе в ногу. Вы помните изначально, когда мы разбирали exception, который умеет кидать runtime в систему Haskell, там же был exception blocked indefinitely on STM. Вот как раз и в случае неаккуратного использования функции retry можно выстрелить себе в ногу и получить бесконечную STM транзакцию. Поэтому ее нужно использовать с умом.

Но на практике очень редко хочется использовать функцию retry. Просто берем, заворачиваем наш соклодатблок Atomically, или же исполняем все это в Monodext, и мы потом вызываем Atomically, для того, чтобы преобразовать это в OOP, и чувствуем себя счастливым. Также у нас есть функция Orals, которая принимает две транзакции. Если первая из них абортится, фейлится, то исполняет вторую. Также может быть полезно при написании каких-то комплексных сценариев.

Допустим, если мы хотим взять данные из двух разных источников, первый у нас запейлился, по какой-либо причине берем из второго. Также есть функции throwStm и catchStm, которые просто специализированные версии функций throw, yaw и catch для Monodext. То есть никакой смысловой нагрузки новой там не прибавляется. Это не является еще одним фундаментально новым способом lowly exception. Это просто вещи, которые удобно использовать в Monodext.

Есть ли какие-то вопросы по остальным? Да, мне кажется странным, что она перезапускает транзакцию при изменении данных. Кажется, здесь очень легко задеволочиться, даже на нашем примере с банком. Давайте подумаем, как это сделать. Две транзакции, одна с аккаунта A на B, вторая с B на A, одновременно запустить. Первая списала деньги с аккаунта A, начинает зачислять на B, приходит вторая, меняет на аккаунте B, это видит первая, перезапускается.

Вторая снимает деньги с B, начинает записывать на A, приходит первая, видит, что ашку изменили, перезапускается. Я понял, о чем вы говорите. Перезапуск транзакций – это не такая тривиальная вещь, как мы с вами сейчас думаем. Очевидно, шедулер потоков, так же как и шедулер, он называется VSTM, это называется Transaction Manager, это механизм, который ответственный за перезапуск транзакции. Он достаточно интеллектуален для того, чтобы такие кейсы не допускать.

Он умеет давать какой-то транзакции и подождать. В данном случае, согласитесь, эта проблема решается в том, чтобы дать какой-то транзакции и немного подождать, если же идет вот такая вот зацикленная конкуренция за данную. А разве VSTM мы не навешиваем прям всю блокировку на всю операцию трансфера, так что у нас не залезет транзакция друг на друга? В VSTM у нас нет блокировок. В STM отсутствуют блокировки. Это вещь, которая реализована на других примитивах.

Одна из реализаций STM, она реализована в MPP. У вас, наверное, уже была такая тема, такая операция, как compare-and-set. Это можно сделать без блокировок с помощью цикловайл с compare-and-set. Если что-то у нас не сошлось, мы просто LBK транзакцию. Тут нет блокировок от слова совсем.

Разве мы не давляем состояние, когда у нас произошел STM, то есть мы вышли из STM, тогда мы говорим, что новые потоки не успели запускаться заново. Что сейчас? Смотрите, мы вышли из STM. Я просто не понял ваш вопрос. Да, мы вышли из STM. Другие потоки, допустим, там, в этом STM еще находятся.

Мы им говорим о том, что давайте вывести все заново, потому что какой-то там вышел, состояние обновилось, давайте заново. Совершенно так происходит. Да, это так происходит. Только мы явно никому не говорим. За это механизм STM умеет это разруливать самостоятельно.

Смотрите, если у нас есть две транзакции, которые конкурируют за данные, одна из них видит, что данные были изменены каким-либо образом. Я сам, честно признаться, далеко не знаю, как в деталях реализована STM. Очевидно, там условия не такие тривиальные, как просто данные изменены. Там выстраиваются зависимости между данными, используются более сложные механизмы. Давайте просто разбирать на примере.

Две транзакции. Обе из них оперируют какими-то shared данными. Одна из них успеет изменять эти данные. Вторая из них видит, ага, они уже изменены. Давайте-ка я rollback.

Таким любым образом у нас присутствует постоянный прогресс в нашей параллельной системе. То, что у нас не бывает такое, что обе наши транзакции рождают rollback друг друга. Одна из них всегда идет дальше, а вторая перезапускается уже на обновленных данных. И вторая может перезапуститься 2-3 раза, если у нас много транзакций. Но у нас имеется постоянный прогресс.

Отсутствует голодание. По-моему, это называется, если я не забыл терминологию параллельного программирования. Короче, все менеджируется самостоятельно. Нам, как программисту, достаточно написать doblock в Monado STM и запустить это с помощью функции Atomic. Есть ли еще какие-то вопросы по STM? Вроде нет.

Супер. Да, еще немного отвлечения в сторону. Нельзя не пропиарить, что Haskell является одним из достаточно немногих языков, где STM реализована из коробки и присутствует, можно сказать, в стандартной библиотеке. Да, у нас пакет STM, это не стандартная библиотека, но он входит в список библиотек, которые поставляются вместе с компилятором грешки. Они называются boot libraries.

Haskell называется почти стандартной библиотекой. Ровно так же, как пакет текст. Его нет в стандартной библиотеке, но он поставляется вместе с грешкой. И STM, если мне не изменяет память, есть в Haskell, есть в Rust, есть в Clojure, есть в OCaml и в Scala. По-моему, также есть какая-то экспериментальная реализация в плюсах на Monado.

Но я не уверен, что она production-ready от слова совсем. Короче, так уж вышло, и в курсе параллельного программирования вы также этого коснетесь. То есть реализация STM очень хорошо разложится на функциональную парадигму. И поэтому большинство из языков, где присутствует STM, это именно функциональные языки. Потому что там довольно просто реализовать вот такую бы нетривиальную конструкцию, как STM.

Вот такие дела. И последний на сегодня пример с STM. Про то, как использовать функции retry и or else. Давайте заведем довольно тупой трансфер, который принимает amount from to. И смотрит, что если у нас достаточно денег, чтобы снять с этого аккаунта, мы делаем debit-credit, иначе мы делаем retry.

Данный пример абсолютно не имеет никакого практического смысла. Потому что писать банк, который retry транзакцию, если там нет достаточно денег, это очень наивно. Данный пример нужен просто, чтобы продемонстрировать пример функции retry. То есть в данном случае наша данная транзакция будет бесконечно выполняться, пока кто-то другой не положит нам деньги на наш банковский счет. Очевидно, что это плохой пример реализации бизнес-логики, но это неплохой пример реализации функции retry.

Потому что обычно функцию retry нам не хочется очень часто использовать, поэтому хотелось какой-то репрезентативный, но не самый умный пример. Вот, собственно, есть. И также, если мы хотим каким-либо образом комбинировать наши тайм-транзакции, представьте, что у нас есть два товара, и хотим попытаться взять либо один из них, либо второй. А, господи, это у нас на самом деле не товар. Товар – это такая вещь, как TMVAR.

Это товар еще и с mutex, который можно использовать в Monado STM, и на который также можно лочиться. Что мы тут делаем? Мы тут пытаемся взять первый MVAR. Если транзакция у нас зафрейлилась, мы пытаемся брать второй MVAR. И оборачиваем это дело либо в constructor.left, либо в constructor.right. Честно вам скажу, видел в жизни достаточно много concurrent кода, ни разу не видел TMVAR.

Это что-то из области очень и очень странного. Ни разу в жизни не приходилось использовать этот примитив. В основном хочется использовать либо MVAR для mutex, либо товар для STM. Но такой зверек, как TMVAR, тоже существует. Также есть пакет, который называется STM Containers, в который включены реализацию concurrent структур данных MapAsset с использованием STM.

Можно с ним ознакомиться. В конечном итоге давайте подведем итоги того, что нам дают фичи Haskell при написании concurrent программ. Easier to debug. Довольно спорное утверждение, потому что в Haskell нет дебегеров. Но действительно отсутствие мутабельности во всех аспектах, то есть имение какой-то лимитированной мутабельности только в URF или MVAR, действительно делает код проще для анализа.

Но в чем точно мутабельность помогает очень сильно, так это в написании TRC в коду. Представьте, что у нас есть какой-то MVAR, в котором лежит какая-то мапа. Довольно большая структура данных, которая завернута в mutex. Почему в силу того, что данная мапа мутабельна, нам может быть легче писать TRC в код? Потому что в Haskell мы можем взять нашу мапу из MVAR и сразу же отпустить блокировку. И при этом, зная, что эта мапа мутабельна, мы знаем, что никто из другого потока не изменит эту мапу.

В другом языке программирования наивная реализация будет держать блокировку на всю эту мапу, или хотя бы на один из ее ключей, если мы работаем с этим ключом, до тех пор, пока мы полностью не осуществим нашу операцию. Потому что в любой момент до нашей мапы могут достучаться и изменить ее. В Haskell мы просто на секундочку берем блокировку, достаем нашу мапу и работаем с ней дальше. Потому что наша мапа мутабельна, мы можем взять блокировку всего на чуть-чуть и знать, что никто нашу мапу не изменит. Это такой достаточно мотивирующий пример.

Ну и классическая байка про то, что в Haskell тяжело выстрелить себе в ногу и так далее. На самом деле мы увидели, что довольно легко. Но утверждается, что в других языках не сложнее. Также у нас, если грамотно все использовать, у нас ни датарейсов, ни блокировок, если у нас используется Monado ST. Короче, если сильно не хайпить Haskell и по-реалистичному смотреть, я бы сказал, что киллер-фичей для конкуренции Haskell является то, что его потоки достаточно легковесные и то, что присутствует такая вещь, как STM, которая действительно позволяет нам очень легко писать многоточный код.

Вот это действительно является киллер-фичей Haskell в контексте конкуренции. Байки про мутабельность, это конечно хорошо, они действительно помогают, но во всех остальных языках программирования уже завезли нормальную работу с мутабельными данными. Этим никого не удивить. А вот STM из коробки, я думаю, можно много кого удивить. На этом мы с вами заканчиваем такой раздел нашей лекции, как конкуренции, который про EOS-ные многопоточные программы и взаимодействие между ними, синхронизацию и так далее.

Сейчас будем говорить про параллелизм. И поговорим мы с вами достаточно быстро. Есть ли у вас какие-то вопросы про раздел по конкуренции? Ок. Давайте тогда по-быстренькому пробежимся, как же мы можем исполнять наш Haskell-чистый код параллельно. И посмотрим, как это дело профайлить по-быстренькому и закончим лекцию.

Напоминаю, что параллельность в терминах Haskell – это когда у нас есть какое-то чистое действие, и мы хотим выполнить его параллельно. Распараллелить на несколько потоков. Для этого дела существует, вы не поверите, но отдельная монада, которая называется Eval. Это монада для исполнения параллельных вычислений. Давайте разберем, какие у нее есть функции.

Есть функция runEval, которая принимает значение в монаде A, значение комплексное, которое мы хотим посчитать параллельно. И с помощью функции runEval доставать оттуда, запускать параллельное вычисление и на выходе получать результат. И есть две функции, основные, с которыми мы будем работать. Это rpar и rsec. Функция rpar применяется в монаде Eval, принимает какое-то значение и говорит, вычисли мне его, пожалуйста, до слабой головной нормальной формы параллельно.

То есть создай отдельный спарк в своем трекпуле, для того чтобы вычислить вот это значение до слабой головной нормальной формы параллельно. В спарке, если вы помните, в самом начале лекции у нас была такая диаграммка, и у нас там были ядра, оэстроды, хаскельные троды и спарки. Спарки — это куда более мелкие единицы, которые используются как задачки, вида вычисления что-то параллельно. Есть функция rpar, которая просто берет значение и говорит, посчитай мне его параллельно. Есть функция rsec, которая берет значение и говорит, посчитай мне его последовательно, в этом же потоке, и дождись его вычисления до слабой головной нормальной формы.

Как мы уже говорили, спарк — это просто какая-то работа, которая может быть сделана, и хинт компилятору, что ты можешь сделать это параллельно. Вот, разберем, как это все дело у нас работает. Представьте, что у нас есть функция f, и мы хотим вычислить fx и fy параллельно. Что мы делаем? Мы находимся в monad. yval, и говорим, пожалуйста, вычисли f от x, и присвоим это дело переменной a параллельно.

Затем сразу же вычисли f от y, и присвоим это дело переменной b параллельно. И затем верни пока еще недосчитанные thunks a и b. Если рассматривать все это дело как таймлайн, и представить, что f от x вычисляется дольше, чем f от y, то return будет вызван ровно в то же время, когда у нас были запущены параллельные вычисления. То есть на момент нашего с вами return, вот эти thunks, пока еще не вычисленные выражения f от x, чистые выражения, они все еще будут читаться. Если же нам где-то, допустим, понадобится вывести их на консоль, или с чем-то сравнить, то в данном моменте мы остановимся и подождем, пока наш thunk довычислится.

Но в данном случае мы свободно можем продолжать дальше и подождать где-нибудь потом. То есть мы можем вернуть эти thunks из нашей функции, и они когда-то потом посчитаются. И потом уже, может быть, на момент использования они уже будут досчитаны. В этом прикол функции rpath. То, что мы берем и просто говорим, вычисли мне, пожалуйста, параллельно, и идем дальше.

И так же говорим, вычисли мне параллельно, и идем дальше. И так как это у нас чистые значения, у нас нет никаких future, нет никаких iot и прочих других обертков, это просто какое-то ленивое значение, которое пошло вычисляться. Вычислилось оно еще или нет, фиг знает. Но если оно нам нужно, и оно не вычислилось, мы подождем. Вот такие периоды.

Разберем, как работает RSEC. Мы говорим, давай f от x вычисляй параллельно, и отправили вычисляться. А f от y мы хотим вычислить последовательно. То есть мы хотим, чтобы на момент ретерна b уже было вычислено, а a еще нет, потому что мы предполагаем, что a считается дольше. Получается, ретерн будет вызван сразу после того, когда считается b.

И на этом, собственно, интерфейс Monado Eval заканчивается. Основной интерфейс Monado Eval заканчивается. Там, понятно, есть более сложные примитивы, как и с Concartly Erase, для работы с всякими списками, для работы с произвольными траверсаблами, фолдаблами и так далее. Но все это дело можно смоделировать, представить через mpar и RSEC. Если же мы хотим...

Смотрите, последний пример мотивирующий. Мы отправляем a вычисляться в отдельный поток, затем в том же потоке вычисляем b, а потом все-таки хотим дождаться a. Тогда ретерн будет выполнен уже после того, когда у нас обе a и b будут вычислены. Короче, мы с помощью mpar и RSEC можем манипулировать параллельными вычислениями как нам угодно. То есть мы в нужный момент можем подождать с помощью RSEC, в нужный момент можем что-то отправить читаться с помощью mpar.

Все. То есть на этом API monad и val заканчиваются. И потом с помощью run и val мы это дело достаем и получаем чистое значение. Мне показалось, что там кто-то четко что-то писал. Есть ли какие-то вопросы? Да, конечно.

Почему это сделано монадой отдельной и другим типом? Ведь если у нас чистые функции, компилятор мог бы сам неявно это все запускать параллельно и вычислять. Зачем нам что-то делать? Об этом мы сейчас будем говорить. Потому что это делать невыгодно. Хочется, чтобы программист явно указывал, что мы хотим параллелить. Потому что это логичное предположение.

У нас все чистое. Почему бы не параллелить все? Но на самом деле, если делать это без ведома программиста и параллелить каждую операцию, ну или до какого-то осмысленного момента, то может быть две проблемы. Первая. То, что мы наплодим с лица, это слишком много спарков. Несмотря на то, что их, в принципе, можно плодить очень много, мы можем с этим переборщить.

Во-вторых, порой оверхед на создание спарка, несмотря на то, что он очень маленький, может быть больше, чем оверхед на выполнение операции. Поэтому параллелить все и всегда – это невыгодно. А делать какой-то conditional параллелизм – а зачем? Если можно предоставить программисту удобный API? Потому что, на мой взгляд, Monado и VAL – это очень простая и очень удобная вещь. Просто берешь RUN и VAL, просто говоришь, что вычислить параллельно, что вычислить последовательно. И никаких датарейсов, вообще ничего, у тебя все иммутабельное, все чистое, ты живешь в себе прикрывающий.

Лучше уж сделать вот так, чем параллелить все. А уж тем более, чем грабить какие-то костыли в компиляторе, чтобы он пытался догадываться, что лучше параллелить, а что нет. Но это мы уже забегая вперед сказали. Ну, тут у нас пример, как вычислять Fibonacci от и от параллельно. И если же мы вдруг хотим посмотреть, сколько у нас ядер процессора было задействовано, сколько у нас отработал garbage collector, и на другую интересную инфографику, мы можем передать туда флажок event log и какие-то другие флажки, о которых, я думаю, нет смысла останавливаться, если что, прочитать.

И запустить утилиту Threadscope на файле . eventlog, который был с предыдущим запуском ваших программ. И увидеть, что в данном случае, если вы запускаете с плюс RTS, но без минус n2, то есть на один поток, вы будете видеть, что у вас всего одно ядро задействовано. Это применение Monado и Val, но все еще с одним потоком. А вот если же мы скомпилировали с минус n2, мы увидим, что вот оно первое ядро, вот оно второе ядро, оба ядра были загружены.

Тут мы можем посмотреть какую-то интересную аналитику по количеству спарков, которая была создана, и много всякого интересного, которое, вполне возможно, нам никогда не пригодится. Но если уж очень хочется, если уж мы заботимся, если нам нужно найти какой-то bottleneck в performance нашей программы, оно может быть полезно. Вот этот вопрос, который вы задавали. Давайте просто попробуем параллелизовать все. Проблема в том, что компилятор недостаточно умный для того, чтобы понять, что параллелить стоит, а что нет.

Это, в принципе, не является ответственностью компилятора. Можно очень тупо начать параллелить. Вот, допустим, представьте наивную реализацию чисел Фибоначчи, которая, как известно, работает за экспоненту. И попытаемся каждый из веток нашей рекурсии параллелить. То есть мы будем плодить экспоненциальное количество потоков.

Попробуем все это дело скомпилировать, и будем видеть то, что ядра использованы довольно неоптимально, потому что если в этом случае мы видим, что все довольно плотно, то каждый из ядер все время делал какую-то полезную работу, потому что была сплошная зеленая полоска. Здесь же мы видим, что желтый – это garbage collect, то что было очень много лишних вызовов, очень много каких-то лишних данных, которые сразу в garbage collect. И поэтому очень часто были прерывания между нашими физическими ядрами, которых четыре, а на спавне лимы потоков, простите, экспоненциальное количество. Это мотивирующий пример, почему параллелить каждый из действий, несмотря на то, что все чистое и, казалось бы, нам это дозволено, плохо. Поэтому вместо того, чтобы параллелить все, в Haskell сделали удобный механизм для параллельных вычислений, чтобы разработчик сам об этом задумался.

Если же вас заинтересовало параллельное программирование в Haskell, можете ознакомиться с следующими вещами. Библиотека Repo для вычислений на GPU и операций над многомерными массивами, тензорами и всем остальным. И также пакет DPH для вычислений численных методов на Haskell. Мы также не коснулись такой вещи, как каналы в Haskell, Chan и Tchan, аналогичные тому, что бывает, например, в Golang. Также мы не коснулись другой монады для параллельных вычислений, которая называется Plan.

Она более интересная, но и, как следствие, менее простая, чем монада Eval. Можно ознакомиться с ней самостоятельно. Можно ознакомиться с распределенным программированием на Haskell, с использованием платформы Cloud Haskell, которая, к сожалению, уже давным-давно умерла, но мало ли кому-нибудь интересно. Кому интересно, там будет ссылочка в конце про то, как работает Scheduler в VRC. И также можно тюнить и дебагить программу.

Вот тут куча ссылочек на все это дело. Если вам интересно, можете ознакомиться. На этом мы заканчиваем лекцию. Кажется, мы даже более-менее уложились в тайминге. Есть ли у кого какие-то вопросы? Зачем проверять вектора, если они и так в процессорах проверены? Вы сразу о каких векторах речь? Математические.

Или тут не математические вектора? Нет, тут имеется в виду многомерный вектор. Допустим, если вы ML на Haskell хотите посчитать, а почему вы решили, что они и так параллельно вычисляются? Из-за инструкции, из-за векторов инструкции на СПУ? Да. Как раз-таки это библиотека. Если вы представите ваш математический вектор Haskell-ным списком, он не будет считаться параллельно либо на ГПУ, либо с использованием векторов инструкции. То есть это обертка над этим? Да, это просто обертка над вызовами вот этих системных штук.

Haskell-ные списки плохо годятся под это дело. Это просто специализированная версия. Всё окей. Окей, если вопросов нет, видимо, тогда заканчиваем. Всем спасибо.

Пока. Спасибо, до свидания. До свидания. 