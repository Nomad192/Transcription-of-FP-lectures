0:01
Отлично, так.
0:03
Ну что ж, всех приветствую на восьмой лекции по функциональному программированию.
0:07
Сегодня мы поговорим про performance и про строгость в Haskell.
0:13
План будет следующий.
0:16
Мы поговорим про...
0:18
Начнем с difference-листа,
0:20
того, какую он разрешает проблемку.
0:23
На самом деле, он разрешает довольно маленькую
0:25
проблему, такую незначительную, я бы сказал.
0:27
Тем не менее, разрешает.
0:28
Дальше мы поговорим про строгость.
0:29
Потом про механизм предотвращения накапливания
0:33
преимущественных представлений в памяти,
0:37
функцию deforestation.
0:39
Поговорим про объект, который предотвращает
0:43
накапливание этих представлений в памяти,
0:46
это называется streamfusion.
0:48
И немножко поговорим про бутабельные объекты.
0:50
Начнем с difference-листа.
0:54
Итак, вот есть функция Trinity.
0:56
Она принимает три списка.
0:58
И, судя по тому, что написано здесь, конкретизирует
1:02
их каким-то соответствующим способом.
1:06
Их вообще способов здесь три строчки.
1:10
Но на самом деле, конечно же, способов
1:13
конкретизации два списка, их только две штуки.
1:18
Вопрос номер один.
1:20
Помним ли мы, какая ассоциативность у конкретизации списков?
1:29
Совершенно верно, да.
1:30
Конкретизация списков у нас… извиняюсь, сейчас… Правая статья.
1:34
Я просто хочу еще начать смотреть, на всякий
1:37
случай, если у вас вопросы есть и так далее.
1:39
Но сейчас не получается.
1:44
Ассоциативность правая.
1:45
По определенной причине.
1:48
Поэтому фактически ведет первая строчка в определении Trinity.
1:50
Это эквивалент, на самом деле, второй.
1:53
Просто такой способ не ставить скобочки, чтобы они
1:58
автоматически бандились к rightmost конкретизации.
2:02
Поскольку у нас, опять же, правая ассоциативность.
2:05
Вопрос следующий.
2:06
А какое определение из среди этих трех, тем не менее, лучше не использовать?
2:11
И почему, на ваш взгляд?
2:24
Есть идеи? Последнее.
2:36

2:37
Потому что мы хотим к более короткому списку прибавлять.
2:42
Потому что нам нужно у последнего обновить ссылку на следующую ноду, последнего узла.
2:49
Да.
2:50
Я совершенно согласен с вами.
2:51
Последнее лучше не использовать по причине определения конкретизации списков,
2:56
и по тому, что мы именно перемачиваем, как мы именно
2:59
перемешиваем наши конструкторы, конс и так далее.
3:02
Вопрос.
3:04
Смысл?
3:05
Да.
3:06
Дефолт.
3:07
Нет.
3:08
Выбирать корректное определение ассоциативности на простом.
3:12
Ассоциативность правая и рейдер пятый.
3:15
Потому что, вспомним определение ассоциативности.
3:18
У нас конкординация ленивая по второму аргументу.
3:21
То есть второй аргумент может быть, на самом деле, бесконечным.
3:23
Но первое должно быть бесконечным, чтобы можно
3:26
было взять, например, n элементов из конкординации.
3:29
По первому аргументу перемешиваем просто конус. Вот и все.
3:34
Если мы проанализируем эти два отрывка, мы увидим, что, в
3:39
принципе, на самом деле, поскольку ассоциативность ленивая,
3:44
вот эта строчка, конечно, тут не будет вычислена, вот эта скобочка первая,
3:49
это вычислится сначала конкординация с левым списком
3:55
из n элементов, поэтому сначала будет n операций.
3:57
Ну, не n, на самом деле, а, я бы сказал, n плюс 1, потому что, на самом деле,
4:01
список n элементов – это n элементов плюс пустой список.
4:07
Поэтому, на самом деле, n плюс 1 операция – не важно. Плюс константы.
4:11
То есть сначала будет n операций.
4:13
И когда мы конкординируем левый список, по определению ровно конкординации,
4:18
а потом уже мы конкординируем результат с непосредственно списком 1 и так далее,
4:29
n плюс 1 и так далее, k.
4:31
И вот здесь, конечно, будет уже n операций.
4:34
В итоге будет ровно n плюс 1 операция.
4:37
Именно если у нас имеет место правая ассоциативность.
4:40
Посмотрим тогда на левую ассоциативность и посмотрим на то, что изменится.
4:43
Значит, опять же, у нас плюс-плюс строгий, де-факто, по первому аргументу.
4:48
Поэтому вычислится сначала левая часть.
4:51
Безусловно, то, что я выделил, будет n операций.
4:55
Это и так понятно.
4:56
А вот потом, когда мы конкординируем наш
4:58
жадивающий список со списком 1 и так далее,
5:01
будет у нас теперь n плюс m операций.
5:06
Потому что мы, опять же, потормачиваемся по результату, то
5:10
есть левому списку, а этот список из n плюс m элементов.
5:13
Поэтому у нас будет n плюс m плюс 1, на самом деле, операции,
5:17
и того у нас будет 2 n плюс m операций в общем случае.
5:22
И, ну, как бы, вроде это все равно от n плюс m.
5:27
Ну, просто мы делаем личный траверсал нашего списка.
5:31
Личный траверсал, личный проходок.
5:33
Личный траверсал делать, как бы, если его не сбежать, то это хорошо.
5:38
Лишних траверсалов не делать.
5:40
По этой ссылочке можно перейти и посмотреть,
5:44
как работают постановки всяких определений, которые вы вводите в Haskell.
5:50
Только в отличие от Haskell, здесь вот по
5:52
этой ссылочке, по этой интерактивной игрушке,
5:55
можно будет выбрать, какие под выражения вы учисляете.
6:02
То есть вы кликаете на пузырики, и там эти пузырики,
6:05
и вот это вот выражение, которое можно редуцировать.
6:07
У вас есть там выбор.
6:09
Вы можете задать свое определение и посмотреть на то, как все редуцируется.
6:15
Если вы предпочитаете… Да, собственно, если вы предпочитаете проверить ленивость,
6:21
то вы должны всегда попытаться попасть в самые
6:24
левые пузырики в этой интерактивной среде.
6:28
Есть такая вещь, можно какие-то попробовать, когда у вас будет время.
6:32
Very fun.
6:33
Вот.
6:34
Итак, избегать проблемы выбора ассоциативности.
6:38
Как сделать так, чтобы у нас не было, скажем, явного выбора ассоциативности,
6:45
и так, чтобы не сделать ошибку, если у человека ошибки случаются?
6:46
Ошибки случаются, это бывает.
6:49
Решение на следующее.
6:51
Создадим такой тип данных, который называется The List.
6:54
Сочиняется как Difference List.
6:56
Он энкапсулирует в себе функцию из списка А в список А.
7:03
Логично было бы в рамках использования The List не экспортировать,
7:07
это я уже в мысли вслух, не экспортировать конструктор DL данных, естественно,
7:13
потому что основная вещь здесь будет происходить
7:17
именно в этих двух функциях, From List и To List.
7:21
А From List принимает или возвращает, собственно, DL от какой-то функции,
7:24
и эта функция, внимание, это в точности компетенция слева.
7:28
Вспоминаем, базовая синтексис Хаскелла, это
7:31
называется, господи, какая это секция? Правая секция.
7:34
Здесь лямбда, скажем, L', стрелка L++ L'.
7:41
То есть мы добавляем L к аргументу нашей лямбды, причем L слева.
7:48
Вот это является ключевым моментом в определении From List,
7:53
что мы L добавляем слева.
7:54
Сейчас мы видим, что это поплечет.
7:58
А как перевести тогда The List в To List,
8:01
то мы просто применяем нашу функцию в кустом списке.
8:04
Внимание, To List от From List, вот L, это по определению L++ кустой список.
8:12
И это у нас, опять же, координация, она является моноидом,
8:18
и у нас кустой список – это центральный элемент.
8:20
Поэтому L++ кустой список – это L.
8:23
Поэтому To List от From List L – это L, что хорошо.
8:28
Итак, смотрим теперь.
8:32
Насчет обмена.
8:34
У нас есть координация, и теперь мы можем
8:39
произвести семигруппную операцию склеивания двух тл.
8:48
Я не помню, освещалось ли это на лекции по моноидам, которую я вел,
8:54
я даже не помню свою лекцию, печально.
8:56
Но там действительно есть такой теган, который называется endo,
8:59
который капсулирует в себе эндоморфизм, то есть функцию из ова.
9:03
Здесь то же самое, у нас операция, фактический эндоморфизм, списка в список.
9:08
Операция append, которая типа добавляет два списка вместе,
9:12
хотя там функция, на самом деле, казалось бы,
9:14
какие списки она добавляет, у нас функции.
9:16
Но это просто координация, ой, композиция функций, вот и все.
9:20
И да, у нас композиция, естественно,
9:23
анастатична, поэтому L образует семиполигруппу.
9:27
Более того, тут M append стоит, то есть можно подумать, а что, L образует моноид?
9:34
Конечно образует моноид.
9:36
Нейтральный эвент у лековой композиции – это identity, морфизм,
9:39
то есть это одно, которое принимает и возвращает то же самое.
9:44
Поэтому L вполне себе полноценный моноид, что классно.
9:48
И вот, соответственно, два случая того, как расставить скобки.
9:55
Что они публикуют оба? Какой результат?
9:58
На самом деле, забегая вперед, не анализируя подробно, что тут написано,
10:04
это элементарно просто будет TL от композиции трех функций.
10:08
F, допустим, наш аргумент – это X.
10:11
Ну и XS, окей, XS, пока здесь.
10:13
И вот F в обоих случаях, что важно.
10:16
F от J, от H, от XS.
10:18
Тут, конечно, не написано.
10:20
Ну, как бы тут вот T – это та самая функция, на самом деле, которая J от H.
10:28
Получается F от J от H от XS.
10:31
По определению M-аппенга.
10:33
Тут по определению нашего даймонда.
10:34
Напоминаю, я называю это даймондом и наша полугруппная операция, астротипная.
10:40
Вот. Вопросы есть? Нет вопросов пока, нет, окей.
10:42
У меня чат перед полицами, поэтому задавайте, если хотите.
10:46
Так. Ну, как бы, отлично.
10:50
F от J от H от XS.
10:52
И что за того, казалось бы?
10:55
Ну, вспомним, что мы имеем право по консенсусу нашему
11:00
пользоваться исключительно from-листом, чтобы лист лифтить в контекст DL.
11:07
Поэтому F – это что-то наподобие…
11:10
Вот какой-то список здесь, это список F-штрих, F-штрих плюс плюс.
11:14
Вот D-штрих плюс плюс – это рот тот самый L-плюс плюс,
11:17
который мы определили в рамках определения from-листа.
11:21
Значит, F – это F-штрих плюс плюс, J – это
11:23
J-штрих плюс плюс, H – это H-штрих плюс плюс.
11:27
Итого, F от J от H от XS – вот здесь это Y или S, не важно вообще, просто аргумент –
11:33
превращается вот в такую серию, в общем, в обоих случаях, в такую серию координаций.
11:39
И вот теперь уже прикол в том, что именно поэтому
11:42
мы добавляем определение from-лист L слева.
11:47
Это поплечет, как бы мы скобки не ставили, в правоостативность координации,
11:55
что, естественно, избавит нас от лишних траверсовов,
12:01
потому что правоостативное выполнение операции
12:03
координации поплечет наименьшее количество траверсов.
12:07
Сначала пройдется по всему F-штрих, потом по всем, мы сконструируем новый список,
12:11
потом J-штрих, потом H-штрих, ну и потом мы просто добавим YS и все.
12:16
Итого у нас будет ровно от длина AF-штрих плюс
12:21
длина J-штрих плюс длина H-штрих в обоих случаях.
12:27
Как бы мы скобки не ставили здесь.
12:28
В отличие от левоостативности плюс-плюс.
12:32
Там будет операции, господи, длина F плюс F плюс J плюс F плюс J плюс H.
12:39
То есть это прям 3F плюс 2J плюс H. Печаль.
12:42
Это хуже, чем хотелось бы. Хотелось бы просто F плюс J плюс H.
12:46
Вот. В этом прикольный difference list.
12:48
Difference list решает довольно не такую капитально
12:54
значимую проблему с точки зрения time complexity,
13:01
но тем не менее разрешает.
13:03
И, опять же, желательно иметь меньше траверсов по нашим спискам.
13:09
Вопросы по difference list.
13:11
Дальше у нас… А, да. Дальше у нас немножко про sequence.
13:14
Один слайд. Вопросы слушаю, если есть. Если нет, мы пойдем дальше.
13:24
Так, окей.
13:25
Вот тут один слайд посвящен просто reference-у
13:28
типа данных, который называется sequence.
13:31
Точнее, seq, да?
13:33
С большого буквы. У нас скоро будет seq с маленьким буквы.
13:35
Это разные вещи принципиально.
13:36
Вот. Data sequence, точнее, типа данных seq, он реализован с помощью Finger3.
13:44
Finger3 – это такая функциональная структура данных,
13:49
на которой можно реализовать двусвязный список.
13:55
И вот иллюстрация того, как оно получается…
13:58
Вот, короче, есть видео где-то в деблях интернета, где-то в ютубе, точнее.
14:02
Можно там глянуть на то, как получить Finger3
14:05
из обычного бинарного дерева. Визуально.
14:10
Спойлер. Там, в общем, берется нода, она
14:13
перевешивается, она становится, короче, root-ом.
14:17
Наша нода где-то внутри дерева, то есть под дерево, да?
14:20
Становится root-ом, а все остальное двигается вниз.
14:22
И там, внезапно, получается такая немножко нетривиальная структурка.
14:27
Но, на самом деле, Finger3 – это действительно
14:31
структура не такая простая с точки зрения реализации.
14:35
Может быть непонятно, как вообще реализовать двусвязный список на Finger3.
14:40
Тем не менее, можно.
14:41
Поэтому, если вам интересно, посмотрите на DataSequence.
14:45
Но пока мы подходим к строгости в Cascade.
14:50
Итак, начинаем мы с seq.
14:52
Вот вот самый, который с маленькой буквы.
14:54
Не имейте никакого отношения к sequence, о котором я только что упомянул.
14:56
Seq – это вообще другая вещь, другой зверь.
15:01
Sequence делает следующую вещь.
15:05
Вот его модель.
15:06
Она… Очевидно, неопределение, внимание.
15:08
Очевидно, это неопределение, потому что мы не
15:10
можем играть в каждый параметр bottom, очевидно.
15:13
Да, в Cascade bottom – это что-то подобное, defined.
15:16
Вообще, bottom – это, например, error.
15:18
Опять же, если мы… SignatureError – это функции строки в произвольном типе.
15:25
Если стомить matlock, который у нас был весной, то там, в общем…
15:34
Опять же, пустой тип void можно определить как for all a.a.
15:40
Это как undefined фактически.
15:42
Тогда error – это стринг, стрелка for all a.a.
15:46
То есть, по эзоморфизму Кори Ховарда, то же самое, что не строка.
15:49
То есть, error – это отрицание строки.
15:51
Вот, на самом деле, тип error'а.
15:54
Немножко астропемиологическое, как называется,
16:00
signature error'а, как она воспринимается в чеке matlock'а.
16:03
Это отрицание строки, что-то типа того.
16:08
Ну, undefined – это что-то подобное bottom'а.
16:09
Ну, как error, в принципе.
16:12
А bottom – это что-то, что либо является непродуктивной рекурсией.
16:21
В общем случае, да.
16:22
Например, infinite loop – это непродуктивная рекурсия.
16:24
Либо что-то, что никогда не завершается успешно.
16:27
То есть, какой-нибудь exception.
16:29
То есть, потом это самокупность там.
16:31
Как и именно в двух случаях.
16:32
Непродуктивная рекурсия и exception, который невозможно поймать, например.
16:37
Но это, конечно, слишком строго.
16:38
То есть, на самом деле, это просто любой exception.
16:40
Потому что, опять же,
16:42
прокопирование подобное Java, C++, Kotlin, Scala – неважно.
16:47
Все exceptions имеют тип bottom'а.
16:52
Не тип bottom'а, а это является bottom'ами.
16:57
Но их, естественно, можно поймать.
17:00
То, что я сказал, типа, которые нельзя поймать, это, конечно, страйд, я извиняюсь.
17:06
То есть, любой exception, фактически.
17:08
И непродуктивная рекурсия.
17:10
Значит, это bottom, называется расходящееся вычисление.
17:15
Что делает sequence?
17:16
Все, переходим к, собственно, sequence'у.
17:20
Вот его модель.
17:21
Это не определение, просто модель.
17:23
Если слева стоит bottom, возвращается bottom.
17:26
Sequence вычисляет левый аргумент до его первого аргумента.
17:31
Слабая, главная, нормальная форма.
17:33
Я буду говорить о какой-нибудь нормальной форме,
17:34
потому что слабая, главная, нормальная форма тяжело выговаривается.
17:38
Weak-head normal form. Вот как здесь написано.
17:41
Вычисляет его, но возвращает он второй аргумент.
17:45
Вот это все, что делает sequence.
17:48
Да, и вот его сигнатура, если она принимает a, принимает b, возвращает b.
17:51
Потому что возвращает она второй аргумент, вычисляя первый до weak-head normal form.
17:56
Вот и все.
17:59
Предлагаю следующий микроквиз по тому, как ведет себя sequence на разных input'ах.
18:05
Начинаем.
18:06
Zero, sequence, 10. Что вернется?
18:12
10.
18:14
Все наверное, 10 вернется.
18:16
Да, мы вычистим 0, получим 0, отлично, до weak-head normal form, и потом вернем 10.
18:21
Undefined sequence, 10.
18:23
А разве 0 не в слабоголовной форме находится?
18:27
Почему 0, sequence, 10, вернул 10?
18:32
Потому что мы вычислили 0, он может уже пребывать в weak-head normal form.
18:38
Это зависит от того, какой тип у нас.
18:41
Например, если у нас тут тип int hash, то он
18:44
уже там пребывает в weak-head normal form.
18:47
Просто возвращаем 10, отлично.
18:48
А если это какой-нибудь, скажем, сейчас ratio, напоминаю, что сейчас rational.
18:54
Rational – это ratio integer, это процент integer.
19:00
То вот там вместо 0 поставится from integer
19:03
0, вместо 10 поставится from integer 10,
19:06
вычислится from integer 0, вот он уже вычислится,
19:10
from integer 0, и вернется конструктор с процентом, тот самый, типа данных ratio.
19:18
Надеюсь, вы помните, что такое ratio – это один из нумерических типов данных,
19:21
который представляет из себя division числей заменателя.
19:27
Причем явно, это произведение типов.
19:30
Будет вычислиться, получится там внешний конструктор процент,
19:34
отлично, вычислится, все в порядке, и вернется 10.
19:38
То есть это тоже зависит от того, какой тут тип стоит.
19:40
Напоминаю, что 0 и 10 – это просто литералы нумерические,
19:45
и это синтетический сахар, from integer 0, и from integer 10.
19:49
Это зависит от ваших типов.
19:51
Допустим, здесь int, вроде простоты.
19:53
Но 0 же пребывает, we have double form, отлично, просто возвращаем 10.
19:58
Это стало понятно? Я правильно?
20:01
Ты ответил на вопрос, надеюсь, или нет? Вроде да.
20:04

20:07
Что делать с undefined?
20:08
Если undefined стоит в первом аргументе, что случится? Ошибка, т.
20:16
к. undefined не вычислится.
20:21
Я бы сказал, вычислится, потому что он… Он выкидывает ошибку.
20:27
Да, конечно.
20:29
Undefined – это же bottom, напоминаю.
20:33
Bottom – exception.
20:36
Just undefined sequence 10.
20:42
10.
20:44
Совершенно верно, 10.
20:46
Потому что just undefined пребывает в weakhead normal form.
20:50
Что такое weakhead normal form?
20:52
Давайте напомним, что это либо внешний конструктор, и только внешний конструктор.
20:58
То, что находится внутри него, если оно есть, не вычисляется.
21:03
Либо это лямбда-абстракция.
21:05
То есть лямбда-аргумент, стрелка и дальше тело нашей лямбда-абстракции.
21:09
Здесь это конструктор just.
21:11
Нам плевать, что тут undefined стоит.
21:12
Отлично, пускай стоит.
21:14
Он не вычислится, потому что у нас weakhead normal form – это just.
21:16
Just уже есть. Отлично, все.
21:18
Вычислили это weakhead normal form, вернули 10.
21:21
Вот все.
21:23
Маленький перк, связанный с очередным отличием data и newtype.
21:27
Мы знаем, что newtype – это оберточка, а data – это просто плацентимент.
21:32
В компайл-тайме newtype происходит так называемое…
21:34
Сейчас, я не знаю, это корректный термин – newtype erasure.
21:37
То есть стирание конструкторов newtype.
21:40
Вот в компайл-тайме так происходит.
21:43
Поэтому здесь, когда мы передаем конструктор nw,
21:48
это можно воспринимать как undefined sequence 42.
21:52
Если кто-то ставит newtype.
21:54
Это можно воспринимать просто как то, что я выделил.
21:56
В случае newtype.
21:57
Поэтому это просто выбросится undefined.
21:59
В случае data, естественно, никаких таких магий
22:04
на потопе erasure конструкторов не происходит,
22:06
потому что data – это не особый случай.
22:10
Поэтому внешний конструктор dw – это уже weakhead normal form.
22:13
То есть это как just, по-корочему говоря.
22:16
Эта часть эквивалентна вот этой части.
22:20
Вот эта часть, то, что сейчас выделено, эквивалентна вот этой части.
22:24
То есть без конструктора nw.
22:25
Из-за newtype erasure, что-то типа того.
22:29
Erasure, стирание.
22:30
Это еще один перк.
22:32
Я не помню, он обсуждался или нет.
22:35
Это было в самом начале курса, кажется.
22:38
Разница newtype и data.
22:40
А, я же определил лекцию, кажется.
22:42
Я не помню ничего.
22:43
Вот.
22:46
Теперь поговорим про строгости в рамках сверток.
22:50
Ну, мы знаем, что у нас также есть
22:54
две классические свертки – левая и правая.
22:56
Например, когда мы спрашиваем список, мы можем это сделать в два способа.
23:00
И фундаментально, и синтетически, и схематически – это разные вещи.
23:04
Правая свертка и левая свертка.
23:06
Зависит от того, как его собирать здесь.
23:07
Например, здесь плюсы и нолик.
23:09
Фолдер, эквивалентин, фолдл – они все вернут один и тот же результат.
23:12
Потому что плюс – это коммутативная основательная
23:15
операция, и плюс образует коммутативный манойд.
23:18
Все. Это достаточно.
23:19
Мы знаем, что такое коммутативный манойд.
23:22
Поэтому фолдер, эквивалентин, фолдл.
23:24
В данном случае.
23:26
Тем не менее.
23:27
Допустим, мы захотим посчитать фолдр плюс ноль.
23:31
То есть мы просто суммируем все элементы.
23:33
От списка из десяти миллионов элементов.
23:36
Это будет довольно медленно.
23:40
Как фолдр, так и фолдл.
23:42
Оба варианта.
23:43
Сейчас я на следующей стадии
23:46
продемонстрирую в очередной раз определение
23:49
фолдра и фолдра, чтобы можно было их отличить.
23:50
Если мы вдруг забыли.
23:52
А вот если мы пытаемся посчитать это на
23:56
списке из 100 миллионов элементов,
24:00
то, возможно, у вас все зависнет,
24:02
и ваша машина немножко поломается.
24:05
Поэтому рекомендую не запускать вашу программу на
24:11
гигантских структурах без верхнего предела по памяти.
24:15
Как так добыть?
24:16
Вдруг у нас реально гигантские списки.
24:18
А как их, собственно, вычислять?
24:21
Есть строгая версия.
24:22
Строгая версия, например, левой свертки.
24:25
Более того, строгая версия левой свертки лучше, чем строгая версия правой свертки.
24:29
Более того, я не...
24:31
Называется строгая версия правой свертки фолдр-штрих, очевидно,
24:34
потому что фолдр и штрих – это как бы строгостика того.
24:38
Она определена в классе типа foldable.
24:42
Как и фолдл-штрих, собственно говоря, они все определены в foldable.
24:44
Это можно глянуть на их предутствие там.
24:49
Фолдл-штрих – это строгая версия фолдла,
24:52
и мы потом выясним, в чем заключается строгость,
24:56
как она отражается на редукции, как мы вычисляем наши операции.
25:02
10 миллионов элементов вычисляется довольно быстро.
25:04
100 миллионов не ломает нашу систему, что хорошо.
25:08
Из-за строгости.
25:10
Более того, я бы сказал,
25:14
что тут, на самом деле, можно сделать фолдл
25:17
из-за определения фолдла, из-за того, как он определяется,
25:20
хоть на миллиард.
25:22
Такое ощущение.
25:23
Да, у нас будут довольно большие числа.
25:28
Зависит от вашей памяти, как минимум.
25:32
Но, чисто теоретически, на миллиард чисел ваш список
25:36
тоже можно сделать за фолдл-штрих идти, короче говоря.
25:40
Да, это теория.
25:42
В смысле, спекуляция.
25:43
Нет, я не попробовал, не хочу сам попробовать.
25:46
Тем не менее, фолдл – фолдер.
25:48
Фолдл – правая сторона.
25:50
Мы знаем, что такое фолдер.
25:52
Это применяем функцию f к пустому списку к голове и к пустому списку к фолдеру.
25:56
А если список пустой, возвращаем так называемое начальное значение z.
26:00
Оно начальное.
26:01
Вот.
26:02
Фолдл – это почти фолдер,
26:05
только здесь, во-первых, функция немножко другая.
26:07
Из b и a в b.
26:08
А тут из a в b.
26:10
В функции с fb в fb.
26:13
Да, кейс с пустым списком такой же, но вот этот элемент теперь в фолдле
26:20
называют аккумулятором, потому что мы аккумулируем значение
26:23
и делаем холостовую рекурсию, как вы можете заметить.
26:27
Именно поэтому я спекулировал,
26:29
а вот вдруг можно реально сделать фолдл от списка на миллиард элементов.
26:32
Вдруг это удастся.
26:34
Мне кажется, сейчас.
26:36
Есть ли списки из них, те же элементы, типа units или там нолик,
26:40
то, наверное, да.
26:41
Но если там гигантские числа, наподобие, опять
26:44
же, миллиарда, то, наверное, все поломается.
26:46
Неважно. Все.
26:48
Не будем говорить о списках, о количестве элементов.
26:52
Но такая проблема возникает вот в реализации фолду, например.
26:57
У нас аккумулируются результаты пробежуточные
27:01
в нашем втором аргументе, в нашем аккумуляторе.
27:04
Мы знаем, что хаскер ленивый.
27:07
Нам пока нет смысла его вычислять.
27:13
Поэтому я обращусь пока к второму определению с фолдлом.
27:19
Вот у нас аккумулируется на первой стадии 0,1.
27:22
Он не вычисляется, очевидно, потому что его нет смысла вычислять.
27:25
Мы пока его не вернули.
27:27
У нас нестройки вычисления.
27:28
Потом 0,1 плюс 2.
27:30
Левостативно, очевидно.
27:32
Вот наш старый аккумулятор, собственно говоря.
27:34
Потом плюс 3.
27:36
А потом уже мы возвращаем аккумулятор.
27:39
И вот теперь на этой стадии, когда мы вернули аккумулятор, мы начинаем редукцию.
27:42
Мы начинаем вычислять 0,1, 1,2 и 3,3.
27:47
Мы получаем 6, очевидно.
27:50
Фолдер работает более понятно.
27:52
Мы не можем пока сложить единицу с тем, что стоит справа,
27:56
потому что справа у нас реквизитный вызов фолдера.
27:59
И так далее, и так далее.
28:01
Вот тут уже возвращаем 0.
28:02
Потом уже выполняем редукцию вычисления.
28:06
4 плюс 0, 2 плюс 3, 1 плюс 5.
28:08
В обоих случаях тут на самом деле возникает 7 переходов.
28:13
Раз, два, три, четыре, пять, шесть, семь.
28:17
Ну и проблема.
28:18
Явная проблема в том, что у нас и в фолдере,
28:20
и в фолдле, особенно в фолдле я даже поговорю,
28:24
почему именно фолдл является критически важной функцией здесь.
28:30
Аккумулируется значение, во втором аргументе, гигантское.
28:32
Это thunk, он не вычислен.
28:35
И если у нас здесь возникает список из, опять же, 10 миллионов элементов,
28:42
и мы делаем fold2, у нас во втором аргументе будет копиться
28:47
колоссальных размеров гигантский thunk,
28:50
который не вычислен до тех пор, пока мы не прогревать
28:52
по всему списку из единых 10 миллионов элементов.
28:55
Вот.
28:58
Как быть тогда?
29:00
Передача макетинговый запрос, маленький квиз очередной,
29:04
создающий задание вопроса.
29:06
Что вернет фолдер, конъюнкция false и repeat false,
29:10
это бесконечный список из фалсов,
29:12
и аналогично только четко левая.
29:15
Что вернет каждая из этих функций, на ваш взгляд?
29:19
Чет пока мертв, к сожалению.
29:21
Пишите вопросы, если у вас есть, я попытаюсь ответить.
29:25
Первый фолдер вернет фалс, а фолдер будет бесконечной ситуацией.
29:31
Абсолютно верно.
29:33
Фолдер, конъюнкция false, repeat false,
29:36
средуцируется в, вот как по определению фолдер,
29:39
на списке бесконечных фалсов всегда const стоит, фалс, конъюнкция, фолдер.
29:44
Вот на текущем этапе мы вычислим конъюнкцию от фалса и фолдера.
29:47
Конъюнкция от фалса делает short circuit.
29:50
Короткое замыкание вычислений.
29:52
Это не вычисляется, возвращается фалс.
29:54
Ну, очевидно, у нас есть конъюнкция с конъюнкцией,
29:55
хотя в один фалс, то еще фалс, очевидно.
29:58
Так и определен фалс фразками.
29:59
И не только фразками, в принципе.
30:01
Вообще, если конъюнкция ленивая, и дезюнкция тоже.
30:05
Не одна из всех, но хотя бы в javac, скажем, да.
30:10
Если правильно помню.
30:11
Фолдер, однако, будет аккумулировать фалс, конъюнкция, фалс,
30:15
причем, очевидно, он не будет вычислен,
30:18
потому что у нас нету строгости к второму аргументу, спойлеры.
30:23
Он будет аккумулировать, аккумулировать, он будет аккумулировать до бесконечности.
30:26
И рано или поздно ваша система умрет.
30:29
Ну, надеюсь, что потом она будет оживить каким-то образом.
30:33
Главное сделать control все как можно скорее.
30:37
Лучше не вызывать фолдл, конъюнкция фалса, репит фалс, никогда вообще,
30:41
чтобы случайно не набороться на смертельный случай.
30:48
Это смертельный номер.
30:49
Вот, да, верно.
30:51
Это вернет фалс, это записнет.
30:53
Правильно.
30:55
Итак, в чем прикол фолдла?
30:57
Вот в чем прикол фолдла.
30:59
Вот здесь вместо того, чтобы аккумулировать
31:02
гигантский фланг, мгновенно происходит вычисление.
31:04
То есть здесь раньше было 0 плюс 1, если не помню, теперь это просто 1.
31:08
Ну и дальше было 0 плюс 1 в скобочках, потом плюс 2,
31:11
теперь это плюс 3.
31:12
Не плюс 3, а просто 3.
31:14
А логично 6.
31:17
Итого у нас всего 4 перехода.
31:18
4, потому что у нас список элементов плюс пустой список.
31:22
Вот, да, логично.
31:24
Все вычисляется мгновенно.
31:26
И это, между прочим, хвостовая рекурсия,
31:29
что, по идее, хорошо.
31:32
Собственно, как можно определить фолдл-штрих?
31:37
Фолдл-штрих можно определить через sequence,
31:39
который вычисляет наш вот этот вот f от a и x.
31:45
Вот помните, да, это наш новый аккумулятор, который мы
31:48
поставляем в фолдл-штрих, когда мы вызываемся от хвоста.
31:51
Давайте его в LED binding сделаем локальную связку,
31:57
произведем sequence, вычислим а-штрих до weak-head-normal-form,
32:01
и потом пропихнем это в фолдл, и все.
32:04
То есть а-штрих вычисляется до weak-head-normal-form.
32:07
Ну, это уже что-то.
32:09
Вот уже что-то этого недостаточно.
32:13
Потому что у нас, как бы очевидно,
32:16
в нашем списке могут быть,
32:21
не в нашем списке, а в нашем, точнее, B,
32:23
у нас могут быть, ой, нет, A, в данном случае это A,
32:26
более сложные структуры, наподобие пары.
32:30
Что делает интересная у нас пара? Ничего, страдать.
32:32
Почему страдать? Ну, потому что у нас пара.
32:34
То есть там, внешний конструктор, это запятая,
32:37
уже пребывает в weak-head-normal-form.
32:40
Ак плюс икс, лен плюс один не вычислятся,
32:43
потому что они пребывают внутри пары, внутри конструктора запятая.
32:47
А sequence вычисляет до weak-head-normal-form.
32:50
Какова weak-head-normal-форм у пары?
32:52
Конструктор запятая.
32:53
Нам плевать на аргументы запятой.
32:55
Они не вычислятся у нас, опять же, в weak-head-normal-form.
32:58
Поэтому фолдл-штрих на более сложных
33:00
структурках будет работать так же, как к фолдлу.
33:03
Ну, почти.
33:06
Конечно, будет вычислено это выражение.
33:10
Как вы можете заметить, оно вычислено.
33:11
То есть тут именно применяется функция f к паре иксу.
33:16
Но вот это выражение, внутри уже пары, не вычислено.
33:19
Что печально.
33:23
А когда быть?
33:25
А вдруг нам хочется везде все максимально строгим сделать? Даже с парой.
33:29

33:31
На помощь приходит так называемый deepseq.
33:35
Что такое deepseq?
33:38
Deepseq это определенная функция,
33:41
которая задана с помощью другой функции.
33:46
Сейчас мы увидим, какой.
33:50
И эта функция, которая называется rnf, спойлеры,
33:53
она вычисляет до-нормальные формы.
33:56
Не слава богу, это нормальные формы.
33:58
А именно это нормальные формы.
34:00
Мы вычисляем seq от этого списка.
34:03
Но у нас, очевидно, в динамике конструктор.
34:05
Это конструктор cons.
34:08
Undefined это вообще глубже в списке.
34:10
Поэтому это верный триггер.
34:11
А вот deepseq, по названию уже понятно, что это deep sequence.
34:18
То есть мы вычисляем максимально глубоко до,
34:22
так сказать, как корректно выразиться, до, видимо,
34:28
листа нашего абстрактового статистического дерева.
34:32
Правда ли, мы забыли о том, что это undefined.
34:34
Пытаемся сделать, вычисляем undefined и выкинем exception.
34:42
На deepseq.
34:43
Deepseq, извиняюсь.
34:45
Вот.
34:47
Так.
34:50
Как вы считаете...
34:52
А, да, тоже довольно простой вопрос.
34:54
Что будет, если вызвать sequence от repeat false в 15?
34:58
И аналогично с deepseq.
34:59
Из тематики, которую я только что описал, про deepseq.
35:02
На ваш взгляд, что случится? Парус ломается.
35:07

35:10
Что значит ломается?
35:11
Более детально, что это означает.
35:15
Не завершится или упадет с out of memory.
35:19
А, да.
35:19
Спасибо.
35:21
Действительно, да.
35:21
Мы попытаемся вычислить бесконечный список.
35:24
Причем бес, он бес.
35:25
Вы должны бесы вычислить.
35:26
По аниматории deepseq вычисляется вообще все, что стоит слева.
35:30
До nf.
35:31
Нормальная форма.
35:33
Правильно, да.
35:33
И мы нигде не завершимся.
35:35
А рано или поздно, если мы не завершим предвидительно,
35:37
опять же, лучше это не вызвать специальный номер.
35:41
Лучше... Не лучше, а... Просто не вызывать вообще никуда.
35:44
Упадем с out of memory.
35:45
Правильно.
35:47
Это наиболее приятный исход.
35:50
Ну, а в первом случае что случится? Второе понятно.
35:52
А с первым?
35:56
15.
35:58
Да, 15.
35:59
Repeat false.
36:00
Это фалс.
36:01
Две точки repeat false.
36:02
Две точки.
36:03
Наш лишний конструктор.
36:05
Это уже выход норма форм.
36:06
Отлично.
36:07
Возвращение 15.
36:07
Правильно.
36:09
Так.
36:10
Все.
36:11
И... Ой, что? А, да, окей.
36:12

36:13
Вот теперь определение deepseq.
36:14
Начинаем с nf.data.
36:16
nf.data.
36:19
Это... Как я хочу пошутить.
36:20
Это прям...
36:22
Чувствуется, язык пошутить.
36:25
Сейчас, ладно, без шуток.
36:26
Окей, без шуток.
36:26
Все.
36:27
nf.data – normal form data.
36:30
Не non-fungible data, но normal form.
36:32

36:33
Это класс типов.
36:34
Принимает a.
36:35
У него есть одна функция – rnf.
36:37
Вот та самая функция rnf, которая вычисляет нормальные формы.
36:40
Вот тут написано, что rnf a равен aseq unit.
36:44
Ну, это... Что-то наподобие дефолтного определения rnf,
36:49
который используется для примитивных типов.
36:51
Наподобие int,
36:52
не знаю,
36:53
char, double, word.
36:54

36:56

36:56
Word, напоминаю, это unsigned integer в Haskell.
37:00

37:02
Вот.
37:03
Отлично.
37:04
Да.
37:04
Вот, по идее, если instance.
37:06
nf.data для всех них,
37:07
а очевидно, для всех этих,
37:09
которые только что упомянул,
37:11
типов, есть instance.
37:12
nf.data.
37:13
Очевидно.
37:13
Безусловно.
37:14
Как же это?
37:15
Я думаю, что там не прописывается явно определение rnf.
37:19
Просто потому, что, опять же, int,
37:20
double,
37:21
char,
37:21
word,
37:22
это все примитивные типы.
37:25
Поэтому можно использовать для них дефолтное определение.
37:28
Но для более сложных структур, наподобие суммы типов, представим типов data.
37:31
Именно с data.
37:33

37:35
Лучше определить rnf кастомным образом.
37:37
Вот пример.
37:39
Начнем с maybe.
37:41
Окей.
37:41
Ну, мы... Что происходит?
37:43
Мы здесь вычисляем до... Явно сразу же,
37:45
видимо, да,
37:47
вычисляем до weakly normal form.
37:48
Pattern matching
37:49
по внешнему конструктору –
37:51
это ровное вычисление до weakly normal form.
37:53
rnf от nothing – это unit.
37:54
Отлично.
37:55

37:55
Мы уже вычислили
37:57
левую часть,
37:57
там просто nothing.
37:58
Он не принимает никаких других значений,
38:00
возвращаем unit.
38:01
Отлично.
38:02
А вот если у нас
38:03
just с x,
38:05
давайте вызовемся рекурсивно.
38:07
Попытаемся вычислить до нормальной формы.
38:10
rnf приводится как reduce to normal form.
38:13
Что, в принципе, логично.
38:14

38:15
Пропихнем rnf внутрь, попытаемся вычислить до нормальной формы x.
38:20
Именно из этого возникает constraint.
38:21
rnf data – a.
38:23
x имеет тип a, да.
38:25
Поэтому a обязан станцировать
38:27
type class rnf data.
38:29
Отлично.
38:29
Вот и все определение maybe.
38:31

38:33
Сейчас, наверное, на время.
38:36
Вот.
38:37
Death risk аналогично, совершенно прям.
38:41
Эквивалентное определение.
38:43
Мы вычисляем
38:44
аргумент до weakly normal form явно,
38:46
делаем pattern matching к логическому конструктору.
38:48
То есть, в принципе, возвращаем u сразу же, нам нечего больше вычислять.
38:51
И здесь у нас есть глава x и хвост xs.
38:52

38:54
Вычисляем голову.
38:57
Делаем seek.
38:58
Собственно,
38:58
seek как раз делается, чтобы мы явно вычислили голову.
39:02
Потому что, опять же,
39:03
seek вычисляет
39:04
левую вещь до weakly normal form.
39:07
Слева стоит rnf x.
39:08

39:10
То есть, мы уже будем вычислять до нормальной формы.
39:13
Поэтому seek достаточно.
39:15
Вот.
39:17
Да, мы вычисляем rnf x.
39:19
x имеет тип a.
39:20
Опять же,
39:20
из-за этого у нас имеет место constraint.
39:23
rnf t от a.
39:24
Ну и дальше вызываемся рекурсивно от хвоста.
39:25

39:26
И, собственно,
39:27
это все определяет rnf t для списка.
39:29
И deep seek тогда определяется почти как seek.
39:31

39:34
Deep seek b
39:35
это
39:37
вычисление a до
39:39
normal form seek b.
39:40

39:42
Seek обеспечивает нам однозначно
39:44
вычисление левой части.
39:45

39:47
Потому что,
39:47
если мы просто вернем b, очевидно,
39:49
если мы вернем b,
39:50
у нас a
39:51
уже будет не вычислено.
39:52
Это максимально бесполезная функция.
39:54
Это flip const.
39:56
Вообще-то.
39:57
А deep seek тогда был flip const.
39:59

40:00
Это бесполезная функция.
40:01
Поэтому
40:03
поставим seek,
40:04
чтобы вычислить a до нормальной формы.
40:07
Вот.
40:08
И из-за этого a обязан дистанцировать rnf t.
40:11
И такая такая страница.
40:12
Вот.
40:14
То есть, это ответ на вопрос, почему нам нужен type class для deep seek.
40:16

40:18
Потому что для
40:19
соответствующих типов данных
40:21
кастомных,
40:22
они имеют кастомную структуру.
40:25
И для соответствующих кастомных структур можно, конечно же,
40:29
сейчас я уже ухожу в дебри того, что будет потом.
40:33
Очень потом.
40:34
Можно, конечно,
40:35
на самом деле сделать
40:38
кажется,
40:38
реализовать какой-нибудь nf data для
40:41
произвольных типов.
40:42
А вообще произвольных с помощью tplate haskell'а, кажется.
40:44

40:45
Кажется, в таком машинаре можно просто произвести.
40:48

40:49
Но лучше просто делать
40:51
мануально, мне кажется.
40:51

40:52
Мануально
40:53
делать instance nf data, потому что, конечно,
40:56
структуры кастомные.
40:59
Ваши суммы типов, ваши определения, они все кастомные, зависит от того,
41:03
сколько у вас там полей в ваших структурах.
41:05
Вот всех нужно вычислить с помощью
41:08
pseek'а
41:09
и вызвав rnf от полей.
41:10
Вот и все.
41:11

41:15
Да, вопрос есть.
41:15
 
41:17
Нельзя,
41:18
разве,
41:19
через
41:19
генерики, очевидно,
41:21
задеравить
41:22
структуру реализации nf data?
41:24
Ну, типа, надо просто пройти по всем вариантам, для
41:27
каждого варианта вызвать рекурсивно для всех полей.
41:29

41:31
Да,
41:32
ну,
41:32
то, что я упоминал сейчас,
41:34
это не делается на обычном haskell'е,
41:36
это делается
41:37
в tplate haskell'е.
41:40
Я,
41:40
мне кажется, это даже можно.
41:41

41:42
Потому что tplate haskell'е позволяет
41:44
анализировать
41:46
уже в рамках языка haskell'а то,
41:49
как у нас сконструированы наши типы данных.
41:52
Какие там конструкторы
41:53
и какие там поля.
41:54
Да,
41:54
совершенно верно,
41:56
вот это как бы эдскин того,
41:57
как можно сделать
41:59
nf data запросто, бесплатно.
42:01

42:02
Пройти по всем кейсам,
42:04
по всем полям,
42:04
вызвать rnf от всех полей и сделать
42:06
ряд секвенсов и все.
42:07
Да, согласен.
42:07

42:08

42:09
Это именно тот способ,
42:10
который я говорю.
42:11
Но это просто сложно, там нужно использовать tplate,
42:13
сложно кому-то, кому-то нет.
42:14

42:16
Нужно использовать tplate haskell, а tplate haskell'е мы поговорим,
42:20
не мы,
42:20
а с кем-то другим, мне кажется, поговорим потом на лекции 10 или 11.
42:24
Сейчас пока 8.
42:26

42:27
Значит, тут есть ссылочка
42:29
про то,
42:30
как
42:31
избежать
42:33
многих
42:34
вызовов rnf, если у нас
42:37
строгие вычисления,
42:40
предпочтительные, извиняюсь.
42:40

42:41
И это делать с помощью такого типа данных, который называется once.
42:43

42:43
Вот он определен по этой ссылке.
42:44

42:44
Ссылка работает,
42:46
там все доступно.
42:48
Пойду посмотреть.
42:49
Вот.
42:50
Это весь deepseq.
42:51
Довольно
42:53
простая вещь,
42:54
довольно простой инструментарий для вычисления нормальной формы.
43:00
Микро-вопрос.
43:02
У всех от определений сам есть проблема.
43:04

43:06
У всех у всех есть проблема.
43:07
есть проблема.
43:08

43:10
В чем заключается проблема каждого? Как и с fold.
43:17
Мы делали до этого,
43:20
что у нас типа,
43:20
если мы запутаемся на очень большом списке каком-то,
43:23
то мы
43:24
проиграем,
43:25
потому,
43:26
у нас очень трудно.
43:27
Просто как в конце будет огромное, огромное,
43:29
огромное выражение, которое никогда не вычисляется.
43:30
Справедливо.
43:32

43:32
Да, действительно.
43:33
Например, вот здесь кейс ровно fold.
43:35

43:36
У нас в аккумуляторе аккумулируется пеганский фланг,
43:39
который не вычислен до тех пор, пока мы не вернем его явно.
43:46
Тут нечего вычислять, тут x плюс реквизитный выставка.
43:48
Тут нужно ждать, пока список опустеет.
43:53
Это предотвратить чуть-чуть менее тривиально, чем fold, но тем не менее можно.
43:58
А здесь, в втором случае, это описывалось в лекции по 1.0, typeclass 1.0 и т.д.
44:09
Это то же самое ровно. Мы делаем плюсик, у
44:14
нас сами в кастингере аккумулируются значения,
44:19
и потом, когда мы делаем get сам, мы вычисляем сам.
44:23
Тогда уже этот гигантский фланг будет средуцирован.
44:27
Проблема в том, что там гигантские танки, которые не нужно
44:32
желательно вычислять, чтобы памяти не занимать больше, чем ожидается.
44:40
Да, пожалуйста, это же самая проблема.
44:44
Тут их 6, да? 6 переходов.
44:49
Значит, как это можно исправить?
44:54
Это просто больше инструментария в рамках языка Haskell,
44:58
который позволяет делать некоторые вещи более строгими.
45:03
Первая вещь, точнее, в рамках текущей секции нашей лекции, это bang by trans.
45:10
Опять же, наш аккумулятор слишком ленив, мы
45:12
хотим вычислять на каждой хвостовой рекурсии.
45:16
Мы можем добавить bang, то есть знак восклицания, ровно перед нашим аккумулятором.
45:23
Внимание, тут не должно быть пробелов.
45:26
Если нет пробелов, тогда это воспринимается как индексный оператор.
45:32
То есть тут ровно не должно быть пробелов.
45:35
Вообще не привык я к авторам текстов.
45:40
Значит, этот bang ставится единожды, и он вычисляет
45:44
то, что стоит после него, ровно после него.
45:47
То, опять же, weak headorable form.
45:51
Спойлеры, опять, будут маленькие проблемы. Сейчас мы до этого дойдем.
45:58
Раньше, для того, чтобы делать bang, необходимо было прописывать этот extension.
46:03
Если я правильно помню, в версии GHC 2021...
46:07
Какая-то версия GHC в годе 2021.
46:12
Это стало по умолчанию синтезатором Хаскова.
46:15
Я не уверен в этом, но я где-то видел эту новость.
46:18
Я не спермитировал, но надо попробовать.
46:23
Не писать bang patterns, а написать bang.
46:26
Если у вас все скомпилируется, то да, действительно,
46:29
это уже теперь по умолчанию часть синтезатора языка.
46:31
Но раньше bang patterns просто расширялся в языках Хаскова,
46:35
в котором можно было добавлять воскресенье ровно перед
46:38
тем, что мы хотим вычислить до weak headorable form.
46:41
Причем это делается единожды.
46:44
И это типа-типа раскрывает что-то наподобие вот этой вещи.
46:51
Причем, да, это определение ровно эквивалентно обычному самому.
46:57
То есть вычисляется это вот то же самое.
47:00
Что тут написано? Тут есть guard.
47:02

47:04
Guard можно опять же ставить в локальных связках без проблем.
47:08
Например, в where.
47:10
Очевидно можно.
47:13
Легальный синтаксис.
47:14
Мы делаем seek, ack, а тут false.
47:17
То есть это вернет false.
47:18
Мы вычислим ack до weak headorable form, вернется false.
47:21
Undefined никогда не будет вычислен, потому что это false.
47:23
Аck, guard, false, state.
47:24
Отлично.
47:25
Все.
47:26
Вот тут уже на этом моменте ack вычислен.
47:28
До weak headorable form.
47:30
Переходим в оставшиеся два кейса.
47:34
Вот еще.
47:35
То есть эти два определения типа-эквивалентны.
47:43
На самом деле можно сделать вместо ack,
47:46
ой, вместо вот такой вот машины можно сделать не guard,
47:51
а написать case, ack, off, нижнее подчеркивание, стрелка,
47:55
и дальше то, что стоит справа.
47:58
Потому что case expression в хаскеле,
48:00
именно case, это ровно та самая синтетическая конструкция,
48:05
которая позволяет вычислять до weak headorable form.
48:07
Ровно case.
48:09
Case это прям фундамент вычисления в хаскеле.
48:12
Вот и все.
48:14
Так.
48:16
Вопросы по bank-паттерну на текущий момент.
48:20
Если не есть, конечно.
48:22
Час, милосердце, час.
48:23
Никто не пишет, ну ладно.
48:31
Да, теперь пишите, отлично.
48:33
Так, окей.
48:35
Больше bank-паттерна.
48:36
Можно ставить банк-паттерны внутри конструкторов.
48:38
Например, здесь у нас есть конструкция запятая, есть два поля.
48:40

48:41
Вот я прописываю здесь банк внутри первого элемента пары.
48:47
То есть это будет что-то наподобие,
48:52
сейчас скажу,
48:55
g, это сахар следующий,
48:58
gb, стрелка case p, ровно case p of,
49:01
дальше у нас конструктор запятая,
49:04
x штрих y,
49:06
а потом у нас стоит банк у xа.
49:08
Мы делаем что?
49:09
Мы делаем case x штрих of,
49:12
x стрелкой, и дальше мы возвращаем список.
49:15
То есть мы явно делаем case еще,
49:18
пол, внутри него элемент нашей пары.
49:20
Теперь можно прописывать как глубоко,
49:23
как только захотим,
49:26
наши более сложные типы данных.
49:29
В лет-связках то же самое.
49:32
Лет...
49:33
Ну тут, да, это как жилье, только это локальная связка.
49:38
Тут явный паттерн-матчинг паре,
49:40
и первый элемент пары у нас будет чуть более строгим, чем по дефолту.
49:48
Более того, можно ставить backpattern, извините, в лямбде.
49:54
Напоминаю, это донотация,
49:56
это нам проследуется в bind, вспоминаем монады,
50:00
донотацию в монаде, это pop, bind, дальше лямбда x,
50:03
стрелка и так далее.
50:07
Можно ставить bang в аргументах лямбды.
50:11
Это как раз транслируется, лямбда x', стрелка, кейс x', off x.
50:16
Мы сделаем один шаг вычисления
50:20
до выходного формулы x', получим x, отлично, да, правильно.
50:25
Не x, извиняюсь, а нижнее подчеркивание.
50:28
У нас уже и так x' вычисляется.
50:30
То есть там просто кейс x, off.
50:33
Опять же, можно ставить bang в лямбдах.
50:37
На основе этого можно думать на тему того,
50:41
как мы можем вычислять
50:44
аргументы наших функций,
50:46
когда мы передаем аргументы к какой-то функции.
50:51
Помним доллар, обычная аппликация.
50:53
Аппликация с bang – это
50:57
строгая версия аппликации,
51:00
когда мы вычисляем наш аргумент, потом вызываем функцию f.
51:05
Это строжайшая версия аппликации
51:07
доллар-бэнг-бэнг.
51:08
Это когда мы делаем deep-seq, вычисляем x до
51:12
нормальной формы, потом уже передаем функцию f.
51:17
На самом деле,
51:18
вот тут, конечно, есть bang-паттерн, но я бы это написал через x-seq-fx.
51:25
Потому что мне кажется, это эквивалентная вещь.
51:27
Это как здесь, где deep-seq стоит,
51:32
мы вычисляем x до нормальной формы.
51:33
Это то же самое, что делает bang.
51:35
То есть это x-seq-fx.
51:37
Должно быть абсолютно эквивалентно тому, что написано здесь.
51:41
Но, тем не менее,
51:43
оба варианта максимально легальны.
51:45
То есть строгое вычисление аргументов и потом передаем функцию f,
51:49
и строжайшее вычисление аргументов до
51:51
нормальной формы, потом передаем эту функцию f.
51:54
Вот тут есть маленький примерчик, примерчик, да, русский язык,
51:58
примерчик того,
51:59
как мы можем использовать
52:02
строгое вычисление.
52:04
Мы тут униформально,
52:06
что происходит?
52:08
Господи, униформально, то есть uniform distribution,
52:12
генерируем чиселки от 1 до 10.
52:14
От 1 до 10, конечно, исключительно, если я правильно помню.
52:17
У нас будет список разнообразных элементов.
52:19
Делаем sum, но мы при этом вычисляем sum.
52:21

52:24
С учетом,
52:26
с надеждой на то, что sum здесь тоже довольно строгий.
52:31
Сейчас я скажу вещь, надеюсь, будет понятно.
52:34
sum sum,
52:35
первое sum это s, это вот sum,
52:37
это русское sum, да, а второе sum это вот сум, сам сум.
52:41
Сам сум может быть не строгим, но он вычисляется, потому что у нас
52:45
доллар black стоит. Но желательно, чтобы сум был строгим.
52:49
Потому что вот, опять же, мы это уже обсудили.
52:52
Соответственно, чисел желательно, чтобы было строгим.
52:55
Потом мы дойдем до всех кейсов,
52:57
которые мы рассматривали на протяжении, например, части лекции.
52:59

53:01
Вопрос к собственно зрителям,
53:04
ну и вам тоже, очевидно.
53:05
Чем отличаются две функции f1 и f2?
53:17
Есть идеи?
53:22
Казалось бы, ничем.
53:24
Ну, потому что, когда мы решили банк паттерн,
53:27
в первом случае на пару, у нас пара, как бы,
53:29
запятая это уже конструктор.
53:31
Ну вот, собственно, он и есть вычисленный.
53:33
Да, максимально справедливо мы, да, спасибо большое,
53:37
мы вычисляем запятую до выхода термоформ,
53:41
получаем запятую, ничего не меняется.
53:42
То есть, когда мы пишем здесь явно, на самом деле,
53:46
потормачиваемся по структурке здесь, вот тут вот, да,
53:50
мы вот ровно это и производим.
53:51
Мы производим, как я уже говорил
53:53
миллион раз
53:55
вычисления до выхода термоформ.
53:57
Поэтому эти две…
54:00
У меня слышно?
54:01
Интернет у меня работает? У меня слышно? Алло?
54:04
Да, все слышно, все хорошо.
54:05

54:07
Да, мне просто написано, что интернет пропал.
54:09
Окей, сори, господи.
54:11
Так, спокойно.
54:13
Было бы плохо, если бы интернет пропал
54:17
и набегнуло в лекции.
54:17

54:19
Да, в общем, ничем они друг от друга не отличаются.
54:22
Вот.
54:23
А теперь поговорим про
54:25
полярную противоположность bng,
54:28
которая называется Lazy Pattern Matches.
54:30
Раньше, вроде, как-то это имело название irrefutable pattern,
54:35
что, на самом деле,
54:36
с точки зрения английского языка, тоже логично.
54:38

54:40
Выглядит оно вот таким вот образом.
54:44
Значит, что тут прикол?
54:46
У нас есть f от пары abm.
54:47

54:50
Ну да, мы делаем, опять же, паттерн-матч, мы делаем
54:53
редукцию до weakly normal form,
54:55
достаем этот первый элемент, делаем const 1a.
54:58
Ну, const 1a вычислится до единицы,
55:01
это так понятно, число.
55:03
Определение const.
55:04
Но, на самом деле, эта пара слишком строгая.
55:09
Казалось бы, в чем?
55:10
Ну, какая разница? Ну, пускай будет строгая.
55:13
Проблема в том, что если мы сделаем f от undefined, то будет undefined.
55:17
Спойлер к следующей части этого слайда.
55:21
f от undefined, несмотря на то,
55:23
казалось бы, у нас const 1, от чего-то, неважно от чего,
55:26
он выходит в единицу, если мы передадим const 1 в любой аргумент.
55:31
Хочется, чтобы f от undefined означало единицу тоже.
55:35
Для этого существует,
55:38
уже,
55:39
если я правильно помню,
55:41
именно вот часть английского языка Haskell, тильда.
55:43
Похоже на bang.
55:45

55:46
Опять же, пишите тильды вместе с тем, что стоит справа.
55:48
Без пробела.
55:51
Иначе это ух, иначе это равенство типов.
55:53
И это уже будет потом.
55:55
Это будет
55:57
лекция, опять же, 10, 11, 12.
55:59
Не помню.
56:01
Вот. Тильда.
56:02
Значит, что делать тильдом?
56:04
Значит, я сейчас скажу... Нет, давайте я сделаю так.
56:06
Я сейчас копирую функцию, у меня же открыт блокнотик. Я специально его подготовил.
56:11
Тот самый, в котором я уже писал миллион раз.
56:13
Видно, да, что я пишу здесь?
56:18
Друзья?
56:21
Это закомментирую пока. Ну, в смысле, это не Haskell, но не важно.
56:25
В общем,
56:26
по что трансформируется
56:29
типа вот этого вот тильда?
56:31
Значит, еще раз, тильда называется lazy pattern match.
56:35
Когда я пишу здесь тильду,
56:37
и дальше мы делаем pattern matching явно,
56:40
это трансформируется в следующую вещь.
56:43
Сделаю align.
56:45
g от p.
56:47
Именно от p.
56:49
p это просто идентификатор.
56:51
И не больше.
56:53
То есть мы не паттерматимся в этом прикол.
56:55
Вот тут
56:57
проблема в том, что тут стоит a.
56:59
Очевидно, откуда a взялось.
57:01
Тут стоит a, и не очевидно, откуда a взялось на первый взгляд.
57:03
На самом деле очевидно, но не важно.
57:05
Вот это вот a, это первый элемент.
57:08
Вот это вот a, это f of t, p.
57:09

57:12
То есть когда мы тут заполучаем какие-то элементы в нашем
57:17
pattern matching,
57:18
в смысле не элементы, а поля,
57:20
а это поля, пары,
57:23
то когда мы делаем тильду, опять же,
57:27
пары больше нет. У нас есть просто произвольный p.
57:30
Его не вычисляем в этом прикол.
57:31

57:32
Тут как бы стоит не f of t,
57:35
а вроде как чисто более формально лямбда p стрелка
57:39
кейс p of a, стрелка a.
57:42

57:43

57:47
Ну или вот лямбда кейс, давайте я сделаю вот так вот.
57:51
Да, так лучше.
57:54
Вспоминаем лямбда кейс, мы его проходили.
57:57
Вот.
57:58
Итого. И refutable pattern,
58:01
то есть lazy pattern matching, трансформирует то, что мы pattern matching в
58:06
индикатор 1,
58:08
тут это я назвал tp,
58:10
и поля становятся
58:12
то же самое, что селектор.
58:14
Это селектор.
58:15
Мы берем нашу пару
58:19
и возвращаем левую часть.
58:21

58:22
То же самое, что левая проекция нашей пары.
58:24
Мы называем батлок.
58:26
Вот, это селектор.
58:28
Что прикол функции j?
58:30
В том, что если мы произведем здесь undefined,
58:32
вот тут уже предупредим undefined для j, поскольку мы явно не
58:36
pattern matching на самом деле.
58:39
Тут будет undefined, const, по определению конста не вычисляет
58:43
правую часть, он ленив по второму аргументу.
58:46
Возвращает единицу.
58:50
И написано здесь,
58:51
что делает refutable pattern.
58:53
Я уже сразу не хочу больше пока что уходить по атлантику.
58:58
Если непонятно, я снова вернусь по атлантику, поясню.
59:01
Значит, это jp
59:02
равно const 1, и тут селектор левого аргумента, левое поле p.
59:08
Я уже говорил about undefined, потому что мы тут
59:10
pattern matching, мы вычисляем наш аргумент
59:13
по первому форму явно.
59:14
В j мы не вычисляем, потому что стоит тильда.
59:16
Вот и все.
59:18

59:20
List-нестройность нам, казалось бы, не очень нужна.
59:22

59:25
Вот.
59:26
И refutable patterns
59:29
активно используют в тех местах,
59:33
где у нас один
59:34
конструктор, как у пары, и много полей.
59:36

59:39
Вот я сказал один конструктор.
59:40
Почему важно, что там один
59:42
конструктор? Вот почему.
59:45
LazyHat.
59:46
Смотрим на LazyHat.
59:47
У нас везде refutable patterns.
59:50
Везде refutable lazy pattern matches.
59:54
Приков в следующем.
59:56
В этой строке, опять же, у нас стоит тильда.
59:58
Тильда.
1:00:05
..
1:00:05
список трансформируется в просто L.
1:00:08
Опять же, я отдал название идентификатору L.
1:00:11
Фреш, например.
1:00:14
Это трансформируется в LazyHat.
1:00:15
fresh равно undefined.
1:00:18
Но LazyHat.
1:00:20
fresh,
1:00:22
где фреш – это просто
1:00:24
аргумент, не вычисленный, равен undefined, уже вот здесь, на первом определении,
1:00:30
будет возвращаться undefined на любых аргументах нашего списка.
1:00:34
Каковый мы список не передали.
1:00:36
LazyHat от пустого списка – undefined.
1:00:37
Потому что LazyHat от любой, опять же, fresh state,
1:00:41
любой идентификатор – undefined.
1:00:42
LazyHat от списка 1.2.3 – undefined.
1:00:48
Вот этот кейс второй, он redundant,
1:00:51
он ненужный, потому что второй кейс
1:00:55
трансформируется в LazyHat.
1:00:56
fresh равен
1:00:57
Hat.fresh.
1:00:59
Hat – это, опять же, перед головой.
1:01:04
Опять же, у нас происходит кейс по всем
1:01:08
аргументам, всем
1:01:10
случаям сверху вниз.
1:01:13
У нас этот кейс будет удовлетворен моментально,
1:01:15
потому что это кейс по произвольному аргументу, там, опять же, fresh.
1:01:19
Давайте я буду говорить L.
1:01:21
L списка, да?
1:01:22
Вот.
1:01:25
Вопрос вам.
1:01:27
Что будет, если мы поменяем местами
1:01:29
эти два случая?
1:01:31
Напоминаю, что здесь undefined у любого списка.
1:01:34
Что будет, если мы поменяем местами два случая?
1:01:35
То есть это станет первым случаем, а это вторым.
1:01:40
Ваше мнение.
1:01:53
На пустом списке
1:01:54
паниковать будут.
1:01:57
Как именно?
1:01:58
Да, как именно?
1:02:01
Ну, типа, типа, что,
1:02:02
скажем, откуда
1:02:04
возникает пустой список.
1:02:09
Можно не точно, можно вербально, я пойму.
1:02:17
Строго говоря,
1:02:18
когда у нас пустой список, он как бы подходит как
1:02:21
раз таки, когда мы достаём голову из нашу списка,
1:02:23
но при этом уже не знаем, что там за голова, потому что там пустой список.
1:02:27
Какая-то ошибка тогда будет.
1:02:29
Ошибка будет в том, что у нас
1:02:31
просто
1:02:36
будет написано non-exhaustive cases.
1:02:40
Помним, или,
1:02:41
сейчас, дайте я подумаю.
1:02:44
Да.
1:02:46
Потому что, опять же,
1:02:47
lazy head это что-то на подобии lazy head p равен head p.
1:02:50
То есть lazy head от этой списка равен head.
1:02:54

1:02:56
Head это частичная функция, partial function.
1:02:58
Она не определяет до пустого списка.
1:02:59
Ну, типа того, да.
1:03:00
То есть, если, опять же, это кейс первый, то lazy head от пустого списка будет
1:03:05
паниковать и с ошибкой на подобии non-exhaustive patterns.
1:03:10
Либо non-exhaustive patterns, то есть не все паттерны были
1:03:15
учтены,
1:03:16
либо вот та самая ошибка в head.
1:03:20
Нет, неправильно.
1:03:21
Не та самая ошибка в head.
1:03:23
Я объясню, почему.
1:03:25
Всё просто.
1:03:25
Вы видите, я тут написал fst.
1:03:28
Написал бы тут fst,
1:03:30
была бы одна вещь.
1:03:31
Но здесь, опять же, lazy head от fresh равен head fresh, это некорректно.
1:03:38
У компайлера нет доступа к стандартным селекторам.
1:03:41

1:03:43
Тут не head стоит, тут стоит
1:03:46
case
1:03:48
a
1:03:49
colon
1:03:53
underscore a Вот именно поэтому возникает non-exhaustive patterns.
1:03:58
Один паттерн здесь.
1:04:01
Это конс.
1:04:05
Поэтому в случае,
1:04:08
если этот кейс первый, у нас будет, к сожалению,
1:04:11
non-exhaustive patterns.
1:04:12
А если у нас голова,
1:04:16
если у нас конс стоит,
1:04:18
то вернее лazy head от конса.
1:04:26
Тут уже всё просто.
1:04:28
Come on.
1:04:29
То, что и должно быть, всё хорошо будет.
1:04:32
Да.
1:04:33
У нас паттерн удовлетворяет кейсу, который я написал в платнотике.
1:04:37
Прямо голову, всё хорошо.
1:04:40
Именно из-за таких вещей
1:04:41
lazy pattern matches не используют,
1:04:44
и это опасно на самом деле, не используют в
1:04:48
вот это ещё бесполезно, в сумме типов.
1:04:49
Это используют в произведении и больше ни в чём.
1:04:53
Это когда у нас есть дата, отдельный конструктор и множество полей.
1:04:58
У вас были трансформеры, я знаю, у вас они были на
1:05:01
прошлой лекции,
1:05:03
в смысле, 2 недели назад.
1:05:06
3 недели назад.
1:05:08
Да, 3 недели назад.
1:05:10
Вот там обсуждался стейт.
1:05:11

1:05:13
И даже райтер,
1:05:15
райтер t, стейт t.
1:05:16
Вот там, если взглянуть на source,
1:05:18
в стейт t используются illegal patterns,
1:05:21
потому что там не нужна лишняя строгость в паттерн-матчике по паре.
1:05:24
Не нужна просто.
1:05:27
Вот всё.
1:05:29
У пар 1 конструктор, там множество полей, вполне себе
1:05:33
не то, что это
1:05:35
легальный способ использовать
1:05:38
lazy pattern matches, так ещё и
1:05:42
предпочтительный.
1:05:43
Это по этой причине.
1:05:44

1:05:46
f1 очень тупая функция, принимает either и int, тут написано write1,
1:05:53
но это вообще не важно, что тут стоит.
1:05:56
Это tilde, в этом прикол.
1:05:58
Во что превращается f1 tilde write1 равно 42?
1:06:02
Превращается это в f1 fresh равно 42.
1:06:03
Fresh это что?
1:06:06
Вот.
1:06:08
То есть f1 здесь,
1:06:09
вот это же const, реально,
1:06:11
но это const 42.
1:06:15
Игнорируем аргумент, который стоит здесь.
1:06:18
Возвращаем 42.
1:06:19
Факт того, что мы его не вычисляем, факт того,
1:06:22
что он ленивый, что стоит tilde, что f1 fresh,
1:06:24
то есть underscore неважно,
1:06:26
позволяет нам писать здесь left.
1:06:29
Максимально элементарно.
1:06:32
И даже
1:06:34
пытаться выбросить ошибку в наш
1:06:37
irrefutable pattern
1:06:38
всё ещё вернуться в 42.
1:06:40
Потому что это не вычисляется.
1:06:42
Это lazy pattern match.
1:06:44
f1 fresh равно 42.
1:06:47
Ну, опять же,
1:06:49
конечно,
1:06:49
это функция безопасная,
1:06:51
это просто const 42.
1:06:53
Но, да, тут сумма типов тоже не очень безопасна
1:06:57
в общем случае, как с lazy pattern, да?
1:07:01
Вот.
1:07:02
Поэтому лучше так не делать, наверное.
1:07:03

1:07:05
Или просто писать f1 равно const 42, раз уж приспичили.
1:07:09
Вопросы по lazy pattern match.
1:07:11
Что дальше?
1:07:12
А, окей, strict Haskell.
1:07:14
Мы подходим к концу первой части лекции.
1:07:24
Окей.
1:07:26
В общем,
1:07:28
где ещё могут использоваться bank patterns?
1:07:30
Мы уже узнали, что могут использоваться в лето-байдингах
1:07:33
локальных, в аргументах конструкторов внутри полей.
1:07:38

1:07:40
А также можно использовать bank patterns в самих полях типов данных.
1:07:45

1:07:46
Так как здесь у нас есть конфиг,
1:07:48
это что, просто
1:07:50
экстракт, там есть int, есть map-settings, users и extra.
1:07:52

1:07:54
Мы хотим, если мы хотим,
1:07:56
сделать так, что у нас
1:07:57
int и map-settings были строгими.
1:08:00
Всегда.
1:08:02
А элементарно давайте мы ставим bang-bang'и
1:08:06
именно в типах,
1:08:09
не вот перед users и extra, а именно в типах.
1:08:12
Тогда users и extra будут всегда вычисляться на выход-нормал-форм.
1:08:17
Проблема в следующем.
1:08:19
Казалось бы, у нас,
1:08:20
опять же, у maybe есть локотструктура nothing-adjust,
1:08:24
nothing-adjust уже прибывает выход-нормал-форм.
1:08:25
Тут нужно пытаться понять,
1:08:29
имеет ли смысл поставить bang в maybe.
1:08:30

1:08:33
Если bang делает то же самое ровно, что делают другие bang'и.
1:08:36
На мой взгляд, нет.
1:08:39
Ну, потому что мы вычисляем… Нет, ну окей, ладно.
1:08:42
Это стретч, с моей стороны.
1:08:44
Возможно, это имеет смысл, потому что даже, несмотря на то,
1:08:47
что там тут stack-maybe-settings, то, что
1:08:50
если у нас есть just от какого-то settings,
1:08:52
он не будет вычислен,
1:08:53
то, что just будет вычислен хотя бы до just, а не до ничего, уже что-то.
1:08:59

1:09:01
Несмотря на то, что это stack-maybe.
1:09:03
То есть, если вдруг реально нам не нужно что-то больше, чем выход-нормал-форм,
1:09:07
пожалуйста, ставьте ваши bang'и без проблем.
1:09:09

1:09:10
А вот у всяких таких полей как int или опять же те же самые bool, char…
1:09:14
нет, не bool, не bool.
1:09:17
char, double, word и так далее.
1:09:20

1:09:22
Вот там
1:09:22
реально ставят bang'и.
1:09:25
И это работает.
1:09:27
А если мы хотим, чтобы
1:09:28
в нашем файле у всех типов данных были строгие поля,
1:09:32
тогда можно просто добавить прогму strict data и не ставить bang'и.
1:09:37
Нигде.
1:09:38
То есть, возникает вопрос,
1:09:39
а что, если мы хотим, чтобы во всем модуле
1:09:42
все было строгим?
1:09:44
Потому что мы мазохисты.
1:09:47
Можно тогда ставить strict прогму, делать все строгим по умолчанию.
1:09:54
Ее не используют, кажется,
1:09:57
так часто,
1:09:59
как возможно ожидается кем-то из вас или каким-то другим человеком.
1:10:05
Потому что, ну,
1:10:06
смысла в тотальной строгости, наверное, не совсем есть.
1:10:10

1:10:12
Смысл совсем есть.
1:10:14
Более того, вы, наверное, успели познакомиться с тем, что вот есть
1:10:17
в ваших проектах package.yaml, в которых можно
1:10:22
указать внимание, включенное extension по умолчанию.
1:10:24
Представьте, что вы указываете strict по умолчанию,
1:10:27
как extension project-wide, то есть в вашем проекте.
1:10:29
Тогда у вас весь
1:10:32
ваш проект станет строгим.
1:10:37
Я никогда в жизни такого не видел, чтобы это было,
1:10:40
и надеюсь, никогда в жизни не увидишь, потому что мало смысла
1:10:44
в тотальной строгости Haskell.
1:10:46
Один PR Haskell просто вперед и пропадает. Его не используют.
1:10:50
Стрикт экстенсивно.
1:10:51
Но strict.
1:10:53
id используют однозначно.
1:10:55
И в нем есть смысл.
1:10:59
Да.
1:11:00
Естественно, как уже много раз
1:11:04
обсуждалось, строгие поля
1:11:07
позволяют избежать space leaks.
1:11:08
Space leaks, опять же, это те самые случаи, когда у нас оказываются гигантские
1:11:11
фанки в нашей памяти, которые вычитаются очень потом.
1:11:13
Это space leak.
1:11:16
Это у вас уже наверняка было.
1:11:17
Например, в C++, кажется.
1:11:20
То есть это было сколько лет назад?
1:11:22
Полтора, да?
1:11:24
Короче, это было давно. Неважно.
1:11:26
Вот.
1:11:28
Все, это strict Haskell.
1:11:31
Да, тут, короче, есть еще блог-пост от Романа Чепляки
1:11:34
о том, сколько занимает 8-битный интеджер в C и Haskell.
1:11:36

1:11:37
В этом блог-посте еще Роман также упоминает то, как в Haskell
1:11:44
представляются
1:11:45
значения в памяти, да.
1:11:46
Я это тоже себе затронул в конце лекции.
1:11:50
Это более интересная вещь. На самом деле, это
1:11:53
уже
1:11:54
slightly
1:11:56
advanced Haskell, типа того,
1:11:58
на уровне компилятора.
1:12:00
Но я остальное затронул, потому что это интересно.
1:12:02
Это все еще не компилятор, казалось бы,
1:12:04
все еще на уровне Haskell, но более advanced штуки.
1:12:06
Это затронул в конце лекции.
1:12:08

1:12:10
Итого, сейчас мы будем на 20-минутной,
1:12:13
резюмируя, что делают,
1:12:15
когда можно использовать strict evaluation.
1:12:17
Вот когда у нас
1:12:19
есть некоторые ленивые подчисления, которые, к сожалению, возвращают
1:12:22
out of memory, ну, не с такой workflow, как тут написано почему-то,
1:12:27
можно
1:12:29
проанализировать вашу программу, выяснить, в каких местах у вас используются
1:12:35
слишком ленивые подчисления, которые можно сделать более строгими.
1:12:39
В том числе, когда у нас имеются арифметические операторы
1:12:42
по, скажем, примитивным типам.
1:12:45
Например, int, double, float,
1:12:48
хоть chart, какая разница.
1:12:49

1:12:52
Тогда можно использовать строгость по этим аргументам.
1:12:55
Например, если мы, опять же,
1:12:58
делаем свертку,
1:13:00
например, левую,
1:13:01
мы можем
1:13:03
сделать строгим
1:13:05
наш аккумулятор.
1:13:07
Если мы, например, сворачиваем наш список или любую
1:13:10
произвольную структуру по сложению.
1:13:16
В случае, когда у нас возникают всякие
1:13:19
состояния высовывания функций внутри памяти.
1:13:20

1:13:21
Из-за этого можно сразу вычислить h от x, как здесь.
1:13:25
Вычисляем h от x,
1:13:27
потому что тут стоит банк.
1:13:29
Потом мы передаем это g.
1:13:34
Или можно ставить банк у x.
1:13:36
Тогда x будет строгим, то есть мы вычислим x.
1:13:42
h от x, конечно, sorry,
1:13:44
g от h аргумента,
1:13:46
x будет в памяти,
1:13:48
но хотя бы у нас x вычислится.
1:13:50
Вот эти два примера, они как бы
1:13:52
разные на самом деле, потому что вычисляется h от x, а тут именно x.
1:13:57
Очевидно,
1:13:59
кейсы фундаментально отличаются.
1:14:01
Тем не менее, они используются.
1:14:04
Ну и,
1:14:05
как я уже говорил недавно,
1:14:07
поля данных, чтобы
1:14:09
изображать очередных кейсов офф SpaceLeaks.
1:14:12

1:14:15
Вот.
1:14:16
А, нет-нет-нет,
1:14:20
я совсем забыл про эту часть лекции.
1:14:23
Да,
1:14:24
я оборачиваю еще 6 минут, потом уйду на перерыв.
1:14:27
Немножко про SpaceLeaks.
1:14:29
И вот эта часть очень важная.
1:14:31
Давайте обсудим, что тут написано.
1:14:33
Функция pet.
1:14:36
Она вычисляет сумму списка, ну, сворачивает по список по сложению и нулю.
1:14:40
И длину.
1:14:41
Запекивает оба результата в пару.
1:14:45
Фух.
1:14:46
Вот этот вот SpaceLeaks, он неизбежный.
1:14:48
Вообще.
1:14:52
Почему? Посмотрим следующее.
1:14:54
Допустим,
1:14:55
опять же, тут, наверное, возникнет сейчас,
1:14:58
вот тут нужно подумать, есть ли недетерминизм в том, что вычисляется сначала.
1:15:02
Я вот не знаю.
1:15:04
К сожалению, я забыл эту часть.
1:15:05
Хаскова.
1:15:08
Но, допустим,
1:15:09
сначала вычисляется левый аргумент пары.
1:15:11
Один из двух случаев.
1:15:14
Отлично.
1:15:15
Мы вычислили sum.
1:15:18
Чтобы вычислить sum,
1:15:19
необходимо сделать паттерн матча к пиксу.
1:15:22
До тех пор, пока мы не вычислим полностью нашу сумму.
1:15:23

1:15:25
Чтобы это завершилось, наш список должен быть конечным.
1:15:27
Это очевидно.
1:15:30
Мы вычислили sum.
1:15:32
Дальше мы вычисляем length.
1:15:34
Поскольку мы уже сделали кейс xs, причем
1:15:37
полный кейс,
1:15:39
мы полностью разанфолдили наш список, этот список сейчас будет
1:15:43
висеть в памяти до тех пор, пока мы не сделаем length и не завершим функцию bed.
1:15:47

1:15:50
То есть мы вычислим функцию sum, например.
1:15:52

1:15:53
Какой бы он ни был гигантский, он будет висеть в памяти до тех пор, пока мы
1:15:57
не вычислим length, не вернем результат и не завершим работу нашим списком.
1:16:01

1:16:03
Это unavoidable space leak.
1:16:06
Как быть?
1:16:10
Это мы уже обсудили, когда у нас здесь
1:16:14
возникает
1:16:16
типа строгий foldable по более сложным структуркам в аккумуляторе.
1:16:19
Это мы уже проходили.
1:16:21
Есть такая классная библиотечка от Кабриэла Гонзалеса, называется foldable.
1:16:25
Целый пакет,
1:16:27
в котором потеряет тип данных, сейчас я его напишу,
1:16:30
fold,
1:16:32
да, это fold,
1:16:35
он принимает два аргумента a, b, и
1:16:38
ух, сейчас вспомню.
1:16:41
В общем, это есть экзидентальный тип, тут ставится парол
1:16:45
x.fold и дальше три значения.
1:16:49
Это то, как мы сворачиваем,
1:16:52
а это наш элемент контейнера.
1:16:55
Например, это элемент нашего списка. Их это
1:16:58
начальное значение, а тут просто processing.
1:17:00
То есть, мы совершили наш fold, и дальше мы хотим вернуть просто из xа в b.
1:17:04
То есть, это
1:17:06
что-то после fold.
1:17:08
После fold, извиняюсь, после четвертки.
1:17:11
Финальная функция, собственно говоря.
1:17:13
Видели вот этот парол x?
1:17:14
Вот это то же самое, что экзидентальный тип.
1:17:16
Пока их не было, я потом упомяну еще экзидентальный тип
1:17:20
и объясню, что это такое на следующей части лекции.
1:17:22
Но fold
1:17:24
это такая вот функция, ой, функция, господи, тип данных, который капсулирует
1:17:29
переход
1:17:30
и изгибничный переход
1:17:32
в свертке начальное значение и постпроцессинг.
1:17:34

1:17:37
Да.
1:17:40
Вот.
1:17:40
И на основе этого типа данных тут реализуются всякие уже
1:17:44
встроенные вещи, как length, sum, понимание.
1:17:46

1:17:48
Вот length означает fold.
1:17:50
И fold является функтором и аппликативом.
1:17:52
Fold не является монадой.
1:17:55
Такие дела.
1:17:58
Что принимает fold?
1:18:04
Он принимает fold a, b,
1:18:05
принимает f от a.
1:18:07
f от a, помните, foldable, да?
1:18:10
f от a до t, там было t от a.
1:18:11
Это просто какой-то контейнер,
1:18:13
варганизованный типом a.
1:18:14
Возвращает к b.
1:18:17
Вот.
1:18:18
И
1:18:21
здесь,
1:18:22
поскольку там все это как композиция функции,
1:18:26
когда там возникает s-кабинатор, вторая аксиома в матлоге,
1:18:30
когда там возникает первая аксиома в матлоге, это pure и app, управление есть,
1:18:35
то там еще функции.
1:18:36
Это все
1:18:40
в итоге получается довольно строгим.
1:18:41
Там, кажется, какие-то есть
1:18:44
элементы фолда, которые вообще-то с bang'ами, я не помню, какие, я забыл. Блин.
1:18:49
Кажется, начальное значение с bang'ом.
1:18:51
Вообще логично, да? Неважно.
1:18:53
В общем, да.
1:18:55
И это просто позволяет
1:18:58
для типа произвольных структур
1:19:02
делать
1:19:04
приколюхи связанные с обработкой
1:19:08
структуры, свёртки и так далее.
1:19:09
А, ну это свёртка, собственно говоря.
1:19:11
Fold, между прочим, это левая свёртка.
1:19:13
Написано fold, но на самом деле это fold'у по фолду.
1:19:14

1:19:17
Короче, рекомендую посмотреть видео Габриэлы.
1:19:18
Она обсуждает вот реализацию фолда, но
1:19:25
моноидальной реализации фолда.
1:19:28
То есть у нее там другие
1:19:32
определения типа данных через моноид.
1:19:35
Но моноид конкретно тому, что вот в фолду.
1:19:36

1:19:38
Там всё довольно просто.
1:19:41
Очень классный данный.
1:19:44
А ещё
1:19:47
финальная финалочка, да? Да, финалочка.
1:19:49
Всё.
1:19:51
Вот немножко
1:19:52
про то, как
1:19:54
визуализируется Spacelix.
1:19:58
Вот здесь две картинки перед вашими глазами.
1:20:01
Слева по вертикальной шкале у нас байты, алоцированные с правой секунды.
1:20:04
А логично с правой части.
1:20:06

1:20:08
Здесь всё это хаскилные функции.
1:20:11
Сейчас надеюсь, что это всё видно.
1:20:12
Я не знаю, что зависит от качества трансляции.
1:20:15
Это всё хаскилные функции.
1:20:16
Можно заметить здесь, что тут
1:20:19
локация варьируется, но примерно константная на самом
1:20:22
деле, потому что там всё учитывается в левой части.
1:20:24
Там всё по релевантным аргументам строгое,
1:20:28
поэтому там не разрастаются фанки линейно.
1:20:32
Как это делается
1:20:33
справа? Можно заметить, что справа у нас есть
1:20:37
линейная зависимость от секунд и от байтов.
1:20:39
Внимание, вот здесь слева
1:20:40
мой кристалл виден, я даже вижу его.
1:20:43
Тысяча байтов. Тут миллионы, более того, тут сотни миллионов.
1:20:47
Вот здесь это уже примерно гигабайт.
1:20:50
Потому что
1:20:52
миллиард байтов.
1:20:54
Да, правильно.
1:20:56
Типичный пример спейслика.
1:20:57
Вот тут у нас разрастается фанк, который у нас начислен. Внимание, вот тут
1:21:01
приколчик
1:21:03
возникает с питфоллом.
1:21:04
Это гигантская пропасть.
1:21:06
Это что? А это завершение нашей функции.
1:21:09
Наша функция завершается,
1:21:11
производится вычисление фанка, он начинается довольно
1:21:14
быстро, там всё вычисляется в уже одно значение,
1:21:17
и аллокация теперь уже более адекватная.
1:21:18

1:21:21
Поэтому этот питфолл это непосредственно
1:21:24
вычисление аргумента после завершения функции.
1:21:26
Явно тут графы, а не тут линейные.
1:21:29
Но в зависимости от того,
1:21:30
какого space complexity именно space complexity.
1:21:34
Вот графы может быть хоть как парабола
1:21:38
выглядят, хоть как логарифм, хоть как logstar.
1:21:40
Я никогда в жизни не видел алгоритм, у которого бы space complexity был logstar.
1:21:44

1:21:47
Никогда в жизни я не видел такого алгоритма.
1:21:48
Я не знаю, как это работает, и есть ли такой
1:21:52
алгоритм, у которого logstar space complexity.
1:21:54
Но, тем не менее, наверняка можно придумать.
1:21:56
Короче говоря,
1:21:57
шейп вашей зависимости
1:22:00
отражает то, как у вас разрастаются ваши танки.
1:22:02
Тут это линейная зависимость.
1:22:05
Во всех функциях почти.
1:22:07
Вот.
1:22:09
Да.
1:22:10
Вот как вы детектите space leak.
1:22:13
Смотрим по батикам.
1:22:15
Смотрим на то, какой у вас граф.
1:22:16
Желательно, чтобы там у вас все, конечно, было константное.
1:22:19
То есть все прочиталось мгновенно по релиматным аргументам.
1:22:23
Все. Окей.
1:22:25
Эта часть лекции завершилась.
1:22:26
Давайте уйдем на перерыв. Я пока завершу запись.
1:22:33
Чпок.
1:22:34
Окей.
1:22:35
Вторая часть будет посвящена мутабельным объектам и дефористейшну.
1:22:39
И как резолвить дефористейшн. Ой, как резолвить,
1:22:41
наоборот, дефористейшн — это способ резолвить
1:22:44
промежуточные представления в памяти.
1:22:47
Итак.
1:22:49
Собственно, дефористейшн — это механизм, который позволяет
1:22:52
предотвращать или... Да, правильно. Предотвращать
1:22:55
промежуточные структурки в памяти.
1:22:58
У нас есть несколько типичных примеров промежуточных структур, наподобие
1:23:04
следующей ситуации.
1:23:05
Более того, ситуация первая с мапами.
1:23:07
Я ее упоминал, я помню,
1:23:09
что я упоминал ее в лекции
1:23:13
по type-классам, которые... То есть она сейчас
1:23:17
затрагивала то, что у type-классов есть некоторые правила.
1:23:21
Вот эти некоторые правила как раз таки можно
1:23:25
использовать, чтобы избавиться от промежуточных
1:23:28
представлений в памяти.
1:23:30
А что это такое?
1:23:31
Откуда возникают
1:23:35
промежуточные представления?
1:23:37
Посмотрим на левую часть.
1:23:38
В левой части у нас есть mapf.
1:23:39
mapr.
1:23:41
Мы придаем список,
1:23:43
по нему один раз применяем функцию, по нему второй раз применяем функцию.
1:23:47
Когда мы применяем функцию g,
1:23:51
то мы заотводили весь список, весь список у нас
1:23:56
теперь находится в памяти, и там ко всем элементам
1:23:58
функция g применена.
1:23:59
Она будет висеть в памяти,
1:24:02
пока мы не применим функцию f, не завершим работу с нашими двумя мапами.
1:24:06

1:24:08
Это два траверсала
1:24:09
одного и того же списка.
1:24:11
Потому что или два, список будет оставаться, это прям как в ситуации с
1:24:18
собственно, бетом, с первым бетом.
1:24:20
Из-за того, что у нас два траверсала списка, у нас из-за этого возникает
1:24:25
промежуточное представление списка в памяти.
1:24:27
Только здесь оно именно промежуточное.
1:24:29
Потому что результат, это должна быть композиция функции f и g.
1:24:34
Поэтому это называется
1:24:36
промежуточная представление.
1:24:37
Потому что мы пока что применим только функцию g, а нужно применять еще функцию f.
1:24:41
Мы знаем, что есть функциональный
1:24:44
ло,
1:24:45
который говорит о том, что mapf.
1:24:47
mapj равен mapf.j.
1:24:50
Перк этого
1:24:51
правила в том, что у нас один траверсал, один проход по списку,
1:24:55
мы сразу применяем элементную функцию f от g,
1:24:59
применяем g, потом f.
1:25:01
И все.
1:25:02
Мы ничего не храним в памяти
1:25:08
промежуточного и лишнего,
1:25:10
у нас один траверсал.
1:25:11
Это хорошо.
1:25:13
По идее, аналогичная вещь в самом.
1:25:14

1:25:17
Мы
1:25:18
приезжаем по списку,
1:25:21
потом делаем сам.
1:25:22
Мы проехали по списку,
1:25:26
а потом мы свернули список.
1:25:28
И когда мы прошли по списку, у нас есть
1:25:30
список в памяти, который мы потом сворачиваем.
1:25:32

1:25:34
Зачем хранить список в памяти, если мы его рано или поздно сворачиваем?
1:25:38
Можно ведь это сделать сразу же.
1:25:41
И скоро будет алгоритм,
1:25:43
как сделать из вот такой вот страшной вещи,
1:25:49
наподобие того, что написал здесь,
1:25:51
вещь, которая избавляет нас от промежуточных представлений.
1:25:55
Вот следующий слайд.
1:25:56
А пока затронем еще третью строку от filterp.
1:26:00
mapf.
1:26:02
Мы опять же приезжаем по списку, применяем функцию f, потом фильтруем наш список,
1:26:09
оставляем только те f от x,
1:26:11
которые реально притягают у p.
1:26:14
Причем,
1:26:15
опять же,
1:26:16
эта функция filterp.
1:26:18
mapf работает еще и для бесконечных списков,
1:26:20
по причине того,
1:26:22
что все ленивое.
1:26:25
У нас, например, список бесконечный, он всегда не пустой.
1:26:29
Мы из мапы вытаскиваем gold,
1:26:32
потом этот gold обрабатываем фильтром.
1:26:35
И, например, если мы делаем take 10 от filterp.
1:26:37
mapf.
1:26:41
l, то надо, чтобы у нашего бесконечного списка было хотя бы 10 элементов
1:26:48
f от x, которые притягают у p.
1:26:49

1:26:51
А мы хотим сделать аналогичную функцию,
1:26:54
которая тоже будет работать для бесконечных списков,
1:26:57
но в которой один треверсал.
1:26:58
Тут треверсалов, опять же, два.
1:27:04
Хочется, чтобы у треверсалов была одна штука.
1:27:08
Чтобы не было,
1:27:09
опять же,
1:27:11
прогружечных представлений наших списков.
1:27:12

1:27:13
А прикол в финальной строке в том,
1:27:16
что мапа, а потом фолдер, можно заменить на фолдер от композиции.
1:27:20
Ровно она и есть.
1:27:20
Причем ровно в таком виде.
1:27:23
f – это функция из fb,
1:27:24
f – это функция из b, функция из cfc.
1:27:25

1:27:28
f.g – это функция из a, функция из cfc.
1:27:32
Та же самая сигнатура.
1:27:34
Фолдровская, так сказать.
1:27:37
Поэтому
1:27:39
композиция вполне валидная.
1:27:40
И более того, мы
1:27:41
сразу же сворачиваем наш список.
1:27:43
Что удобно.
1:27:44
Опять же, у нас один треверсал по списку.
1:27:49
Перед тем, как мы перейдем к алгоритму,
1:27:52
мануальному алгоритму
1:27:53
произведения Deforestation, давайте мы перепишем map немножечко.
1:27:55

1:27:56
Ну, map определяется каноническим образом по паттерн-матчингу
1:28:00
по второму аргументу, конечно же, нашему списку.
1:28:06
конечно, паттерн-матчинг по аргументу сразу же – это
1:28:08
на самом деле четный потопей сахара к кейс-экспрессиону.
1:28:13
У нас, как я уже говорил, кейс-экспрессион, кейс-форажение – это фундаментальная
1:28:17
составляющая, которая вычисляет наши значения.
1:28:21
Именно кейс-форажение это производит.
1:28:23

1:28:24
И, на самом деле,
1:28:27
эта запись, которая
1:28:29
здесь, она, естественно, эквивалентна записи вот этой
1:28:32
те же самые записи.
1:28:34
Но эта запись более похожа на ту запись, которую вы
1:28:38
можете найти, если вы скомпилируете Haskell в его
1:28:43
первое
1:28:45
промежуточное представление.
1:28:47
У Haskell'а в мультикомпиляции есть несколько представлений.
1:28:48
Первое из них называется core.
1:28:52
Core – это такой язык внутри Haskell,
1:28:53
очень-очень маленький, у него очень минимальный.
1:28:56
И вот это почти core, на самом деле,
1:28:58
только тут у функций в core нету
1:29:02
списка аргументов. Есть, опять же, lambda f стрелка,
1:29:06
lambda l стрелка, то есть там лямбда и по одному аргументу.
1:29:08
Ну, как в обычных функциях.
1:29:10

1:29:11
Мы знаем, что в Haskell у нас все функции по одному аргументу.
1:29:15
И тут нету инфиксных кооператоров, тут все применение функции префиксное.
1:29:20

1:29:22
Немножко про core,
1:29:23
язык внутри Haskell.
1:29:26
Это похоже на core немножечко.
1:29:27
И вот это определение мапа, мы будем его использовать, когда будем
1:29:32
делать differentiation
1:29:33
под этой функцией.
1:29:36
Мы здесь применяем
1:29:38
функцию умножить на 10
1:29:39
ко всем элементам, потом сворачиваем по плюсу и нулю. То есть мы делаем sum.
1:29:46
Как мы должны сделать,
1:29:48
значит, опять же, в чем прикол?
1:29:49
Прикол в том, что мы
1:29:51
делаем два траверсала. Хотим делать один траверсал.
1:29:53
Один проход по нашему списку, чтобы не было
1:29:58
промежуточных списков в памяти.
1:30:01
Шаг нулевой.
1:30:02
Мы делаем это экспансию.
1:30:03
Это экспансия, это мы добавляем аргументик.
1:30:06
У нас аргумент ожидается, да?
1:30:08
Вот эта композиция, да?
1:30:10
И потом unfolding определяем композиции.
1:30:13
Композиция в точке – это просто аппликация.
1:30:15
Это мы знаем.
1:30:18
Очень просто.
1:30:21
Тут шаг нулевой.
1:30:22
Это мы просто берем,
1:30:23
явно аргументы вставляем и живем спокойно.
1:30:25
Дальше мы
1:30:29
вставляем определение фолдера.
1:30:32
Похоже на определение мапа,
1:30:34
только там тот андроид через кейс у фолдера, да? Мы вставляем определение
1:30:37
фолдера, и мы его inlining определяем фактически. Что такое фолдер?
1:30:42
Мы делаем кейс к нашему списку.
1:30:43
Вот наш список. Это весь наш список, которым мы делаем кейс.
1:30:47
Если
1:30:50
const, то мы плюсуем
1:30:51
x и потом вызываем рекурсивность.
1:30:54
Рекурсивно.
1:30:56
Мы просто делали inlining определение фолдера. Это ничего больше.
1:31:01
А потом
1:31:03
мы делаем inlining определение мапа.
1:31:06
Опять же, мап, мы определяем
1:31:09
мапу, как мы потормачиваемся по списку L.
1:31:11

1:31:13
Пустой список – это пустой список.
1:31:15
А если const, то смотрите, мы применяем функцию к y,
1:31:21
производим бета-редукцию.
1:31:23
Поставляем y на нашу функцию, получаем y умножить на 10. Вот, все.
1:31:27
А потом вызываемся рекурсивно на ys.
1:31:31
Окей.
1:31:32
На текущем этапе
1:31:35
может быть непонятно, что делать дальше.
1:31:38
У нас есть
1:31:40
кейс внутри кейса.
1:31:43
Можно ли с этого избавиться? Можно ли сделать кейс
1:31:48
внутри кейса, как-то его извлечь? Конечно, можно.
1:31:50
Называется case-of-case transformation.
1:31:53
Он позволяет внутренний кейс сделать внешним, а
1:31:56
внешний кейс делать на уровень глубже, короче говоря.
1:31:58
Смотрите, внешний кейс теперь – это внутренний кейс. Вот он, кейс L и так далее.
1:32:03
Вот, раз и два.
1:32:04

1:32:06

1:32:08
Это ровно внутренний кейс.
1:32:11
Извините.
1:32:12
А теперь, кейс на уровень глубже – это кейс по результату,
1:32:16
по пустому списку. И дальше у нас есть опять же, вот тут написано,
1:32:20
это ровно
1:32:23
ой,
1:32:23
это разные фрагменты.
1:32:27
Вот это ровно эта вещь, этот фрагмент кода и этот фрагмент кода.
1:32:31
Он дублируется.
1:32:34
Опять же, мы
1:32:35
внутренний кейс сделали внешним.
1:32:38
И тут можно заметить одну классную вещь.
1:32:40
Видите, кейс пустой список, of и дальше кейсы.
1:32:43

1:32:47
Если заглядывать немножко в операционную семантику, вот
1:32:50
она обычно определяется для языков программирования, small step semantics.
1:32:55
Когда мы делаем кейс,
1:32:58
и у нас уже паттерн совпадает моментально.
1:33:01
Вот как тут у нас паттерн совпадает, кейс пустой список, of пустой список.
1:33:04
Вот тут паттерн совпал.
1:33:06
Мы возвращаем ровно тот бренд, который соответствует пустому списку.
1:33:13
Это логично.
1:33:15
Поэтому этот вот кейс
1:33:18
редуцируется, то есть один шаг в small step semantics в нолик.
1:33:21

1:33:24
Опять же, логично.
1:33:25
Мы матчим пустой список,
1:33:27
получаем у нас уже есть кейс пустому списку, получаем нолик.
1:33:31
Вот и все.
1:33:34
Аналогично вот с этим кейсом.
1:33:36
Мы делаем матчинг по консу.
1:33:37
Вот конс,
1:33:40
вот еще один конс,
1:33:41
наш branch релевантный,
1:33:43
x у нас просто это y умножить на 10.
1:33:47
Производим шаг в нашей операционной семантике,
1:33:50
получаем вместо этой вещи вот эту вещь.
1:33:54

1:33:57
Вместо xs
1:33:57
мы подставляем
1:33:59
вот эту вещь map функции ys.
1:34:01

1:34:03
А вместо x здесь мы подставляем y умножить на 10.
1:34:09
Я все релевантные части выделил.
1:34:11

1:34:15
Мы делаем кейс по консу.
1:34:21
Казалось бы, больше ничего сделать мы не можем.
1:34:24
Мы сделали все, что могли.
1:34:25
Мы проанализировали наш список внутренний l,
1:34:30
сделали case of keys transformation, произвели шаг в семантике.
1:34:34

1:34:37
И теперь
1:34:39
смотрите, видите этот фолдер?
1:34:43
Такой же в точности этот фолдер.
1:34:45

1:34:47
Не правда ли?
1:34:49
Тут вместо l стоит ys.
1:34:51

1:34:55
Использовать этот фолдер это нехорошо.
1:34:56
Опять же, потому что у нас все еще есть фолдер и мэп.
1:35:00
Все еще два траверсала. Мы хотели сделать один траверсал.
1:35:03
Но без проблем. У нас этот фолдер это фанк от ys.
1:35:06

1:35:07

1:35:09
Финальная стадия это поставить реквизитное определение.
1:35:14
Все наше правое
1:35:16
вызов наше правое фолдер и мэп это фанк.
1:35:19
И вот теперь
1:35:20
наш фанк,
1:35:21
это простая функция, ее можно было на самом деле
1:35:23
использовать по свойствам, которые были на предыдущей лекции.
1:35:27
Тем не менее,
1:35:30
фанк теперь
1:35:32
проходится по списку единицы.
1:35:35
Мы гранино применяем умноженное 10 к оберегу
1:35:37
и складываем с реквизитным вызовом.
1:35:41
Эта часть тоже очень важна.
1:35:42
Если мы оставим фолдер от мэпа, еще раз, у нас будет два траверсала списка ys.
1:35:46

1:35:49
Что это делает фанк?
1:35:51
Мануальный дефористейшн.
1:35:53
Прошу не поджаловать.
1:35:54
Вопросы по этому слайду есть?
1:36:03
В нашем приоритете сделать так, чтобы у нас
1:36:06
было минимальное количество проходов по списку.
1:36:11
Вот так, окей.
1:36:13
А вот, да, все.
1:36:14
Это весь пример дефористейшна мануального.
1:36:16

1:36:18
Дефористейшн, который я бы сказал
1:36:22
автоматизированный, на самом деле.
1:36:23
Типа того.
1:36:27
Стримфьюжн
1:36:28
это название
1:36:31
типа данных, которые реализуют предотвращение
1:36:37
формирования
1:36:38
промежуточных, ну, давайте скажем, списков.
1:36:41
На самом деле там списки.
1:36:44
Вот.
1:36:47
Стримфьюжн
1:36:47
работает в следующем образом.
1:36:49
Начнем мы изучать стримфьюжн с примитивных попыток.
1:36:54
Вот как
1:36:55
и было в
1:36:57
предыдущих инстанциях, мы делаем фактически один шаг.
1:37:01
В фанке мы делаем один шаг.
1:37:03
Помните, да, фанк, который был на слайде до этого?
1:37:07
И там, по идее, был один шаг вычисления и регустированных вызовов.
1:37:14
Прикол фьюжна в том, что тут тоже один шаг фактически.
1:37:17

1:37:20
Работает списка.
1:37:22
Лист
1:37:23
это тип данных, он принимает а,
1:37:25
инкапсулирует функцию из списка а в мебе вот а из списка.
1:37:29
Эта функция похожа на uncons.
1:37:31

1:37:34
uncons, значит, берет
1:37:35
голову, если есть голова, то он ставит голову и хвост,
1:37:40
оборочит это в just,
1:37:41
иначе это nothing, потому что
1:37:44
в списке нет головы, очевидно.
1:37:46
Это похоже на uncons, то есть cons наоборот.
1:37:53
При этом,
1:37:54
более того, это похоже на, на самом деле, state.
1:37:57
State transformer, я бы сказал.
1:37:57
У нас есть стрим токенов,
1:38:02
мы, типа, берем
1:38:04
первый токен и оставшиеся токены
1:38:07
и оборачиваем это в мебе.
1:38:08
То есть мы можем закончить
1:38:10
и тогда там будет nothing.
1:38:12
Вот, похоже на стрим токенов.
1:38:14
Вот, и это один шаг.
1:38:15
Просто что мы хотим анализировать.
1:38:18
Окей, обработался списком.
1:38:19
Можем ли мы генерировать map1?
1:38:21
Попробуем, окей. f это функция из списка в мебе.
1:38:23
h тоже.
1:38:26
Значит, h, так, сейчас.
1:38:29

1:38:29

1:38:33
Да, значит,
1:38:34
h принимаем в список f',
1:38:37
и здесь мы
1:38:39
придаем f' функции f,
1:38:40
на самую функцию f в листе.
1:38:43
Если у нас nothing.
1:38:44
just, мы пропихиваем функцию j внутрь нашего, собственно, первого элемента.
1:38:51
Это не работает
1:38:53
вообще ни в каких обстоятельствах.
1:38:57
Как вы считаете, почему?
1:38:58
Причины здесь много.
1:39:00
Мне нужна хотя бы одна причина.
1:39:04
Почему не работает?
1:39:13
У нас по типу не сходится.
1:39:15
Наверное, что-нибудь по типу.
1:39:16

1:39:20
Мы просто, как бы, я так понимаю,
1:39:22
что ожидали s', это лист типа a, список типа a.
1:39:27

1:39:28
А потом мы его
1:39:30
почему-то запихнули в результат нашей функции h, хотя она должна быть
1:39:35
листом типа списка b.
1:39:37
Правильно, да.
1:39:38
h принимает в список типа b, а мы передаем f в список типа b,
1:39:43
а f ожидает в список типа a.
1:39:44
Да, это первое замечание, совершенно справедливо.
1:39:47
Еще одно замечание.
1:39:48
Вот тут функция, видите, j.
1:39:52
Очевидно, что уже на этом этапе будет проблема.
1:39:54
Тут type-checking не сработает.
1:39:56
Если еще дальше идти, вот тут функция j
1:40:01
принимает аргумент, тут будет значение типа b,
1:40:03
но здесь вот
1:40:05
допустим, у меня тип список a.
1:40:06
Тут все еще список b.
1:40:08

1:40:10
Все еще, короче говоря, проблема
1:40:13
того, что тут все слишком
1:40:16
блин,
1:40:16
сейчас скажу, конечно, фразу
1:40:18
слишком однотипно.
1:40:20
У нас везде что-то типа a, и из этого мапы не сделать никаким образом вообще.
1:40:26
Он невозможен.
1:40:28

1:40:30
Ну, возможно просто сделать тогда здесь
1:40:33
этоморфизм из a в a, тогда без проблем.
1:40:35
Но это тогда не мапа, это тогда
1:40:38
я не знаю,
1:40:39
номов какой-то, припов какого-то мапа.
1:40:42
Хочется, чтобы у нас
1:40:44
мап был ровно таким же,
1:40:46
ну, каким, какой ожидается.
1:40:49
Поэтому эта наивная реализация Stream Fusion не работает,
1:40:54
которая one-step.
1:40:56
Но вторая версия работает нормально.
1:40:59
То есть мы для этого, для этой фигни можем сделать однозначно
1:41:03
мап просто потому,
1:41:04
что вот это уже, вот это уже, это state.
1:41:06

1:41:08
У нас вместо состояния это stream, вместо monad это maybe,
1:41:12
и b это наше значение,
1:41:13
которое меняется. У нас будет тогда функция с b в c,
1:41:16
лист a в b, ссылка лист a в c.
1:41:18
Очень элементарно.
1:41:20
И наш stream имеет один тип, и он не меняется.
1:41:24
Окей.
1:41:26
Есть еще проблема.
1:41:28
Когда мы обрабатываем список, мы
1:41:32
хотим иметь информацию о изначальном списке.
1:41:36

1:41:38
Да, мы хотим
1:41:40
иметь
1:41:41
в владении то, с чем мы работаем.
1:41:43
Вот у нас как бы есть один степ.
1:41:46
Что-то, что
1:41:47
представляет один степ.
1:41:48
Но сам список тоже был.
1:41:51
Давайте мы добавим.
1:41:53
Добавили список. Теперь это не new type, а data.
1:41:55
Отлично. Потому что у нас есть два поля.
1:41:57
Все. Добавили список.
1:42:01
Текущая проблема
1:42:03
реализации в том, она уже нетривиальная.
1:42:05
Нужно немножко подумать.
1:42:07
У нас есть функции, работающие с списком, которые могут изменять
1:42:13
наши части списка.
1:42:14
Голову, хвост и так далее.
1:42:19
Но maybe это слишком строгий тип.
1:42:23
Слишком ограниченный.
1:42:24
Что тут говорит maybe? Maybe говорит о том,
1:42:27
что у нас есть либо
1:42:29
как голова, так хвост,
1:42:31
либо ни голова, ни хвост.
1:42:36
Вспомним фильтр.
1:42:37
У нас фильтр может отбрасывать элементы.
1:42:39

1:42:41
Голову, да, и
1:42:43
возвращать хвост. То есть фильтр,
1:42:45
один степ в фильтре,
1:42:47
это кейс тот самый, в котором
1:42:49
есть хвост, но нет головы.
1:42:52
Maybe это не инкапсулирует никаким образом. Maybe,
1:42:54
опять же, это либо голова и хвост, либо ничего.
1:42:58
Поэтому нужен другой тип.
1:42:58
Не maybe.
1:43:01
Который допускает только хвост,
1:43:03
но может допускать голову.
1:43:06
Это первое замечание.
1:43:07
Второе замечание.
1:43:10
А нужен ли нам тип нашего
1:43:15
прям железный тип нашего стрима, нашего списка?
1:43:20
То есть нужно ли его здесь передавать?
1:43:23
Я бы сказал, что нет. Я бы сказал, что
1:43:25
его можно абстрагировать. Я бы сказал, что
1:43:27
его можно квантифицировать с помощью for all.
1:43:28

1:43:31
StreamFusion – это вот этот вот тип данных.
1:43:33
Он экзистенциальный.
1:43:34
Тут стоит for all перед стримом.
1:43:35
Сейчас я объясню немножко.
1:43:37
Это будет потом в лекции 2010-й.
1:43:39
Не помню.
1:43:41
Чуть-чуть объясню про экзистенциальный тип.
1:43:43
for all s.
1:43:45
Называется экзистенциальный.
1:43:47
Давайте я его скопирую на всякий случай и создаю в блокноте. Быстренько.
1:43:54
У стрима тогда,
1:43:55
если узнать тип стрим,
1:43:57
именно у
1:43:59
концентра данных стрим,
1:44:00
будет иметь тип for all s.
1:44:05
s, стрелка step, s, а, стрелка s, стрелка, стрим, а.
1:44:11
Вот его тип. Ровно такой тип будет у стрима.
1:44:13

1:44:18
Я не знаю, обсуждали ли вы с Дмитрием Юрьевичем Штукинбергом
1:44:24
на матлоге
1:44:25
способ трансформации экзистенциального,
1:44:29
квантера for all в квантера exists.
1:44:31

1:44:33
Но давайте я сейчас вместо этой стрелки сделаю коррирование и поставлю
1:44:37
Я объясню, почему я так делаю.
1:44:39
Сейчас, видно, запятую.
1:44:41
Я делаю коррирование.
1:44:42
А теперь смотрите, что делает for all s?
1:44:45
Он зажирает все, что есть справа.
1:44:50
Опять же, не знаю, обсуждали ли вы это с Дмитрием Юрьевичем Штукинбергом.
1:44:52
Мы сказали, что for all x.
1:44:55
phi сделка psi
1:44:57
эквивалентно
1:44:59
Я поставлю его
1:45:00
таким вот образом, чтобы было понятно.
1:45:03
Эквивалентно
1:45:04
Господи!
1:45:07
Ой, что происходит? Все в порядке.
1:45:09

1:45:11
Эквивалентно exists
1:45:13
x.phi сделка psi.
1:45:14
Внимание, сколько теперь станет вот таким вот образом.
1:45:20
То есть,
1:45:21
тут for all
1:45:22
сожрал всю аппликацию, а тут x.
1:45:24
phi сожрал только аргумент.
1:45:25

1:45:27
А вот теперь я применю этот трюк.
1:45:30
Причем, более того,
1:45:31
этот трюк вспоминаемый интуитивной логикой.
1:45:33
Этот трюк конструктивный.
1:45:35
Он оказывается, например,
1:45:37
в коке, или в вине, или в аксе, или в баронде, или в индресе, неважно.
1:45:41
Оказывается, это конструктивный факт
1:45:44
в интуитивной логике.
1:45:46
Давайте сделаем теперь то же самое со стримом.
1:45:48
Что у нас имеется,
1:45:49
stream, и тут стоит x.
1:45:51
phi и s. Скобки теперь стоят вот таким образом.
1:45:53
Вот так вот.
1:45:56
И вот так.
1:45:57

1:46:02
То есть, стрим принимает тип, он принимает тип,
1:46:06
типовый параметр, и принимает дальше, собственно говоря, пару
1:46:09
из степа, из функции,
1:46:11
и нашего самого стрима.
1:46:14
Именно поэтому стрим называется экзистенциальным.
1:46:17
Потому что вот этот фурорчик
1:46:19
в настоящей сигнатуре стрима эквивалентен этому экзистцу.
1:46:23
Экзистцу, при том, что его нет в Хаскеле,
1:46:26
потому что он не нужен.
1:46:27
У нас есть фурор, его достаточно,
1:46:29
и так понятно,
1:46:31
когда тип экзистенциальный, когда он стоит перед конструктором.
1:46:36
Вот. Экзистцу.
1:46:37
То есть, стрим де-факто, и это на самом деле отражается в коре, в тот самый,
1:46:42
привычный язык первой рекомендации.
1:46:45
Стрим принимает типовый параметр, и принимает две функции, из s в степ sa и s.
1:46:50
Поэтому он называется экзистенциальным.
1:46:53
Вот.
1:46:53
Двигаемся теперь снова к стриму.
1:46:55
А что такое стрим?
1:46:58
Авторогируемся мы от типа нашего контейнера, нашего списка.
1:47:01
Это произвольный s.
1:47:04
Вот и все.
1:47:05
Функция из s в степ sa – это наш вот один степ.
1:47:09
Вот. В чем прикол?
1:47:11
Видите, мы в степ добавили skip.
1:47:12
Вот skip – это тот конструктор, которого нам не хватало в maybe.
1:47:16
Если мы уберем skip,
1:47:18
у нас будет степик maybe от пары, не эквивалентный, а есть аморфен,
1:47:23
maybe от пары sa.
1:47:26
А skip нам нужен, он важен для фильтрации, например.
1:47:31
Поэтому у степа есть тренинг-конструктор done – мы
1:47:35
завершили наш список, завершили обработку списка.
1:47:36
Yield – у нас есть голова, есть хвост.
1:47:39
И skip – мы пропустили гол.
1:47:42
Это называется string fusion.
1:47:43

1:47:46
Да, вот просто
1:47:47
экстрактор, то есть это один степ в нашем стриме,
1:47:51
один шаг в обработке нашего списка.
1:47:53
И сам стрим кодируется вот в таких вот двух полях нашего конструктора.
1:48:00
Мы можем задать функции, которые приводят в список а в стрим а.
1:48:04

1:48:07
Вот.
1:48:08
Как этот список работает в стриме?
1:48:10
Это наша функция xs.
1:48:11
xs – это список а.
1:48:12
Значит, стрим принимает типовый параметр,
1:48:15
вспоминаем сигнатуру стрима конструктора, и две функции.
1:48:18

1:48:20
Раз стрим принимает типовый параметр, давайте
1:48:24
мы передадим стриму s равен список от а.
1:48:26
Вот и все.
1:48:27
Теперь next имеет ровно эту сигнатуру.
1:48:31
Функции список а
1:48:32
в степ список а и а.
1:48:34
Что делает next?
1:48:35
Next отпустил список до дал, мы закончили обработать наш список.
1:48:41
А от конца мы
1:48:43
возвращаем наш x и хвост xs.
1:48:46

1:48:47
Вообще, в принципе, это похоже на генератор.
1:48:50
Он не является генератором в Python, очевидно.
1:48:55
Типа похож на него.
1:48:57
Типа того.
1:48:57
У нас есть шаг,
1:49:00
который генерируется
1:49:02
степ бай степ,
1:49:04
и это
1:49:05
все такое прикольное.
1:49:08

1:49:10
Мне кажется, генераторы там хрустово представляют.
1:49:14
А тут просто стрим фьюжн.
1:49:15
Не суть, I digress.
1:49:18
OnStream принимает стрим а, возвращает список а.
1:49:22
Здесь, конечно, стрим принимает типовый параметр и next он полиморфный.
1:49:25

1:49:28

1:49:29
То есть next имеет
1:49:31
функции из s в степ а.
1:49:33
Вот наш next.
1:49:36
Но давайте, собственно говоря,
1:49:39
просто
1:49:41
вместо s, опять же, поставим список а. Ой, что? Сейчас.
1:49:45
А, нет-нет.
1:49:47
Sorry, я сейчас подумаю.
1:49:49
Да, я тупой.
1:49:50
Нет, next это все еще список господи, функции из s в степ с а. s0 это все еще s.
1:49:59
go это наша рекуссивная функция,
1:50:02
которая будет обрабатывать следующую вещь.
1:50:03
Face s0.
1:50:05
Тот самый
1:50:07
стрим, который мы сохранили,
1:50:09
потому что, собственно, сама информация о нашем стриме, она важна.
1:50:14
Итого,
1:50:15
go определяется таким образом.
1:50:17
Мы смотрим на наш шаг, один шаг.
1:50:18
Если мы закончили обработку, мы делаем пустой список.
1:50:22
Без проблем, очень просто.
1:50:24
Если у нас есть skip, то есть мы пропускаем какой-то ребят в нашем стриме,
1:50:29
то мы просто вызываемся рекуссивно, пишем go.
1:50:31

1:50:32
А если у нас есть yield, мы добавляем явно a
1:50:37
с помощью конца и рекуссивно вызываемся go.
1:50:39
То есть работает go так, как мы ожидаем.
1:50:40
Мы проезжаемся по всему нашему
1:50:45
контейнеру, нашему s,
1:50:47
а s это просто что-то.
1:50:51
Вот. И строим список,
1:50:53
исходя из результатов next-ов.
1:50:55

1:50:57
Каждый раз, когда мы вызываем go, вызываем next.
1:50:59
Next со next-ом.
1:51:01
Мы строим список обратно.
1:51:03
Вот. Это и есть unstream.
1:51:07
Вопросы по этим функциям? Если у вас есть, то я слушаю.
1:51:08
Окей.
1:51:16

1:51:19
У нас есть очень простые функции, наподобие мапа и фильтра.
1:51:22
Начнем с мапа.
1:51:24
Функция
1:51:26
next это функция из s в степ s a.
1:51:29
Функция next-это функция из s в степ s b.
1:51:34
То есть s не изменяется вообще.
1:51:38
А next-зависит от next-а.
1:51:39

1:51:41
xs имеет тип s, очевидно.
1:51:43
done, done, skip s, ничего интересного.
1:51:47
А вот yield мы возвращаем f a.
1:51:49
То есть мы пропихиваем функцию f
1:51:52
для аргумента a. И не изменяем этот стрих.
1:51:54
Ну, потому что, опять же, это просто отдельный степ.
1:51:59
Главное
1:52:00
узнать, что происходит с этим значением.
1:52:02
В нашем стриме.
1:52:04
Фильтр.
1:52:05
Теперь важно.
1:52:08
У нас есть предикат.
1:52:10
У нас есть стрим next-s. Next опять же функция из s в степ s a.
1:52:12

1:52:15
Next опять же зависит от next-а.
1:52:17
Первые два случая абсолютно они, конечно, информативные, но они тривиальные.
1:52:23
Еще внимание на yield.
1:52:25
Допустим, next в нашем стриме вернул a.
1:52:28
Применяем предикат a к p.
1:52:30
Если a p от a true,
1:52:32
то мы сохраняем его.
1:52:34
Иначе мы пропускаем его.
1:52:35
Здесь вот skip важен.
1:52:37
В этом случае мы используем и ignore нашего элемента. Мы продолжаем
1:52:42
обрабатывать наш оставшийся стрим.
1:52:46
И это отражается в том, что у нас есть skip здесь.
1:52:54
Я подумал сейчас мгновенно.
1:52:56
А если у нас есть в том самом определении, в том
1:53:00
третьем, если вместо b поставить maybe b?
1:53:07
Что будет работать? Да, будет.
1:53:09
Ничего себе.
1:53:10

1:53:11
Можно, конечно, поставить maybe b, тогда это будет почти из аморф в стриме.
1:53:20
Но тут слишком много всего.
1:53:22
Maybe от maybe некрасиво.
1:53:23

1:53:25
Эти конструкторы в степе говорящие.
1:53:27

1:53:29
Лучше использовать просто стрим.
1:53:31
Короче, рекомендую попробовать folder s,
1:53:35
который как фолдер, только тут стримы, а не списки.
1:53:37
На доступе, если вам удастся, это будет здорово.
1:53:41
Релизовать фолдер через стримы,
1:53:43
на основе стримов.
1:53:47
А теперь
1:53:49
map, который на списках, обычный, это композиция.
1:53:53

1:53:54
Map применяет f.
1:53:57
Stream делаем из списка a, stream a.
1:54:00
Потом делаем map
1:54:02
s от f, делаем от stream a, stream b.
1:54:04
Потом делаем от stream, получаем обратно список b.
1:54:06
Это весь map.
1:54:07

1:54:09
Все.
1:54:11
Три функции.
1:54:12
Unstream, map s, stream.
1:54:14
Их можно декомпозировать.
1:54:16
Да, фильтры тоже самое.
1:54:17
Их можно декомпозировать. Пожалуйста.
1:54:19
У нас есть map show и filter even.
1:54:23
Мы по определению мапы и фильтры поставляем вместо фильтра, фильтра s, стрим,
1:54:28
вместо map s, стрим, вместо map s.
1:54:31

1:54:33
Так.
1:54:35
Казалось бы, у нас
1:54:37
есть следующий фрагмент.
1:54:38
Stream.Unstream.
1:54:42
Stream.
1:54:43
Unstream это все еще вызов функции и, к сожалению,
1:54:47
занимает память и время.
1:54:48

1:54:51
Но!
1:54:53
Мы можем от этого избавиться.
1:54:56
С помощью так называемого rewrite rule.
1:54:57

1:54:59
Rewrite rule
1:55:01
это вот такая вот прагма, которая вставляется в ваш модуль.
1:55:05
Прагма rules.
1:55:06
Дальше тут название вашей прагмы.
1:55:08
И дальше правило.
1:55:09
Для любого стрима...
1:55:13
Причем именно так.
1:55:15
Это фактически что-то подобное... Ладно, я, конечно, сейчас скажу дичь.
1:55:18
Но это что-то подобное того, что мы можем ввести в наших интерактивных сетах.
1:55:23
Что-то подобное зависимости.
1:55:27
Это не является зависимыми типами.
1:55:28
Это просто такой способ задать правила.
1:55:30
Это не зависимые типы ни в коем случае.
1:55:31
Это просто синтаксис, очевидно.
1:55:34
Для любого стрима S Stream.
1:55:36
Unstream это S.
1:55:41
Хорошо бы это доказать.
1:55:43
Для произвольного стрима S.
1:55:46
Это можно... Мне кажется, можно делать в тех же самых языках
1:55:50
наподобие Coq, Lean, Acta, Rnt, Idris и так далее.
1:55:52
Причем.
1:55:57
..
1:55:57
Наверное, я этим займусь сегодня.
1:55:58
Это будет уликательно.
1:56:00
Нужно параллельно доказать, что на самом деле стрим Unstream это реально стрим,
1:56:04
из которого мы и начали.
1:56:07
Насколько это стримерливо, я пока сказать не могу.
1:56:08
Честно, не знаю.
1:56:13
Другой вопрос.
1:56:15
Попробую сегодня это сделать на суген, в Coq.
1:56:16

1:56:19
И, собственно, теперь у нас система Unstream, это
1:56:24
будет Id, фактически, и тогда map.s.show и filter.s.
1:56:28
even станут соседними, фактически.
1:56:29
Типа того.
1:56:31
Есть package.stream.
1:56:33
fusion, в котором это все реализовано, все эти функции, наподобие.
1:56:37
И, кажется, вместе с rewrite.
1:56:38
rule тоже.
1:56:41
ByteString – это стрим.
1:56:44
fusion для ByteString.
1:56:44

1:56:47
Так, это все?
1:56:48
А, ну, собственно, representation автоматически.
1:56:50
Мы переводим наш список в stream.
1:56:52
fusion.
1:56:56
Делаем rewrite.
1:56:57
rules, которые релевантны, наподобие вот этой вот вещи.
1:57:01
И это образует differentiation, то есть избавление от состояния.
1:57:05
Почему избавляется
1:57:08
эмоциональное состояние?
1:57:09
Ну, потому что у нас теперь получается
1:57:12
прикол в одном степе.
1:57:13
Один степ
1:57:16
инкапсулирует один шаг.
1:57:18

1:57:20
Вместо двух шагов это один шаг, короче говоря.
1:57:23
И, собственно,
1:57:25
тогда мы просто включаемся в список один раз
1:57:28
в рамках стрима, и это хорошо.
1:57:29

1:57:32
Автоматизация, то есть
1:57:33
вся главная информация заключается в этом next, в этом степе.
1:57:38

1:57:40
Это building-блок нашего stream.
1:57:41
fusion.
1:57:44
Все.
1:57:46
Вопросы по stream.
1:57:48
fusion, по тому,
1:57:50
как его начать, как он будет работать, в реализации.
1:57:52

1:57:57
У нас все равно, мы хотели же избавиться наоборот от лишних проходов по списку,
1:58:01
но у нас все равно уже остались лишние проходы по списку.
1:58:05
Какие лишние проходы остались?
1:58:06
Потому что мы принимаем композицию map-as-show и filter-as-even.
1:58:11
Это два прохода по списку будут.
1:58:14
Значит, по стриму? Да, по стриму.
1:58:16

1:58:17
У нас, например, все ленивое, поэтому мы проанализируем сначала,
1:58:22
если у нас список, например, не пустой, голову,
1:58:25
мгновенно наша голова поставится в наш map-as-show,
1:58:30
мгновенно результат поставится в filter-as-even,
1:58:34
и потом мгновенно мы просто
1:58:39
сконструируем стрим.
1:58:40
Короче говоря, там из-за ленивости все делается мгновенно.
1:58:44
На самом деле там стрим
1:58:47
как бы
1:58:49
да, он делает для нас стрим из списка,
1:58:53
а потом просто по ленивости мы мгновенно поставляем
1:58:56
голову из гилды или скипа в наши функции map-as,
1:58:58
в filter-as, обрабатываем все.
1:59:00
Получается новый, более сложный степ, да,
1:59:04
а потом мы делаем онстрим по этому более сложному степу.
1:59:06
То есть это просто композиция двух степов.
1:59:08
Двух next, да? Помните next, который был там?
1:59:11
Просто их типа
1:59:13
не композиция, а как бы это сказать, суперпозиция, то же самое.
1:59:19
Нормально сказать.
1:59:20
В общем, они
1:59:22
вместе, да?
1:59:24
Они не прям один, потом другой, они вместе.
1:59:26
Это просто
1:59:28
будет
1:59:30
наверное наглядно видно, если попытаться это сделать.
1:59:31

1:59:33
О, кстати, тут же есть сайты которые в начале
1:59:38
лекции, которые с пузыриками.
1:59:39
Мне кажется, если произвести,
1:59:41
надеюсь, что там есть саппорт экзистенциальных типов, я не проверял.
1:59:44
Возможно, там можно привести
1:59:46
мануальную ленивость, как это все вычисляется, да, ленивое вычисление,
1:59:50
и посмотреть,
1:59:52
действительно ли там проход по списку один раз происходит.
1:59:55
Но он должен, иначе
1:59:58
нет в общем этом смысла.
2:00:01
Ожидается, что там будет проход по списку один.
2:00:04
Иначе, опять же, в этом всем нет смысла.
2:00:05

2:00:08
Ну и да, я, собственно, как я уже говорил, я ожидаю, что там просто будет
2:00:12
композиция этих вот next-ов.
2:00:15
Более сложный next из двух составляющих.
2:00:18
А next, что один степ,
2:00:20
это ровно как было с тем самым фолдом, пусть да, фолдер от мапа.
2:00:24
Вот там один степ – это вот y на 10
2:00:27
плюс регуссивный вызов. Это как и здесь, фактически.
2:00:31
Сейчас, что тут происходит?
2:00:32
Фигурация, потом шоу. В одном степе.
2:00:35
Что хорошо.
2:00:36
Так.
2:00:41
Все.
2:00:43
Теперь мы поговорим про мотабельные объекты.
2:00:46
Мы завершили разговор о
2:00:49
strictness и performance.
2:00:50
Немножко, я не знаю, мотабельные объекты как-то не совсем затрагивают.
2:00:54
Нет. Затрагивает, очевидно, performance.
2:00:56
Потому что в некоторых
2:00:58
мотабельных контейнерах есть процесс слайсинга.
2:01:02
Возьмите, я под контейнера,
2:01:04
и он за 1 делается, что прикольно.
2:01:06

2:01:08
Некоторые просто тоже прикольные контейнеры, которые являются айо-рэями.
2:01:11
В общем, мотабельные объекты.
2:01:15
Да, они мотабельные,
2:01:16
во-первых, что интересно.
2:01:18
Вот у нас есть айо-рэй.
2:01:22
Айо-рэй – это, собственно, массив,
2:01:24
именно массив,
2:01:26
который живет в айоманаде.
2:01:29
Не айоманаде, а айотипе данных.
2:01:31
Короче, он живет в айо.
2:01:33
Он живет в чем-то, что инкапсулируется
2:01:36
гипотетически
2:01:38
нечистые вычисления.
2:01:41

2:01:42
Ну да, айо потому что.
2:01:44
Гипотетически здесь оно важно.
2:01:47
Мы создаем new array.
2:01:48
Новый array создаем.
2:01:49
У нас индексация от 0 до 100.
2:01:53
И заполняем наш аррэй чиселками 42.
2:01:54
Вот наш аррэй.
2:01:58
Считываем в позиции 1
2:02:00
а, записываем в позицию 2
2:02:03
а плюс 64
2:02:03
и считываем позицию.
2:02:07
Фактор позиции в нашем новом аррэе.
2:02:10
Умеем получать,
2:02:12
умеем записывать, умеем создавать массивы.
2:02:14

2:02:16
В чем проблема айо-рэя?
2:02:19
Довольно на поверхности эта проблема на самом деле возникает, и она
2:02:26
устранимая, конечно же.
2:02:32
Есть идей
2:02:33
проблемы айо-рэя.
2:02:36
Айо-рэя это максимально легальный аррэй, и можно пользоваться когда угодно.
2:02:39

2:02:41
Инконвиниент, так сказать.
2:02:45
Нет идей.
2:02:46
Он довольно прочный.
2:02:47
Чистота?
2:02:50
Что, чистота?
2:02:52
Наоборот, не чистота айо-рэя.
2:02:55
Казалось бы, да, ведь мы там что-то обновляем, мы там что-то чистим.
2:02:58
Проблема в том, что он живет в айо.
2:03:02
Мы не хотим
2:03:04
делать вещи в айо, которые
2:03:08
могут быть не в айо, а такие есть.
2:03:10

2:03:14
И, значит,
2:03:17
просто айо-рэй
2:03:18
живет строго в айо.
2:03:20
И, например,
2:03:22
когда мы делаем какие-то действия над нашим аррэем, мы не можем выйти из айо
2:03:27
не использовав тот самый небезопасный unsafeperform-айо, помните, тот самый из айо.
2:03:32
Чтобы достать там
2:03:34
значение чистенькое, которое
2:03:36
в spoiler можно сделать
2:03:38
с помощью других типов, которые сейчас мы
2:03:42
выясним,
2:03:44
что они есть,
2:03:46
делается с помощью unsafeperform-айо, что не очень хорошо.
2:03:51
Поэтому нужно каким-то образом от айо
2:03:54
избавиться,
2:03:55
или хотя бы, спойлер, это будет почти возможно,
2:03:59
там мы избавляемся от айо,
2:04:01
а делаем другую монаду.
2:04:03
Не сделаем, а ее используем.
2:04:05
Ну, в общем,
2:04:08
есть
2:04:09
такой тип данных, который называется st.
2:04:12
Здесь написано, что это датам.
2:04:13

2:04:15
Я только имитирую, что это stx, stmonad, проводинг, support и так далее.
2:04:19
А s здесь.
2:04:23
Это так называемый state thread.
2:04:26
Или просто состояние.
2:04:28
st иногда называют state transformer.
2:04:32
Внимание!
2:04:33
Не стоит путать state transformer, который
2:04:36
stt, помните, stt, который я даже напишу.
2:04:39
Важно, что я
2:04:41
перейду к платформе, потому что я буду писать вещи, связанные с st.
2:04:45
Мы помним, что у нас есть type state t,
2:04:49
которое принимает состояние ma, и от этого стоит t,
2:04:52
от run стоит t,
2:04:56
который, что он принимает, он принимает s, возвращает m от пары.
2:05:02
Это тоже state transformer.
2:05:05
s, это наше состояние, тоже может быть мутабельным, оно может изменяться.
2:05:10
Только тут мутабельность, она не фразка,
2:05:12
а функция просто в этом плане мутабельная.
2:05:16
Вот.
2:05:18
А st тоже new type, между прочим.
2:05:22
Тут нету m, во-первых.
2:05:23
Это тоже состояние. Называется state thread.
2:05:27
State thread.
2:05:29
Да, state thread.
2:05:31
Это thread, это внутренние вещи, там есть
2:05:36
целая статья по st.
2:05:37

2:05:38
Вот, кажется, сами напомнили Джонсона, который создал jhc,
2:05:42
компайлер таскал, и вроде как сам таскал часть.
2:05:44

2:05:46
Я не помню, где забыл.
2:05:49
В общем,
2:05:51
помните ли вы,
2:05:52
как определен IEO?
2:05:54
Прямо как он определен, помните его определение? Оно было на слайдах лекции 6.
2:06:03
Господи, отстань.
2:06:05
Помните, да, IEO?
2:06:06
Ну, так условно.
2:06:08
Помните, что там у IEO
2:06:10
была такая фигня, как state hash real world стрелка,
2:06:15
такой вот страшный тупол из
2:06:18
state hash
2:06:19
real world,
2:06:22
помните такого страхолюденного?
2:06:25
Внутри определение IEO.
2:06:27
Это был new type IEO от этой вещи.
2:06:30

2:06:34
Ну, вы живы, господа?
2:06:36
Как вас зовут?
2:06:37
Мы живы, но, если честно, я не помню уже такого слова.
2:06:39

2:06:42
Да, в общем, IEO
2:06:44
это реально похоже на state,
2:06:47
IEO это state фактически.
2:06:48
Вот у нас есть состояние, оно подблизовано магическим real world,
2:06:53
это примитив и это магический примитив.
2:06:55
При этом он boxed.
2:06:57
Ой, господи, lifted.
2:06:59
Сейчас, я забыл, он boxed или lifted.
2:07:01
Может быть, опа, boxed и lifted.
2:07:03
Сейчас я потом объясню, что я имею в виду.
2:07:05
Получается вот такая вот пара, это похоже на tuple,
2:07:08
но когда называется unboxed tuple.
2:07:09
Unboxed, то есть
2:07:12
tuple представляет,
2:07:14
что это не pointer heap object.
2:07:18
Помните, да, у нас, кажется, в Java
2:07:20
и в Kotlin
2:07:22
мы можем создавать объекты на heap s, потому что там u и т.д. и т.п.
2:07:26
в Scala тоже.
2:07:28
По умолчанию все типы данных,
2:07:31
у них все представления, это pointer в какой-то heap объект.
2:07:34
Unboxed tuple
2:07:35
это не pointer в heap объект.
2:07:37
Это прям
2:07:39
tuple, они вот
2:07:41
типа стоят рядышком в регистрах.
2:07:43
У меня очень много с
2:07:44
AVM'ом, AVM-бельников это знают гораздо лучше, чем я, в тысячу раз.
2:07:47
Но я примерно так.
2:07:49
Там есть регистры, регистрики прикольные и т.д. Unboxed tuple
2:07:53
отличается в том, что у него представление другое.
2:07:55
Это не pointer, это прям tuple.
2:07:58
Это в памяти рядышком, короче говоря, стоит.
2:07:59

2:08:01
Но это все еще tuple, все еще пара.
2:08:02

2:08:03
Она обыкновенная сочетание того, что она себе представляет и т.д.
2:08:09
Вот. И опять что IO это вот такая вот функция.
2:08:12
И стоит hash real world вот в пару стоит hash real world а. Внимание!
2:08:18
st это
2:08:20
ща я сделаю магию,
2:08:22
скопирую то, что
2:08:24
я тут выделил,
2:08:25
и вместо real world поставлю s.
2:08:30
Что такое st?
2:08:31
st это как IO,
2:08:34
типа того, только более общий.
2:08:36
У нас s это наш state thread,
2:08:38
это наше недоступное
2:08:40
не при каких обстоятельствах
2:08:43
типовый параметр.
2:08:44
Сейчас мы выясним, почему он недоступен не при каких обстоятельствах.
2:08:48
И просто что-то наподобие такой вот функции.
2:08:52
С одного состояния в другое, и вот наш а.
2:08:53

2:08:56
Вот.
2:08:57
Это st.
2:08:58
То есть IO это типа
2:09:00
the fact and just в случае st.
2:09:03
Это st от real world.
2:09:04

2:09:06
У нас есть функция, извиняюсь,
2:09:08
прям определенная st to IO,
2:09:10
которая принимает st
2:09:12
real world а, возвращает IO а.
2:09:14
Определенно максимально просто.
2:09:16

2:09:18
Достаем функцию, одну
2:09:19
перекидываем в IO.
2:09:20
Вот.
2:09:24
Итак,
2:09:24
st.
2:09:27
Она строгая.
2:09:29
Строгий state transformer.
2:09:30

2:09:31
О нём можно назвать state transformer.
2:09:34
Потому что st это реально как state.
2:09:37
Просто s это не состояние, а это что-то параметризованное,
2:09:42
что-то, что параметризует state hash самый, называется state thread.
2:09:47
Вот опять то самое run state,
2:09:50
у меня там конечно было
2:09:53
именно run state t,
2:09:54
она была transformer, а здесь именно run state без трансформеров.
2:09:58
Run st, однако,
2:10:01
вот таким вот образом.
2:10:03
Первый аргумент это sts a, где s это призвольный тип.
2:10:09
Чтобы получить a,
2:10:10
это читная функция, во-первых.
2:10:13
Тут нет никакого IO.
2:10:15
А во-вторых,
2:10:18
благодаря тому, что стоит for all s именно в аргументе,
2:10:21
именно это обеспечивает
2:10:23
недоступность наших программ недоступность наших программ
2:10:28
информацию о том, какой у нас state thread.
2:10:30
Какой у нас, короче говоря, тип, который параметризует st.
2:10:34
Он недоступен и ни при каких обстоятельствах.
2:10:39
Что хорошо, нам не нужна информация об s.
2:10:40

2:10:41
Так же как нам нужна информация о real world.
2:10:44
Это что-то
2:10:47
внутрикомпайлерное и
2:10:50
неналивантное с точки зрения
2:10:53
нами
2:10:55
производимых вычислений, например.
2:11:02
Run st.
2:11:04
Получаем sts a, возвращаем a.
2:11:05

2:11:08
У нас есть IO ref.
2:11:08
Наверняка он обсуждался в IO.
2:11:11
В лекции по IO на шестой лекции.
2:11:13
Естественно, у нас есть stref.
2:11:16
Референс, который живет исключительно в st-монаде.
2:11:19
st это монада, очевидно.
2:11:22
Потому что st это state.
2:11:24
Конечно же это монада.
2:11:25
IO тоже монада, потому что IO это state в буквальном смысле.
2:11:30
Но не изоморфно.
2:11:33
Да, это разные вещи.
2:11:34
Очевидно.
2:11:37
stref живет в st.
2:11:38
Можно создавать новый strf, можно читать, можно писать, можно модифицировать.
2:11:43
Все то, что там с IO, только это st, и это можно экстрактить с помощью run st.
2:11:48
Вот пример.
2:11:51
Мы хотим заполучить собственно нашу сумму, списка.
2:11:55

2:11:56

2:11:58
Ок. Давайте мы
2:12:00
тогда будем уже жить в st типе данных в этом блоке, потом сделаем run st.
2:12:06
В этом блоке нам не доступна
2:12:08
информация о нашем s.
2:12:10
Никаким образом.
2:12:13
Господи, время так летит быстро.
2:12:14
У меня только не мало остается.
2:12:15
Кошмар.
2:12:18
Ок.
2:12:20
Давайте создадим новый strf.
2:12:22
В нем будет жить чиселка нолик.
2:12:25

2:12:26
Потом мы пройдемся по нашему списку с помощью for, underscore.
2:12:28
Это обсуждалось в лекции по foldable.
2:12:31
И traversable тоже.
2:12:34
Обе лекции.
2:12:36
А потом мы просто модифицируем наш n,
2:12:40
добавляем туда x.
2:12:42
Потом просто считываем.
2:12:46
В конечном итоге тут будет тип st, s,
2:12:49
а. Ой, нет, сейчас.
2:12:51
Да.
2:12:53
Потому что плюсик это полиморфная
2:12:55
функция, очевидно.
2:12:58
Вот поэтому мы вернем
2:13:00
значение суммы в нашем списке.
2:13:02

2:13:06
Более того,
2:13:07
тут есть маленькая проблемка, которая решается
2:13:11
уже чем-то, что в крайнем ходе данной лекции.
2:13:14
Из того, что у нас имеются монады,
2:13:17
это же пайнт, пайнт 1, функция 2.
2:13:22
Тут тоже пайнт, это же n, это n-пайнт.
2:13:23

2:13:25
Это невозможно параллелизовать,
2:13:28
потому что это просто гигантская функция.
2:13:29
Это не параллелизуемо.
2:13:33
В этом проблеме монад в общем случае, там невозможно сделать параллелизм.
2:13:39
Из-за того, что это одна гигантская функция,
2:13:40
там ничего невозможно заспрыгивать практически.
2:13:43
Я вам явно
2:13:45
модифицировать какие-то строчки, чтобы сделать параллелизм. Это невозможно.
2:13:48
Это у нас монады.
2:13:49
Все слишком секвенциально, короче говоря.
2:13:52
Есть инструментарий, который
2:13:55
должен
2:13:57
делать параллелизм.
2:13:58
Он заходит в данную лекцию, но это есть, это прикольная тоже вещь.
2:14:03
Называются линейные типы.
2:14:05
Все, двигаюсь дальше.
2:14:08
Вопросы по этому слайду.
2:14:16
S3 тип данных – это очень прикольный тип данных, похож на IO, опять же, тот самый.
2:14:20
И он эскейпабл.
2:14:20

2:14:24
Именно вот из-за этой вещи.
2:14:31
Окей, теперь у нас есть целый класс типов, который называется MRA.
2:14:35

2:14:37
Для таких M, где M, внимание, это монада состояний.
2:14:43

2:14:48
То есть это монада,
2:14:49
которая, наподобие, либо стоит, либо IO.
2:14:51
В основном это стоит.
2:14:53
S3, S3, S3, S3, извиняюсь.
2:14:55
Я, наподобие, S3, не стоит, а S3.
2:14:58
E – это тип наших элементов.
2:15:00
A – это тип нашего массива.
2:15:03

2:15:05
A имеет вот такой comment, который я выделил только что.
2:15:11
Именно type, arrow, type, arrow, type.
2:15:13
То есть, например,
2:15:15
в случае starray,
2:15:18
starray принимает s, s – это тот самый state thread.
2:15:21
Вот написано.
2:15:23
State variable for the st type.
2:15:28
I – это тип
2:15:30
индексируемых, короче, тип индекса, да?
2:15:33
Индекс индексируется из класс-типов AX.
2:15:35
AX – это подкласс орда.
2:15:38
AX – это тоже прикольный класс типов.
2:15:40
Обычно это int.
2:15:41
Но это могут быть еще и пары из двух AX.
2:15:44
То есть можно комбинировать
2:15:47
multi-dimensional индексацию.
2:15:49
Тоже прикольно.
2:15:52
Можно еще раз узнать,
2:15:54
для чего тип M в MRA?
2:15:57
Да, потому что
2:16:00
у MRA есть такие функции,
2:16:03
наподобие, как здесь,
2:16:05
где M – это та самая монада,
2:16:08
в которой живут значения наших arrays.
2:16:11
Эта монада M упоминает s.
2:16:13

2:16:15
Где s? А, нигде.
2:16:17
Ладно, короче.
2:16:18
Эта монада M – это монада,
2:16:20
в которой живут все мутабельные вычисления, и в основном монада st.
2:16:25
То есть,
2:16:26
в инстанциях MRA,
2:16:28
если вклинать на список,
2:16:29
вместо M будет подправляться почти во всех случаях, если не в 100%.
2:16:34
sts.
2:16:36
То есть M – это sts.
2:16:39
В очень многих инстанциях.
2:16:40
Но тут пометризуется M, потому что вдруг там есть другое.
2:16:43
А, внимание, вдруг там есть IO.
2:16:46
Ну, why not?
2:16:48
IO тоже может быть,
2:16:50
как оказалось бы, если нам приспичить, мы можем поставить вместо M IO.
2:16:54
Это как st, только там real world.
2:16:56
Вместо s.
2:16:58
Вот.
2:16:59
И тогда там не st array, а IO array.
2:17:03
Так.
2:17:03
То есть M – это монада, в которой живут мутабельные результаты.
2:17:08
Sorry, не мутабельные, а просто результаты мутабельных вычислений.
2:17:12
В основном это st.
2:17:15
Так.
2:17:16
Да, есть st.
2:17:18
Пойду назад, чтобы не торопиться.
2:17:19
st array, да.
2:17:20
st – это наш saved thread.
2:17:22
st i – это тип индексов и тип элементов.
2:17:25
st u array –
2:17:27
это мутабельный array,
2:17:29
как st array, только для unboxed элементов.
2:17:32
Значит, boxed – типы данных.
2:17:34

2:17:35
Это типы данных, представление которых – это pointer в heap-объект.
2:17:40
Ну, это boxed.
2:17:43
99.99998753 –
2:17:45
это рандомное число.
2:17:46
Процентов всех типов данных в Haskell – это boxed типы данных.
2:17:51
Они в основном используются.
2:17:52
Boxed типы данных.
2:17:54
Но unboxed тоже есть.
2:17:56
Unboxed – это не pointer в heap-объект.
2:17:57
Это прям что-то в регистрике.
2:18:01
Int –
2:18:03
это
2:18:05
pointer,
2:18:06
к сожалению, в heap-объект.
2:18:07
Но int энкапсулирует значение типа int hash.
2:18:09

2:18:10
И имеет представление,
2:18:13
вот в регистрике это
2:18:16
int,
2:18:18
64-битный, в регистрике.
2:18:19
Unboxed type.
2:18:22

2:18:25
Вот в чем отличие.
2:18:26
Unboxed – не boxed.
2:18:27
Pointer в heap-объект или что-то в регистрике.
2:18:30
И не только, там еще есть tuples, помните, unboxed tuples.
2:18:34
Вот это тоже unboxed.
2:18:37
stu.array
2:18:39
может инстанцировать m.array, но
2:18:42
только для очень
2:18:44
ограниченного количества типов e.
2:18:46
Если взглянуть на инстанцию m.array, для stu.
2:18:50
array e может быть либо int, либо word, либо char, либо double, либо float,
2:18:54
либо pointer, либо функциональный pointer, fun pointer,
2:18:58
либо stable pointer, либо там что-то еще.
2:19:01
Очень ограниченное количество
2:19:04
элементов stu.array
2:19:05
может инстанцировать m.array.
2:19:08
Только те, у которых есть unboxed representation.
2:19:10

2:19:11
Может быть, да? Int, word и т.
2:19:13
д., double, float.
2:19:16
А stu.
2:19:18
array геопроизводит каких угодно элементов.
2:19:21
Поэтому
2:19:22
желательно использовать stu.
2:19:23
array если вам хочется работать с нитами,
2:19:27
там нету pointer в heap-объекте, там просто регистр и т.
2:19:31
д.
2:19:32
В общем, функции, те самые re-array, которые записываются в нашей array,
2:19:39
записывают как в writer, считывают, да, вот
2:19:42
и я, пожалуйста, дашь этот элемент тот самый.
2:19:44
new array, вот он создает наш a,
2:19:46
вот a тот самый имеет kind,
2:19:49
type, arrow, type, arrow, type.
2:19:51
Вот, ровное.
2:19:52
То есть stu.
2:19:54
array может быть поставлен вместо a.
2:19:57
Вот так, вот так вот.
2:19:59
Это все, да? А, да, все.
2:20:01
Вопросы в этой части.
2:20:02
Тут, да, довольно сложная машинерия есть под капотом,
2:20:07
если глянуть на, опять же,
2:20:09
там очень много используется примитивных функций с хэшами на конце года.
2:20:13

2:20:15
Довольно сложно, на первый взгляд.
2:20:20
Еще раз.
2:20:21
m – это монад, в котором живут все вычисления, в основном это st.
2:20:25
s – это тот самый sv для st,
2:20:27
тот самый state thread.
2:20:28
i – это тип индексов, e – это тип элементов.
2:20:32
a, вот здесь a, это тип array.
2:20:33
В случае stu.
2:20:35
array, это
2:20:39
stu.array принимающий s.
2:20:45
Еще пару секунд.
2:20:46
Держу слайд.
2:20:47
А, можно вопрос?
2:20:49
У нас функции newArray,
2:20:51
readArray, writeArray, у нас получается newArray создает просто новый массив?
2:20:55
Или что вот здесь он делает?
2:20:59
Да.
2:21:00
Хороший вопрос.
2:21:01
NewArray принимает пару из двух индексов, это lower bound и upper bound.
2:21:05
Внимание, что интересно,
2:21:09
индексы могут быть какими угодно.
2:21:12
Мы привыкли от 0 до n-1.
2:21:12

2:21:15
Ну, до n, не включая n.
2:21:17
Может быть, хоть от минус 100 до 100.
2:21:20
Поэтому есть маленькая такая свобода в newArray.
2:21:23
Эти lower, upper bound – какие угодно.
2:21:25
Главное, чтобы они сницировали ax.
2:21:27
Значения могут быть какими угодно.
2:21:29
Хоть от числа грэма до числа грэма плюс 1.
2:21:33
Как хотите.
2:21:35
И заполняются все эти индексы e.
2:21:40
Одним элементом.
2:21:43
ReadArray подсчитывает по позиции e, writeArray
2:21:47
запихивает в позицию i элемент e.
2:21:49

2:21:52
Unit, потому что тут прикол.
2:21:53

2:21:55
Можно вернуть
2:21:57
старый элемент, то есть m, e.
2:21:59

2:22:01
Но тут
2:22:05
ничего, видимо, продуктивного не возвращает в writeArray, кроме unit.
2:22:07

2:22:12
NewArray заполняет
2:22:13
все индексы от этого i до этого i
2:22:16
элементами этого e.
2:22:18
Да, возвращается действительно array в m,
2:22:23
в который производится все вычисления и только там.
2:22:25
Next.
2:22:33
Векторы.
2:22:34

2:22:36
Векторы похожи на array.
2:22:38
На самом деле, вектор определен, как array.
2:22:40
Immutable vector это просто вектор, который понимает только a.
2:22:43
Mutable, поскольку это mutable, нам выгнан стоит thread.
2:22:46
То есть m-вектор имеет s в качестве параметра
2:22:50
и, конечно же,
2:22:53
вот это там под капотом используют очевидное st.
2:22:58
Наконец-то!
2:22:58
У нас индексация в векторах O, A, T.
2:23:02
Наконец-то! Мы использовали листы на протяжении 20000 лет.
2:23:05
Теперь мы можем использовать векторы с индексацией
2:23:09
в constant time complexity.
2:23:12
Finally.
2:23:14
Еще у векторов константный slicing.
2:23:16
Тоже классно.
2:23:18
То есть взять под вектор.
2:23:19
Он константный.
2:23:20
Это из-за определения array.
2:23:24

2:23:25
Тут написаны страшные вещи.
2:23:29
Прим монот какой-то страшный.
2:23:31
m-вектор еще
2:23:34
есть класс типов.
2:23:35
v это тот самый
2:23:37
мутабельный вектор.
2:23:39
Тип.
2:23:42
Прим монот.
2:23:44
Сейчас я задумался.
2:23:45
Это, короче, класс.
2:23:48
Да, класс.
2:23:49
Прим монот m.
2:23:51
Поэтому m это монот, очевидно.
2:23:54
И у него есть примитив, который называется примитив.
2:23:58
Да.
2:23:59
То есть
2:24:00
не примитив, а функция.
2:24:03

2:24:05
Тип примитива неизвестен, к сожалению.
2:24:06

2:24:08
Он не прописан в библиотеке.
2:24:11
Бывает.
2:24:13
И
2:24:14
прим монот, короче говоря,
2:24:17
это
2:24:18
фактически иерархия
2:24:20
положенности трансформеров.
2:24:25
То есть есть прим монот например, t, e, m.
2:24:30

2:24:32
Если есть прим монот
2:24:34
m. То есть есть instance.
2:24:36

2:24:37
Есть instance аналогичный с чукок-чукок, с господи writer t.
2:24:42
Тут стоит w.
2:24:43

2:24:45
С reader, reader t.
2:24:47

2:24:48
Тут стоит e, environment.
2:24:50
Такой вопрос. А какой прим монот base case? Какая там база?
2:24:55
Сможете ли вы попытаться угадать, какая там база у прим монот? Просто угадать.
2:24:58

2:25:03
Это неочевидно вообще,
2:25:05
но поскольку мы работаем с мутабельными векторами,
2:25:09
какая база может быть у прим стоит
2:25:13
у instance у прим стоит
2:25:16
ой, господи, прим монота.
2:25:17

2:25:26
База – это прим монот iom,
2:25:30
а также прим монот sts.
2:25:32

2:25:35
То есть база у прим монота,
2:25:37
базовый instance,
2:25:38
это instance для тех типов данных, у которых есть мутабельные вычисления или iom.
2:25:42

2:25:44
Ну, простейшие мутабельные вычисления, то есть более сложные.
2:25:46
Это потом, это другая лекция.
2:25:49
Это base case.
2:25:53
То есть мы можем строить nested transformers,
2:25:55
мы знаем, как строить
2:25:57
ложные трансформеры.
2:25:59
Главное, чтобы там в base case был st или iom.
2:26:00

2:26:04
Есть функция retry,
2:26:06
это то же самое grow, freeze, внимание,
2:26:10
принимает мутабельный вектор, то есть обычный.
2:26:15
А есть ли, короче говоря,
2:26:17
функция, которая принимает
2:26:24
и мутабельный вектор, но возвращает в мутабельный? Есть, да.
2:26:29

2:26:31
То есть freeze – это заморочить, да?
2:26:33
Что обратно, freeze – это saw.
2:26:36
То есть tighter, заморочить for и определённый в модуле ta.
2:26:38
vector.mutable.
2:26:44
Потом из этих модулей.
2:26:47
И да, saw делает из и мутабельного в мутабельный.
2:26:51
То есть можно делать из одного и другого ещё без проблем.
2:26:56
Мы знаем, что у нас есть insertion sort.
2:26:58

2:27:00
Определённо максимально просто мы вставляем x, такой готовый.
2:27:04

2:27:04
Он меньше всех ловеров.
2:27:07
Может быть, больше правильных всех рейтеров.
2:27:08
Ой, стоп.
2:27:10

2:27:12
Наоборот, он больше всех ловеров.
2:27:14
Может быть, меньше правильных всех рейтеров.
2:27:16
Да, другое дело.
2:27:18
Вставляем его.
2:27:19
Дебилитный insertion sort.
2:27:20
Ничего интересного здесь нет.
2:27:24
И он на списке, что как бы не очень.
2:27:26
Time complexity у insertion sort, конечно же, это, как минимум, квадрат.
2:27:30
Ну, как минимум.
2:27:31
Здесь, наверное, даже побольше
2:27:33
просто в том, что это
2:27:36
копирование объектов,
2:27:38
перекидывание концев и так далее.
2:27:40
Неважно.
2:27:40
В общем, квадрат, причём, плохой такой.
2:27:43

2:27:46
Да, можем сделать insertion sort на основе stu.
2:27:48
array без проблем.
2:27:50
Ну, вот смотрите, у нас есть тип элементов int.
2:27:53
И индексация int.
2:27:55
У нас есть instance
2:27:58
stu.array для int,
2:28:00
у которого элементы это int.
2:28:02
Потому что int, это у него есть unboxed representation.
2:28:07
Это то, что находится внутри int.
2:28:09
Сделаем то же самое, мы делаем новый list.
2:28:11
array от нуля до, ну, от нуля, потому что мы привыкли к нулю стартовать, от list.
2:28:15
array-1.
2:28:16
Я только что понял, что list.
2:28:19
array-1 это ровно включительно последний индекс. Он включительно.
2:28:24
Вот.
2:28:26
Вот всё.
2:28:27
И получается,
2:28:28
сейчас, да, делаем из списка
2:28:31
int.array. int.
2:28:33
array это stu.array.
2:28:38
Дальше ещё, собственно говоря, мы приезжаемся по списку 1, по списку 2,
2:28:42
у нас есть два индекса, меняем местами, ой,
2:28:45
сейчас, да, правильно, меняем местами.
2:28:48
Мы запомнили курс, запомнили next.
2:28:49

2:28:51
Если курс больше, чем next, мы меняем местами.
2:28:54
Вот всё.
2:28:56
А потом это getElements достаёт нам, как называется, список.
2:29:01

2:29:02
И он начинает пребывать в monodest.
2:29:03

2:29:06
Поэтому runstyle нужно указать.
2:29:10
Можно через вектор даже делать, без проблем.
2:29:12
Вот, тот самый thaw.
2:29:13
Мы делаем
2:29:15
и мутабельный вектор,
2:29:17
а потом делаем мутабельный вектор с помощью thaw.
2:29:20
То же самое алгоритм, совершенно.
2:29:22
Тут ещё jscan.
2:29:23
Что такое jscan? Я забыл.
2:29:25
Функция, да? Да, это функция.
2:29:28
Вот.
2:29:29
Потом мы делаем freeze, потому что
2:29:31
мы можем получить список из мутабельного вектора.
2:29:36
Вот он, мутабельный.
2:29:36
И потом делаем return. Опять это всё патронно ставим.
2:29:42
Это финалочка, да?
2:29:44
Да, это финалочка.
2:29:44
Мы сейчас завершим лекцию.
2:29:47
Запись идёт? Да, идёт.
2:29:49
Есть много способов
2:29:50
реализовать всякие прикольные
2:29:55
алгоритмы
2:29:56
в мутабельном хаскеле.
2:29:58
Это всё очень-очень sequential.
2:30:01
То есть, это невозможно распараллелить, потому что
2:30:03
там всё где монады, и это очень трудно сделать.
2:30:06
Если бы я сказал невозможно.
2:30:08
Наверное.
2:30:09
Везде bind и так далее.
2:30:11
Всё гаскофункционально, фактически.
2:30:15
Но это возможно, да, с помощью тех самых arrays и так далее.
2:30:19
st – это ваш друг.
2:30:20
Используйте его, если вы хотите сделать мутабельные вычисления
2:30:24
и сделать escaping из них значение а,
2:30:27
то есть чистым его, его заэкстрактить.
2:30:29
st – это ваш друг.
2:30:31
Можно измерять время с помощью set++,
2:30:33
можно измерять секунды.
2:30:35
Ещё есть такой пакетчик, который называется criterion.
2:30:37
И в самом конце
2:30:39
список почти всех, всё за то, что было сегодня, в том числе,
2:30:43
между прочим, всего осталось людей. Четыре человека, да?
2:30:45
Три человека, окей, класс.
2:30:48
Я уже миллион раз референшу
2:30:51
книгу Мирана Лимбабачи «Learn the USSR for Great Wood».
2:30:55
А тут фреск-лист
2:30:57
обсуждается в чаптере 13.
2:30:58
И все остальные, собственно,
2:31:02
ссылочки про streamfusion, про мутабельные объекты,
2:31:05
backup-presentation тоже можно почитать, всё доступно.
2:31:06

2:31:09
Я, кстати, завершил. Нам всем большое спасибо.
2:31:11
Рекординг останавливаем.
