1
00:00:06,305 --> 00:00:10,970
На сегодняшней лекции мы поговорим,
как писать многопоточный код на Haskell,

2
00:00:11,570 --> 00:00:14,530
какие есть примитивы
для синхронизации потоков,

3
00:00:14,790 --> 00:00:18,050
какие есть библиотеки для работы с этим,

4
00:00:18,150 --> 00:00:23,130
потому что работа с низкоуровневыми
примитивами имеет свои проблемы, и так далее.

5
00:00:23,870 --> 00:00:25,790
Вот потихоньку небольшой план лекции.

6
00:00:26,310 --> 00:00:30,434
Сначала мы обсудим, как
писать многопоточные программы

7
00:00:30,446 --> 00:00:33,970
в Haskell с использованием
легковесных трудов.

8
00:00:34,670 --> 00:00:39,070
Потом научимся синхронизировать
эти потоки между собой и поймем,

9
00:00:39,450 --> 00:00:41,650
какие в Haskell бывают базовые
примитивы синхронизации.

10
00:00:42,490 --> 00:00:44,790
Поговорим немного об
эксепшенах в очередной раз,

11
00:00:44,950 --> 00:00:49,630
потому что там, где обычно возникает
конкуренция, возникают и эксепшены непременно.

12
00:00:50,770 --> 00:00:54,682
Затем поговорим про библиотеку
Async, самую популярную

13
00:00:54,694 --> 00:00:58,690
в Haskell для работы с
многопоточным асинхронным кодом.

14
00:00:59,370 --> 00:01:02,870
Затронем немного такую вещь, как
STM – Software Transactional Memory.

15
00:01:04,330 --> 00:01:06,710
Затем в конце лекции
поговорим про параллелизм.

16
00:01:07,270 --> 00:01:09,743
Важное замечание,
конкретно в рамках данной

17
00:01:09,755 --> 00:01:12,530
лекции, да и в принципе,
насколько мне известно,

18
00:01:12,690 --> 00:01:18,250
по общепринятой терминологии, конкуренция –
это про взаимодействие потоков между собой,

19
00:01:19,290 --> 00:01:21,772
по тому, как они
работают с каким-то shared

20
00:01:21,784 --> 00:01:24,510
ресурсами, как их
синхронизировать и так далее.

21
00:01:24,990 --> 00:01:27,650
То есть это всегда про
эошный код в терминах Haskell.

22
00:01:28,390 --> 00:01:30,384
Параллелизм же,
напротив, это когда у нас есть

23
00:01:30,396 --> 00:01:32,750
какая-то чистая функция, и
мы хотим ее распараллелить.

24
00:01:33,980 --> 00:01:36,664
Мы сначала первую половину
лекции, даже большую

25
00:01:36,676 --> 00:01:38,970
часть, будем делять
именно конкуренцией,

26
00:01:39,710 --> 00:01:40,910
а затем коснемся параллелизма.

27
00:01:41,405 --> 00:01:43,670
С параллелизмом в Haskell
все весьма и весьма просто.

28
00:01:44,215 --> 00:01:47,781
И в конце немного затронем
на то, какие есть утилиты

29
00:01:47,793 --> 00:01:50,890
для того, чтобы профайлить
многопоточный код,

30
00:01:51,510 --> 00:01:53,630
если вдруг оно кому-то пригодится.

31
00:01:59,680 --> 00:02:01,450
Тут почему-то не грозит картинка.

32
00:02:01,910 --> 00:02:05,786
Тут должна быть картинка
про сравнение количества

33
00:02:05,798 --> 00:02:09,290
памяти, которую
потребляет Haskell интернет,

34
00:02:10,010 --> 00:02:15,890
в сравнении с ирландовским процессом
и джавовским и сишным петредом.

35
00:02:16,460 --> 00:02:20,630
Спойлер – Haskell интернет
занимает что-то типа…

36
00:02:21,730 --> 00:02:25,370
Ладно, я не буду врать, сколько
конкретно по памяти, но меньше всех.

37
00:02:25,570 --> 00:02:28,650
Уж, по крайней мере, на момент
создания этой презентации это было так.

38
00:02:29,290 --> 00:02:30,210
Из чего мы делаем вывод?

39
00:02:30,310 --> 00:02:36,630
Что Haskell – довольно удобный
язык в терминах уж конкретного

40
00:02:36,631 --> 00:02:38,470
потребления ресурсов для
написания многопоточных программ.

41
00:02:39,230 --> 00:02:41,850
На диаграммке это можно
представить следующим образом.

42
00:02:41,970 --> 00:02:44,210
То, что у нас есть ядра нашего процессора,

43
00:02:45,030 --> 00:02:50,650
над ними идут OS-трэды, так
называемые трэды операционной системы,

44
00:02:50,770 --> 00:02:53,410
которые непосредственно
исполняются на ядрах.

45
00:02:54,450 --> 00:02:57,061
Над ними у нас есть
Haskell легковесные трэды,

46
00:02:57,073 --> 00:02:59,410
или, как по-другому
говорят, green-трэды,

47
00:02:59,630 --> 00:03:01,370
которые также есть во многих других языках.

48
00:03:02,810 --> 00:03:06,430
Они не обязательно один в
один мапятся к OS-трэдам.

49
00:03:06,770 --> 00:03:11,630
То есть на одном OS-трэде можно запускать
много-много Haskell легковесных трэдов.

50
00:03:12,280 --> 00:03:16,830
И самая мелкая, самая гранулярная
единица – это так называемые спарки.

51
00:03:18,195 --> 00:03:21,810
О спарках мы будем говорить,
когда будем говорить о параллелизме.

52
00:03:22,550 --> 00:03:28,850
Спарк представляет собой маленькую
задачку из fork-drawing-pool Haskell,

53
00:03:29,610 --> 00:03:31,930
которую мы хотим
запустить в отдельном потоке.

54
00:03:32,310 --> 00:03:37,470
То есть если трэдов в Haskell
можно наспавнить достаточно много,

55
00:03:37,730 --> 00:03:41,170
потому что они не обязательно
один в один мапятся

56
00:03:41,171 --> 00:03:42,730
к OS-трэдам, потому что
они достаточно легковесные,

57
00:03:43,270 --> 00:03:46,650
то спарки – это куда более
и более мелкая единица,

58
00:03:46,750 --> 00:03:52,770
которой вообще можно тысячами плодить
и никаким образом от этого не страдать.

59
00:03:54,210 --> 00:03:57,114
Ну, разберем базовую
функцию в Haskell, которая

60
00:03:57,126 --> 00:03:59,670
нужна для того, чтобы
создать новый трэд.

61
00:03:59,970 --> 00:04:00,970
Она называется fork.io.

62
00:04:01,230 --> 00:04:06,330
Она принимает какое-то риошное действие
и возвращает трэд-айди, открывает его.

63
00:04:06,860 --> 00:04:09,690
Что такое трэд-айди, мы
поговорим немного попозже.

64
00:04:09,691 --> 00:04:12,490
Точнее, немного попозже мы
поговорим, что с ним можно делать.

65
00:04:12,590 --> 00:04:16,850
Трэд-айди – это просто какой-то
идентификатор конкретного Haskell-грин-трэда.

66
00:04:17,650 --> 00:04:20,450
Здесь мы видим пример, как
можно работать с функцией fork.io.

67
00:04:21,670 --> 00:04:26,570
Например, мы в мейн-функции
спавним следующее вычисление,

68
00:04:26,690 --> 00:04:29,010
описанное do-блоком в новом потоке.

69
00:04:29,370 --> 00:04:34,110
В нем мы ждем одну секунду, трэд-дилей
принимает дилей в микросекунду.

70
00:04:34,370 --> 00:04:38,530
Соответственно, тут мы ждем одну секунду,
печатаем в консоль, что fork-thread awake.

71
00:04:39,280 --> 00:04:41,847
А в мейн-трэде, после
того, как мы запустили,

72
00:04:41,859 --> 00:04:44,610
мы ждем две секунды и
печатаем мейн-трэд finish.

73
00:04:46,870 --> 00:04:53,730
Замечание. По дефолту, если мы
компилируем Haskell-модуль через GHC,

74
00:04:54,470 --> 00:04:57,258
не через stack, не через
compile, то нам нужно

75
00:04:57,270 --> 00:05:00,010
указывать при компиляции
определенные флешки,

76
00:05:00,290 --> 00:05:03,972
для того, чтобы наша
программа скомпилировалась

77
00:05:03,984 --> 00:05:07,050
для использования в
многоточном режиме.

78
00:05:07,375 --> 00:05:10,090
Для этого нужно
использовать флаг min-threaded.

79
00:05:11,010 --> 00:05:14,226
Также при запуске нашего
экзешника, результирующего,

80
00:05:14,238 --> 00:05:16,970
мы должны передать туда
определенные флешки.

81
00:05:18,230 --> 00:05:23,090
В Haskell есть вещь, которая
называется RTS, или же runtime system.

82
00:05:23,590 --> 00:05:28,158
Это библиотека, которая
линкуется по итогу к вашему

83
00:05:28,170 --> 00:05:32,570
объектнику, чтобы получился
финальный экзекютабл.

84
00:05:33,120 --> 00:05:35,900
То есть Haskell-код, как
мы знаем, компилируется

85
00:05:35,912 --> 00:05:38,530
в машинный код, и там
нет виртуальной машины,

86
00:05:38,830 --> 00:05:41,610
или там в отличие от Python,
от JavaScript нет интерпретатора,

87
00:05:42,210 --> 00:05:45,248
и весь необходимый
вспомогательный код, например,

88
00:05:45,260 --> 00:05:47,750
garbage collector или
scheduler потоков,

89
00:05:48,270 --> 00:05:51,030
он находится как
раз-таки в этой библиотеке.

90
00:05:51,110 --> 00:05:55,951
И когда мы запускаем
нашу Haskell-программу, мы

91
00:05:55,963 --> 00:06:00,610
можем, начав с плюс
RTS и закончив минус RTS,

92
00:06:00,611 --> 00:06:02,434
если мы потом еще
хотим передать какие-то

93
00:06:02,446 --> 00:06:04,550
другие опции, перечислить
опции runtime system.

94
00:06:05,120 --> 00:06:09,330
В данном случае мы ставим флажок минус n2,
что означает, что используем два потока.

95
00:06:09,870 --> 00:06:12,890
Мы тут не пишем минус RTS,
потому что у нас после ничего не идет.

96
00:06:13,030 --> 00:06:15,800
Если бы мы хотели еще
передать какие-то аргументы

97
00:06:15,812 --> 00:06:18,310
командной строки, мы
бы закончили минус RTS.

98
00:06:20,990 --> 00:06:24,590
Исполнение программы довольно интуитивно
на двух потоках, потому что сначала,

99
00:06:24,591 --> 00:06:27,769
так как у нас forked thread
ждет меньше, печатается

100
00:06:27,781 --> 00:06:30,470
это, а затем печатается
main thread finish.

101
00:06:32,250 --> 00:06:38,270
По дефолту, если мы опять же компилируем
через GHC, без стека, без кабала,

102
00:06:38,950 --> 00:06:44,190
без каких-то вспомогательных еще команд,
которые указаны в стеке кабала в файле,

103
00:06:44,670 --> 00:06:48,390
у нас многопоточность выключена. Но,
тем не менее, данный код будет работать.

104
00:06:48,690 --> 00:06:51,878
И ваше предположение,
почему, во чем будет

105
00:06:51,890 --> 00:06:55,470
работать, без явного
включения многопоточности?

106
00:06:56,190 --> 00:06:57,310
И как это будет происходить?

107
00:07:02,190 --> 00:07:05,620
Ну, какое-то внутреннее представление языка
многопоточности, наверное, происходит.

108
00:07:06,840 --> 00:07:08,300
На самом деле все используется.

109
00:07:10,400 --> 00:07:13,820
Только в питоне был. Когда-то очень давно.

110
00:07:15,070 --> 00:07:18,019
Ну, в питоне все-таки,
насколько мне известно,

111
00:07:18,031 --> 00:07:21,120
есть так называемая
вещь Global Interpreter Log.

112
00:07:21,820 --> 00:07:26,380
И там, чтобы запускать отдельные
потоки, люди исхитряются,

113
00:07:26,540 --> 00:07:30,060
по крайней мере, до каких-то старых
версий питона довольно сильно исхитрялись.

114
00:07:31,180 --> 00:07:33,725
Тут же все будет, на самом
деле, весьма прозаично,

115
00:07:33,737 --> 00:07:36,600
потому что все действительно
запустится на одном потоке.

116
00:07:36,720 --> 00:07:40,260
Просто будет использоваться
простой шедулер однопоточный,

117
00:07:40,400 --> 00:07:45,900
который будет запускать действия по round
robin, так называемому, то есть по очереди.

118
00:07:46,250 --> 00:07:50,720
Какое-то действие минимальное прогоняется
у первого потока, потом у второго,

119
00:07:50,820 --> 00:07:52,800
потом опять у первого,
потом у второго, так по

120
00:07:52,812 --> 00:07:55,020
очереди, используя всего
лишь один настоящий поток.

121
00:07:56,420 --> 00:07:58,903
Поэтому, несмотря на то,
что результат исполнения

122
00:07:58,915 --> 00:08:00,900
конкретно в данном
случае не изменится,

123
00:08:01,540 --> 00:08:05,520
но важно понимать, что если мы
явно не подключим многопоточность,

124
00:08:05,960 --> 00:08:10,040
при указании соответственных флажков,
хаскельный код будет работать в один поток.

125
00:08:10,640 --> 00:08:17,540
Есть еще такой забавный спецфект. Насколько
я помню, его нет дальше в презентации.

126
00:08:18,090 --> 00:08:21,120
Как раз таки про то, как работает
однопоточный шедулер в хаскеле.

127
00:08:21,880 --> 00:08:24,716
Это если мы запустим
два тардана, каждый из

128
00:08:24,728 --> 00:08:28,040
которых будет с помощью
putstrln печатать строчку,

129
00:08:29,020 --> 00:08:32,350
одновременно, то есть
без разных дилеев, то мы

130
00:08:32,362 --> 00:08:36,140
будем видеть, если мы
отключим буферизацию в выводе,

131
00:08:36,141 --> 00:08:42,400
чтобы не флаттался у нас
output после конкретного куска,

132
00:08:42,640 --> 00:08:45,600
чтобы каждый символ выводился по одиночке.

133
00:08:45,720 --> 00:08:49,880
Мы увидим такую забавную картину, что
выводится по одной букве из первой строки,

134
00:08:50,320 --> 00:08:52,780
чередуясь по одной букве из второй строки.

135
00:08:53,200 --> 00:08:55,335
Что как раз таки будет
явно иллюстрировать то,

136
00:08:55,347 --> 00:08:57,400
как работает однопоточный
шедулер в хаскеле.

137
00:08:57,460 --> 00:08:58,600
Он работает довольно тупо.

138
00:08:59,540 --> 00:09:02,720
Мы помним, что строка – это
на самом деле список символов,

139
00:09:02,920 --> 00:09:05,138
поэтому он просто будет
по одному элементу от

140
00:09:05,150 --> 00:09:07,280
этого списка откусывать
и печатать консоль.

141
00:09:08,040 --> 00:09:12,800
И, соответственно, если у нас будет putstrln
aaa, потом bbb, мы увидим ab, ab, ab.

142
00:09:15,430 --> 00:09:19,280
Забавно, что если мы будем использовать
оптимальные хаскельные строки,

143
00:09:19,400 --> 00:09:24,380
такие как текст или байтстринг,
это не будет работать таким образом,

144
00:09:24,570 --> 00:09:28,220
потому что они представлены не с помощью
списка, а более эффективной реализацией,

145
00:09:28,340 --> 00:09:30,760
и там они будут печататься полностью.

146
00:09:32,370 --> 00:09:34,640
Это было такое лирическое отступление.

147
00:09:35,360 --> 00:09:39,680
На данном слайде видно то,
что я проговаривал минуту назад,

148
00:09:40,100 --> 00:09:42,660
по поводу того, что вот у
нас есть хаскельный исходник,

149
00:09:43,000 --> 00:09:47,540
с помощью jhc мы его компилируем, получаем
какой-то объект, файл с расширением .op.

150
00:09:48,520 --> 00:09:55,160
Затем он линкуется с runtime-системой,
которая называется libhs-rts.op.

151
00:09:55,240 --> 00:09:58,120
Там находится гербыш коллектор,
там находятся шедулеры и другие вещи,

152
00:09:58,520 --> 00:10:03,420
необходимые для того, чтобы программа,
которая написана вами, работала.

153
00:10:04,060 --> 00:10:08,060
И также это линкуется с библиотеками,
например, с библиотекой base,

154
00:10:08,180 --> 00:10:12,880
которая подставляется с каждым
исходным кодом на хаскель.

155
00:10:13,440 --> 00:10:19,160
И таким образом после линковки
всего этого дела мы получаем executable,

156
00:10:19,540 --> 00:10:20,900
который мы уже можем запустить.

157
00:10:21,620 --> 00:10:24,120
Вот в данном случае
тест является executable.

158
00:10:26,010 --> 00:10:31,060
А если мы захотим вдруг в интерпретаторе
хаскеля jhc запустить многопоточный код?

159
00:10:31,480 --> 00:10:35,000
Он запустится в отдельном
потоке или в том же потоке, что и jhc,

160
00:10:35,160 --> 00:10:38,460
и будет так же, как раунд
Робина, гоняться по кругу?

161
00:10:40,810 --> 00:10:45,120
Насколько я помню, при jhc
можно также указывать флешки.

162
00:10:46,340 --> 00:10:50,040
Возможно, они выглядят по-другому, но
данное поведение также специфицируется.

163
00:10:53,090 --> 00:10:55,570
Не могу на самом деле вам
конкретно ответить на данный вопрос.

164
00:10:55,660 --> 00:10:58,040
Никогда не экспериментировал
с запуском многопоточки в jhc.

165
00:10:59,320 --> 00:11:04,720
Но я уверен, что данное поведение также
регулируется соответствующими флешками RTS,

166
00:11:04,980 --> 00:11:08,740
которые можно установить,
допустим, специальными

167
00:11:08,820 --> 00:11:10,020
директивами, как
мы ставим extension.

168
00:11:10,560 --> 00:11:15,840
Через команду doi.js мы также можем,
вероятно, установить какие-то опции RTS,

169
00:11:16,060 --> 00:11:17,060
которые нам необходимы.

170
00:11:18,260 --> 00:11:19,260
Но вопрос хороший.

171
00:11:19,550 --> 00:11:22,080
К сожалению, точного
ответа на него не имею.

172
00:11:31,260 --> 00:11:36,700
Раунд Робин – поток работает
с основным, да? Вместе?

173
00:11:37,260 --> 00:11:38,260
То есть с главным.

174
00:11:38,800 --> 00:11:41,460
Да, да.
Это будет все работать в мейн-потоке.

175
00:11:43,760 --> 00:11:49,300
То есть мейн-поток будет по очереди
исполнять код, который мы написали здесь,

176
00:11:49,520 --> 00:11:53,160
то есть в самом мейн-потоке, и который
мы якобы форкнули в отдельный поток.

177
00:11:53,360 --> 00:11:56,020
Но так как отдельных потоков у
нас нет, это поток всего лишь один,

178
00:11:56,500 --> 00:11:59,800
мейн-поток будет исполнять по очереди
действия как из первого, так и из второго.

179
00:12:05,000 --> 00:12:09,540
То есть если, допустим, там было бы три
потока, а у нас только два потока запущены,

180
00:12:09,541 --> 00:12:11,832
то у нас мейн-поток бы
координировал бы еще,

181
00:12:11,844 --> 00:12:14,200
допустим, каких-то два
дополнительных потока.

182
00:12:17,620 --> 00:12:22,240
Мейн-поток бы уже более хитрым
образом координировался между двумя.

183
00:12:23,420 --> 00:12:26,760
Очевидно, какая-то доля работы
падала бы на мейн, но не обязательно.

184
00:12:26,960 --> 00:12:29,200
То есть, если я вас правильно
расслышал, вы сказали,

185
00:12:29,212 --> 00:12:31,420
что мейн-поток координировал бы
два дополнительных, это неверно.

186
00:12:31,440 --> 00:12:32,440


187
00:12:32,700 --> 00:12:35,840
Скорее, два потока координировали
бы действия на трех потоках.

188
00:12:36,940 --> 00:12:44,180
Что уже, на самом деле, довольно, я бы не
сказал, что нечасто встречающаяся ситуация,

189
00:12:44,260 --> 00:12:47,700
потому что у нас часто во всех этапах
программирования есть такая вещь как трекпул,

190
00:12:49,000 --> 00:12:54,480
где задач всегда больше,
чем потока в этом пуле.

191
00:12:54,520 --> 00:12:56,643
И у нас так получилось
в данном случае, что

192
00:12:56,655 --> 00:12:58,840
у нас трекпул из двух
потоков на три задачи.

193
00:13:00,110 --> 00:13:05,540
Они каким-то образом зависят
от шедулера и его оптимизации,

194
00:13:05,900 --> 00:13:09,080
и будут эти задачи шериться
между данными двумя потоками.

195
00:13:15,980 --> 00:13:16,980
Ок.

196
00:13:17,400 --> 00:13:18,400
Есть ли еще вопросы?

197
00:13:20,290 --> 00:13:23,860
Там в чате один человек написал, что не
может зайти, возможно, его надо впустить.

198
00:13:26,980 --> 00:13:32,160
Мне почему-то не видно.

199
00:13:32,360 --> 00:13:34,540
Обычно у меня всплывает такая штучка.

200
00:13:35,940 --> 00:13:37,520
Давайте я сейчас посмотрю.

201
00:13:39,780 --> 00:13:40,780
Там справа, снизу.

202
00:13:43,080 --> 00:13:46,560
Multiple people want
to... А, господи, реально.

203
00:13:47,040 --> 00:13:50,300
Почему-то в этот раз у меня не всплыл.

204
00:13:50,380 --> 00:13:52,780
Обычно такая отвлекающая вещь всплывает.

205
00:13:53,500 --> 00:13:55,520
Может, кто-то поменял
настройки митинга из коллег.

206
00:13:58,220 --> 00:14:04,020
Всем новоприбывшим, здравствуйте.
Давайте продолжать, если нет еще вопросов.

207
00:14:04,765 --> 00:14:07,200
Мы пока что разобрались,
как в Haskell фортнуть Thread.

208
00:14:09,375 --> 00:14:11,495
Спойлер, это можно сделать
с помощью функции fork.io.

209
00:14:11,600 --> 00:14:13,740
Тут ничего примечательного нет.

210
00:14:14,720 --> 00:14:16,160
Ничего интересного мы не пропустили.

211
00:14:17,610 --> 00:14:18,640
Давайте продолжать.

212
00:14:20,580 --> 00:14:23,600
Раз уж мы умеем уже плодить на токе,

213
00:14:24,060 --> 00:14:26,380
хорошо было бы научиться
их синхронизировать.

214
00:14:26,540 --> 00:14:29,560
Сейчас разберем основной примитив
синхронизации потока в Haskell.

215
00:14:30,200 --> 00:14:31,200
Он называется mvar.

216
00:14:32,560 --> 00:14:34,880
mvar расшифровывается как mutex variable.

217
00:14:35,200 --> 00:14:38,260
Это какая-то мутабельная
переменная, защищенная mutex.

218
00:14:38,840 --> 00:14:41,840
Сейчас разберемся, какой у
нее API и как с ней работать.

219
00:14:42,440 --> 00:14:48,480
Есть функция new empty mvar,
которая создает пустой mvar,

220
00:14:48,620 --> 00:14:50,420
то есть коробочку, в
которой ничего не лежит.

221
00:14:50,540 --> 00:14:53,420
И, понятно, данная
функция, как и в случае с URF,

222
00:14:53,880 --> 00:14:56,480
мутабельной переменной, которая
в отличие от mvar не thread safe,

223
00:14:58,300 --> 00:15:00,220
мы получаем наш результат в O.

224
00:15:00,810 --> 00:15:02,940
Мы не можем в чистом ходе создать mvar.

225
00:15:03,400 --> 00:15:05,802
Есть функция put mvar,
которая принимает mvar

226
00:15:05,814 --> 00:15:08,120
какое-то значение и
кладет значение в mvar.

227
00:15:09,140 --> 00:15:13,180
Соответственно, не возвращает
ничего в URF контексте.

228
00:15:13,520 --> 00:15:19,560
И также есть функция take
mvar, которая берет наш mvar и

229
00:15:19,600 --> 00:15:21,000
возвращает значение, которое
в нем лежит, обернутое в O.

230
00:15:21,860 --> 00:15:23,280
mvar работает следующим образом.

231
00:15:23,400 --> 00:15:25,880
Это какая-то коробочка, в
которой лежит значение типа A.

232
00:15:26,400 --> 00:15:28,379
Данная коробочка может
быть либо полная, то

233
00:15:28,391 --> 00:15:30,520
есть там лежит какое-то
значение, либо пустая.

234
00:15:31,280 --> 00:15:36,160
Если мы хотим положить значение в
коробку, которая уже полная, мы ждем.

235
00:15:36,260 --> 00:15:38,555
Наш thread получится,
пока какой-то другой thread

236
00:15:38,567 --> 00:15:40,780
не заберет оттуда значение
с помощью take mvar.

237
00:15:42,120 --> 00:15:43,740
Наш thread будет ждать.

238
00:15:44,120 --> 00:15:46,426
После того, как какой-то
другой thread заберет,

239
00:15:46,438 --> 00:15:48,460
наш thread положит и
продолжит исполнять.

240
00:15:49,120 --> 00:15:50,960
С take mvar ситуация аналогичная.

241
00:15:51,320 --> 00:15:55,180
Если мы хотим взять значение из
коробки, в которой ничего не лежит,

242
00:15:55,260 --> 00:15:58,700
мы залочимся, пока никакой другой
thread не положит туда значение.

243
00:16:02,380 --> 00:16:05,280
Действительно, можно
представить себе в голове,

244
00:16:05,740 --> 00:16:09,068
как она более-менее
реализована в терминах обычных

245
00:16:09,080 --> 00:16:12,020
mutex, которые
используются в других языках.

246
00:16:14,000 --> 00:16:17,540
Давайте посмотрим пример,
как мы можем использовать mvar.

247
00:16:17,900 --> 00:16:21,240
Кстати, большинство из того, о чем мы
будем говорить на сегодняшней лекции,

248
00:16:21,360 --> 00:16:24,520
находится в стандартной
библиотеке в модуле control.concur.

249
00:16:27,100 --> 00:16:30,400
Помимо библиотека SYNC и SAM, которые не
находятся в стандартной библиотеке, control.

250
00:16:30,990 --> 00:16:32,400
concurrent – это base.

251
00:16:33,100 --> 00:16:35,600
Также мы сегодня осветим вещи,
в которых не присутствует base.

252
00:16:37,330 --> 00:16:41,340
Для начала мы создаем две пустые
коробочки и спавним до отрыда.

253
00:16:42,060 --> 00:16:46,920
Первый thread ждет какое-то время и в
первую коробку кладет числовое значение.

254
00:16:49,820 --> 00:16:53,800
Второй тоже ждет какое-то время и
кладет сроковое значение во вторую коробку.

255
00:16:54,300 --> 00:17:00,900
Затем в данном main потоке мы ждем,
пока оба из потоков завершат исполнение.

256
00:17:01,020 --> 00:17:05,820
То есть в данном случае мы заспавним
эти два отрыда и здесь будем ждать,

257
00:17:06,220 --> 00:17:08,899
пока первый поток ждет
секунду, мы эту секунду

258
00:17:08,911 --> 00:17:11,660
будем ждать, пока наша
коробочка не наполнится.

259
00:17:12,140 --> 00:17:13,580
То же самое со второй коробочкой.

260
00:17:14,760 --> 00:17:21,920
То есть это аналог так называемого
join, который есть в других языках.

261
00:17:21,921 --> 00:17:24,900
То есть для того, чтобы
подождать, пока поток завершится.

262
00:17:25,020 --> 00:17:30,500
Только в Haskell работа с этим
происходит через mvar и его API.

263
00:17:31,710 --> 00:17:35,580
По итогу мы дождались результатов обоих
наших потоков и просто выгоним их в конце.

264
00:17:37,160 --> 00:17:39,857
То есть take mvar, он
именно ждет, пока сам

265
00:17:39,869 --> 00:17:42,640
mvar не поменяется
или что-то не заполнится.

266
00:17:44,900 --> 00:17:47,323
Если вдруг будет пустая
коробка, то он будет

267
00:17:47,335 --> 00:17:49,660
ждать, а не бросит
какой-нибудь exception,

268
00:17:49,661 --> 00:17:52,920
что пустая коробка и я
ничего не знаю, что там лежит.

269
00:17:53,840 --> 00:17:55,980
Именно функция take mvar будет ждать.

270
00:17:56,280 --> 00:17:59,007
Есть также в модуле
control.concurrent функция

271
00:17:59,019 --> 00:18:01,460
try take mvar, которая
возвращает iobull.

272
00:18:03,310 --> 00:18:05,540
Получилось или не
получилось взять значение.

273
00:18:05,740 --> 00:18:08,261
Точнее, она, помимо
результата, который обернут в API,

274
00:18:08,273 --> 00:18:10,760
она возвращает еще boolean
сложок, насколько я помню.

275
00:18:11,620 --> 00:18:17,560
А если в этот mvar никто ничего не положит,
то поток будет ждать бесконечно долго?

276
00:18:17,960 --> 00:18:19,860
Да, это будет deadlock.

277
00:18:22,030 --> 00:18:27,493
Сейчас мы как раз таки
разберем пример с deadlock и то,

278
00:18:27,505 --> 00:18:33,080
какие именно в Haskell есть
приколюхи, связанные с этим.

279
00:18:34,820 --> 00:18:38,441
Действительно, если мы
создадим программу, просто main.

280
00:18:38,453 --> 00:18:42,160
run.do, создадим mvar
и попытаемся его взять,

281
00:18:42,360 --> 00:18:45,400
то наша программа
должна работать бесконечно.

282
00:18:45,940 --> 00:18:51,340
Спойлер. Рантайп система Haskell
умеет детектить некоторые кейсы deadlock.

283
00:18:52,010 --> 00:18:53,560
В основном, конечно, самые простые.

284
00:18:54,160 --> 00:18:55,832
И в данном случае в
Haskell будет кинуто

285
00:18:55,844 --> 00:18:57,780
исключение по поводу
того, что у нас deadlock.

286
00:18:58,180 --> 00:19:02,160
Но далеко не все случаи deadlock в
рантайп-системе Haskell умеет ловить.

287
00:19:04,770 --> 00:19:05,800
Есть еще вопросы по mvar?

288
00:19:12,930 --> 00:19:21,680
Когда мы положим значение,
допустим, в tm1, у нас два потока ждут tm1.

289
00:19:22,460 --> 00:19:24,760
У нас получится только на одном, да?

290
00:19:31,660 --> 00:19:36,360
Обычно это называется, кажется,
честность в терминах многоточности.

291
00:19:37,060 --> 00:19:40,560
То есть, какой первый начал ждать,
в порядке FIFO, такому и вернется.

292
00:19:41,600 --> 00:19:42,880
То есть, да, второй будет ждать.

293
00:19:48,430 --> 00:19:52,400
Могут ли два потока одновременно
изменить mvar или mvar – это thread safe?

294
00:19:53,660 --> 00:19:55,040
mvar – это thread safe.

295
00:19:58,100 --> 00:20:05,660
Чтобы изменить mvar, конечно, есть в
модуле control.concurrent функция update.

296
00:20:05,740 --> 00:20:08,300
mvar, но на самом деле она
работает через put.mvar и take.mvar.

297
00:20:08,700 --> 00:20:11,500
Соответственно, чтобы изменить
mvar, нужно ее сначала взять,

298
00:20:11,960 --> 00:20:14,240
каким-либо образом изменить
значение и обратно положить.

299
00:20:14,900 --> 00:20:18,300
Несмотря на то, что для этого есть
обертка, она реализована именно так.

300
00:20:19,980 --> 00:20:23,060
Давайте представим ситуацию, что два
потока одновременно хотят изменить mvar.

301
00:20:24,720 --> 00:20:27,790
Так или иначе, какой-то
первый из них возьмет и

302
00:20:27,802 --> 00:20:31,080
прочитает значение с
помощью take.mvar из коробки.

303
00:20:31,535 --> 00:20:34,202
Второй в таком случае
залочится, потому что, переводя

304
00:20:34,214 --> 00:20:36,540
на аналогию из других
языков программирования,

305
00:20:36,660 --> 00:20:39,500
будет взят mutex на данную переменную.

306
00:20:39,960 --> 00:20:43,040
Поэтому второй поток будет ждать,
пока первый не положит обратно,

307
00:20:43,220 --> 00:20:44,920
и второй возьмет уже обновленную версию.

308
00:20:44,921 --> 00:20:47,320
Поэтому mvar – это третий примитив.

309
00:20:50,860 --> 00:20:51,860
Спасибо.

310
00:20:52,900 --> 00:20:54,040
Супер. Давайте продолжим.

311
00:20:55,340 --> 00:21:02,220
Как уже говорилось, mvar – это просто
значение, защищенное каким-то mutex.

312
00:21:03,220 --> 00:21:08,440
И там, где обычно у нас возникают mutex
в concurrency, у нас возникают и deadlocks.

313
00:21:09,100 --> 00:21:12,260
Давайте разберем самый
простейший пример deadlocks.

314
00:21:12,660 --> 00:21:17,060
Как мы уже обсуждали ранее, давайте
напишем main, в котором создается mvar,

315
00:21:17,740 --> 00:21:19,420
и мы будем бесконечно ждать mvar.

316
00:21:20,190 --> 00:21:22,860
Никаких других потоков в
нашем приложении не существует.

317
00:21:23,320 --> 00:21:28,000
Очевидно, что данный случай является
простейшим примером deadlock в Haskell.

318
00:21:29,020 --> 00:21:31,675
В данном случае, в силу
того, что рантайм-система

319
00:21:31,687 --> 00:21:34,680
Haskell умеет определять
такие базовые кейсы deadlocks,

320
00:21:35,360 --> 00:21:38,900
мы не будем ждать бесконечно, а наш
main поток завершится заключением,

321
00:21:38,901 --> 00:21:42,420
что thread blocked
indefinitely in mvar operation.

322
00:21:43,510 --> 00:21:46,940
Рантайм-система Haskell довольно
умная и умеет распознавать такие кейсы.

323
00:21:48,000 --> 00:21:50,020
Но не стоит над ним полагаться.

324
00:21:50,200 --> 00:21:54,410
Если у вас есть менее
тривиальный код, вполне возможно,

325
00:21:54,422 --> 00:21:58,260
что обычным reference
count это не задетектируешь.

326
00:21:58,360 --> 00:22:00,460
Можно представить, как
оно реализовано в Haskell.

327
00:22:01,000 --> 00:22:06,200
Мы будем просто на каждый mvar считать
количество потоков, которые ее ждут,

328
00:22:06,250 --> 00:22:08,074
которые ждут для того,
чтобы оттуда взять, и

329
00:22:08,086 --> 00:22:09,880
которые ждут для того,
чтобы туда положить.

330
00:22:10,480 --> 00:22:13,038
И если у нас не
сходятся эти значения,

331
00:22:13,050 --> 00:22:16,160
например, один поток
ждет, чтобы оттуда взять,

332
00:22:16,320 --> 00:22:19,920
но ноль потоков туда кладут. Очевидно,
в данном случае возникает deadlock.

333
00:22:22,615 --> 00:22:25,842
Есть еще подобные
исключения. Например, blocked

334
00:22:25,854 --> 00:22:29,300
indefinitely on mvar,
blocked indefinitely on stm.

335
00:22:30,300 --> 00:22:32,920
Также есть исключение deadlock.
Я его, кстати, ни разу не видел.

336
00:22:33,270 --> 00:22:36,527
Это, видимо, deadlock,
который возникает без

337
00:22:36,539 --> 00:22:40,700
использования mvar с другими
приоритетами синхронизации.

338
00:22:41,440 --> 00:22:44,298
Но сам факт, что такие
исключения для Haskell не

339
00:22:44,310 --> 00:22:47,180
редкость, и на самом деле
оно довольно полезное.

340
00:22:48,020 --> 00:22:51,660
Иногда можно действительно добыть
и допустить какую-то базовую ошибку,

341
00:22:52,300 --> 00:22:54,180
которая в рамках системы
Haskell сразу отловит.

342
00:22:57,040 --> 00:22:58,520
С mvar на этом закончили.

343
00:22:58,820 --> 00:23:01,828
И поговорим же теперь, что
можно делать с значением

344
00:23:01,840 --> 00:23:04,800
threadId, который возвращает
у нас функция forKeo.

345
00:23:05,400 --> 00:23:08,410
Делать можно, на самом
деле, более-менее одну вещь.

346
00:23:08,422 --> 00:23:11,780
Можно послать исключение
в данный поток oid.

347
00:23:12,550 --> 00:23:17,760
Делается это с помощью функции
throwTo. Она принимает threadId,

348
00:23:17,860 --> 00:23:20,320
принимает какое-то e, которое
является instance класса exception.

349
00:23:21,060 --> 00:23:25,320
То есть мы исключение с
вами касались на лекции про его.

350
00:23:26,340 --> 00:23:27,420
И ничего не возвращает.

351
00:23:28,220 --> 00:23:32,090
Также есть оберточка killThread
на функции throwTo, которая

352
00:23:32,102 --> 00:23:35,720
просто данному threadId
кидает исключение threadKilled.

353
00:23:36,640 --> 00:23:39,660
Но можно кинуть какое-то другое исключение.
То есть произвольный datatype,

354
00:23:40,300 --> 00:23:42,140
который является instance класса exception.

355
00:23:43,140 --> 00:23:44,840
Давайте разберем, как это можно делать.

356
00:23:45,380 --> 00:23:49,740
Мы спавним какое-то тяжелое вычисление,
которое может идти потенциально долго.

357
00:23:50,260 --> 00:23:52,160
И хотим реализовать timeout.

358
00:23:52,460 --> 00:23:59,180
Такой паттерн timeout, когда мы
хотим ждать максимум одну секунду.

359
00:23:59,600 --> 00:24:03,680
Иначе убивать данный поток.
Потому что мы не хотим ждать больше.

360
00:24:11,940 --> 00:24:13,180
Давайте продолжим.

361
00:24:13,260 --> 00:24:17,000
Соответственно, мы хотим реализовать timeout
в одну секунду для какого-то действия,

362
00:24:17,080 --> 00:24:19,706
которое потенциально может идти больше.
Что для этого можно сделать?

363
00:24:19,730 --> 00:24:24,940
Мы форкаем наше вычисление
потенциально тяжелое в

364
00:24:25,020 --> 00:24:27,520
отдельный поток, запоминаем
его threadId, ждем секунду.

365
00:24:28,080 --> 00:24:33,360
И если же секунда прошла, а данный
поток не завершился, мы его убиваем.

366
00:24:33,680 --> 00:24:37,060
Соответственно, если данный поток уже
завершился, killThread не будет ничего делать.

367
00:24:38,740 --> 00:24:40,680
Для этого нужна функция killThread.

368
00:24:41,430 --> 00:24:47,660
Но на самом-то деле
механизм забегает вперед.

369
00:24:47,740 --> 00:24:50,720
Немного скажу, что это
называется асинхронное исключение.

370
00:24:51,660 --> 00:24:53,708
Асинхронное исключение
отличается от обычных,

371
00:24:53,720 --> 00:24:55,780
которые мы с вами
разбирали на лекции про ИО.

372
00:24:57,300 --> 00:25:00,720
Допустим, когда мы читаем из файла, и
файла не существует, вылетает исключение.

373
00:25:01,760 --> 00:25:06,240
И так как это исключение
возникло в том же потоке,

374
00:25:06,300 --> 00:25:07,366
в котором мы работаем,
оно называется асинхронное.

375
00:25:07,390 --> 00:25:09,472
Асинхронное исключение
– это исключение, которое

376
00:25:09,484 --> 00:25:11,360
один какой-то поток
бросает другому потоку.

377
00:25:11,680 --> 00:25:14,900
Это очень похоже на
механизм сигналов в линуксе.

378
00:25:15,440 --> 00:25:18,568
Только вместо того, чтобы
бросать какую-то чиселку

379
00:25:18,580 --> 00:25:21,720
между разными процессами,
в нашем случае потоками,

380
00:25:22,320 --> 00:25:23,920
мы бросаем какие-то произвольные данные.

381
00:25:24,360 --> 00:25:28,800
И на самом деле, так как
мы умеем ловить эксепшены,

382
00:25:30,560 --> 00:25:33,460
с помощью функции throwTo
можно не только убивать поток.

383
00:25:33,710 --> 00:25:36,656
То есть killThread –
это один из видов того,

384
00:25:36,668 --> 00:25:39,760
как можно использовать
асинхронное исключение.

385
00:25:39,840 --> 00:25:43,680
На самом деле, если нам очень захочется, на
практике никто так, конечно же, не делает,

386
00:25:43,800 --> 00:25:46,194
можно с помощью асинхронного
исключения реализовать

387
00:25:46,206 --> 00:25:48,660
полноценный механизм
коммуникации между платформами.

388
00:25:49,200 --> 00:25:54,760
То есть можно какие-то осмысленные
данные класть в наш эксепшен,

389
00:25:55,600 --> 00:25:58,240
кидать его в какой-то поток, в
данном потоке ловить эксепшен,

390
00:25:58,720 --> 00:26:00,180
и как-то обрабатывать эти данные.

391
00:26:00,430 --> 00:26:05,020
Делать так, конечно же, не стоит, но сам
факт, что механизм асинхронных исключений,

392
00:26:05,340 --> 00:26:07,140
он не про то, как убивать потоки.

393
00:26:07,600 --> 00:26:12,500
Он про то, как посылать другому потоку
какое-то сообщение, какие-то данные.

394
00:26:12,860 --> 00:26:18,180
А уж как этими данными распоряжаться, за
это ответственный поток куда мы посылаем.

395
00:26:19,670 --> 00:26:23,620
На практике это куда более
сильный механизм, куда более

396
00:26:23,660 --> 00:26:25,000
мощный механизм, чем
просто взять и кинуть thread.

397
00:26:26,080 --> 00:26:28,520
Иногда пригождается каким-то
образом с этим исхитриться.

398
00:26:32,480 --> 00:26:33,680
Давайте рассмотрим еще пример.

399
00:26:35,130 --> 00:26:40,610
На то, как в нашем консольном
приложении делать gracefully handle,

400
00:26:40,970 --> 00:26:45,330
то есть каким-либо образом
обрабатывать осмысленно control-c,

401
00:26:45,750 --> 00:26:48,790
то есть seek-interrupt от пользователя.

402
00:26:50,650 --> 00:26:53,270
Так как это эксепшен,
который летит в наш мейн-поток.

403
00:26:53,970 --> 00:26:57,010
Мы помним, что для того, чтобы ловить
исключение, у нас есть функция catch,

404
00:26:57,560 --> 00:27:00,610
и также есть ее аналог, функция
handle, которая на самом деле flip-catch,

405
00:27:00,850 --> 00:27:03,210
то есть это кетч с флипнутыми аргументами.

406
00:27:03,790 --> 00:27:08,590
Напишем такую функцию как inter-hander,
который понимает async-exception.

407
00:27:10,190 --> 00:27:14,970
Давайте здесь несем ясность, что данная
async-exception – это просто тип данных,

408
00:27:15,030 --> 00:27:19,610
то есть это просто какой-то тип суммы
для популярных и синхронных исключений,

409
00:27:19,710 --> 00:27:21,470
которые определены в
стандартной библиотеке.

410
00:27:21,510 --> 00:27:24,269
Например, user-interrupt
– это когда пользователь

411
00:27:24,281 --> 00:27:26,430
нажимает control-c в
нашем приложении.

412
00:27:26,630 --> 00:27:30,430
Но данная async-exception и в принципе
концепция асинкронных эксепшенов,

413
00:27:31,010 --> 00:27:36,890
которые возникают при общении разных
потоков между собой – это разные вещи.

414
00:27:37,170 --> 00:27:39,468
Потому что мы можем создать
какой-нибудь myException,

415
00:27:39,480 --> 00:27:41,310
который не является
типом async-exception,

416
00:27:41,450 --> 00:27:42,530
и брать его в другой поток.

417
00:27:42,730 --> 00:27:47,310
Просто для удобства, для популярных,
часто встречающихся асинкронных исключений

418
00:27:47,585 --> 00:27:49,305
в стандартной библиотеке заведем дата-тайп.

419
00:27:49,790 --> 00:27:53,670
Одним из конструкторов
async-exception является user-interrupt,

420
00:27:54,810 --> 00:27:56,780
в который непосредственно
конвертится

421
00:27:56,792 --> 00:27:59,310
seek-interrupt, который
летит в наш main-поток.

422
00:27:59,890 --> 00:28:01,090
Что же мы, собственно, делаем?

423
00:28:01,130 --> 00:28:04,490
Мы запускаем какое-то длинное,
долгое вычисление в нашем main-потоке.

424
00:28:04,610 --> 00:28:09,930
Мы идем по числам от 1 до 1000,
на каждом из них ждем секунду,

425
00:28:10,210 --> 00:28:12,170
и печатаем кодсоль, что
завершили обрабатывать.

426
00:28:13,150 --> 00:28:18,530
Если же пользователь во время этого нажмет
control-c, у нас работает наш handler,

427
00:28:18,730 --> 00:28:21,350
то есть в наш main-поток
прилетит user-interrupt,

428
00:28:21,900 --> 00:28:25,490
и мы каким-либо образом можем
этот user-interrupt обработать.

429
00:28:25,570 --> 00:28:30,350
Например, в каких-либо более умных
случаях мы могли бы сделать clean-up

430
00:28:30,375 --> 00:28:32,575
каких-то ресурсов, которые
наша программа аллоцировала,

431
00:28:32,770 --> 00:28:34,810
чтобы не было никаких утечек.

432
00:28:37,940 --> 00:28:40,110
Получается, в случае
user-interrupt мы пишем кодсоль,

433
00:28:40,210 --> 00:28:43,050
что наша программа завершается,
так как ее проработал пользователь,

434
00:28:43,950 --> 00:28:46,770
иначе мы пишем, что поймали
какое-то другое асинкронное исключение.

435
00:28:50,170 --> 00:28:53,840
Есть вопросы по эксцепционам,
асинкронным? Да-да, слушаю.

436
00:28:55,100 --> 00:28:57,320
Можете сразу задавать.

437
00:28:58,810 --> 00:29:04,060
А ThreadId – это ID-шник потока
OS или внутри приложения?

438
00:29:04,900 --> 00:29:09,130
Внутри приложения. В
модуле control-concurrent

439
00:29:09,142 --> 00:29:13,200
есть функция, которая
называется OSThreadId,

440
00:29:13,900 --> 00:29:19,440
которая возвращает IoInt или IoThreadId,
которая непосредственно возвращает ID-шник

441
00:29:19,740 --> 00:29:23,660
OS-ного потока, на котором
запущен наш ThreadId.

442
00:29:24,220 --> 00:29:28,720
Но ThreadId – это ID-шник конкретного
легковесного green-thread-а хаскального.

443
00:29:31,400 --> 00:29:32,400
Спасибо.

444
00:29:35,485 --> 00:29:36,530
Окей, давайте продолжать.

445
00:29:37,850 --> 00:29:41,410
И сейчас немного резюмируем
наши знания об исключениях,

446
00:29:41,411 --> 00:29:45,350
которые у нас имеются из лекций
про Io и из сегодняшней лекции.

447
00:29:46,090 --> 00:29:50,690
Для того, чтобы кидать асинкронные исключения,
мы знаем, что существует две функции.

448
00:29:51,490 --> 00:29:54,910
Есть функция throwIo, которая
кидает исключения в Io-шном коде.

449
00:29:55,700 --> 00:29:58,330
И есть функция throw, которая
кидает исключения в чистом коде.

450
00:29:58,650 --> 00:30:04,770
Например, throwIo используется в
стандартной библиотеке, в функции openfile,

451
00:30:05,930 --> 00:30:07,990
которая реализована
через какой-то C-шный код.

452
00:30:08,290 --> 00:30:11,890
Нам это не важно. Абсолютно. Мы видим,
что здесь используется функция throwIo,

453
00:30:12,250 --> 00:30:14,270
которая кидает какое-то Io-шное исключение.

454
00:30:15,220 --> 00:30:18,790
В случае, допустим, деления на
0, мы кидаем чистое исключение,

455
00:30:18,890 --> 00:30:21,930
потому что в чистом коде мы также
хотим уметь кидать исключения.

456
00:30:22,410 --> 00:30:25,710
Для этого существуют
функции throw и throwIo.

457
00:30:26,550 --> 00:30:28,771
Может ли мне кто-нибудь
напомнить, какие функции

458
00:30:28,783 --> 00:30:30,690
бывают для того, чтобы
ловить исключения?

459
00:30:37,620 --> 00:30:39,080
Handle на предыдущем слайде.

460
00:30:39,100 --> 00:30:40,100
Handle и catch.

461
00:30:40,310 --> 00:30:41,310
Да, Handle и catch.

462
00:30:42,895 --> 00:30:44,620
Они Io-шные или чистые?

463
00:30:45,060 --> 00:30:48,380
Handle равно-равно catch. Можно с
точностью до перестановки аргументов.

464
00:30:48,540 --> 00:30:49,660
Давайте рассматривать catch.

465
00:30:50,925 --> 00:30:52,480
Это Io-шная или чистая
функция? Io-шная.

466
00:30:53,840 --> 00:30:54,840
Отлично.

467
00:30:56,620 --> 00:30:59,620
Теперь давайте
пофилософствуем над вопросом.

468
00:31:00,580 --> 00:31:02,200
А если же мы хотим...

469
00:31:02,201 --> 00:31:05,161
Вот у нас есть какой-то чистый
exception, допустим, в случае деления на 0,

470
00:31:05,570 --> 00:31:12,200
и мы хотим в чистом коде обработать
наше исключение, то есть деление на 0.

471
00:31:12,680 --> 00:31:15,740
Но функции для того,
чтобы это сделать, нет.

472
00:31:16,080 --> 00:31:18,840
Есть всего одна функция для того,
чтобы ловить исключение. Это catch.

473
00:31:19,940 --> 00:31:21,360
Вопрос, а как с этим жить?

474
00:31:22,240 --> 00:31:24,193
Правда лишь, что
если вся логика моей

475
00:31:24,205 --> 00:31:26,700
программы чистая, я не
могу поймать исключение.

476
00:31:30,060 --> 00:31:33,780
Видимо, это значит, что у вас деление
на 0 захардкошено в исходном коде,

477
00:31:34,000 --> 00:31:35,300
вы его не снаружи получили.

478
00:31:35,850 --> 00:31:37,960
Значит, с этим уже поздно что-то делать.

479
00:31:38,700 --> 00:31:41,040
Поздно ловить, нужно в
другом месте исправлять.

480
00:31:43,300 --> 00:31:49,080
Ну, давайте возьмем какие-то более хитрые
случаи возникновения чистых исключений,

481
00:31:49,660 --> 00:31:52,180
которые у нас появляются в чистом коде.

482
00:31:52,720 --> 00:31:57,400
Но я хочу в своей программе
его словить, чистое исключение.

483
00:31:57,980 --> 00:32:01,180
Но проблема в том, что у
меня вся программа чистая.

484
00:32:01,230 --> 00:32:05,200
Представим, что логика
всей моей программы чистая.

485
00:32:06,020 --> 00:32:07,620
Я не могу словить исключение.

486
00:32:08,740 --> 00:32:10,380
Правда ли? Тут в моем
вопросе есть небольшой подвох.

487
00:32:10,520 --> 00:32:14,160
Просто он довольно сильно открывает
глаза, этот вопрос на происходящее.

488
00:32:15,560 --> 00:32:17,240
Хотел бы, чтобы указали на подвох.

489
00:32:19,085 --> 00:32:21,186
Кажется просто, что если
у нас летит исключение,

490
00:32:21,198 --> 00:32:23,620
значит у нас, скорее всего,
какое-то нечистое действие.

491
00:32:25,010 --> 00:32:29,140
Максимум, что мы можем сделать из
чистого такого, что бросит нам исключение,

492
00:32:29,240 --> 00:32:32,420
это как раз-таки какая-нибудь
именно логическая ошибка,

493
00:32:32,665 --> 00:32:35,560
которую мы просто сами
должны ручками отхандлить.

494
00:32:35,900 --> 00:32:37,900
Например, разделение на
ноль – это просто заефать.

495
00:32:38,020 --> 00:32:41,600
Если, условно говоря, что-то еще
происходит, что-то очень страшное,

496
00:32:41,690 --> 00:32:44,860
то это просто заефать или
вынести в отдельную функцию.

497
00:32:45,800 --> 00:32:48,380
Ну, это как опция. Я согласен.

498
00:32:48,440 --> 00:32:53,000
На самом деле функции
error и undefined, с которыми вы

499
00:32:53,080 --> 00:32:56,400
хорошо знакомы, они
реализованы через функцию throw.

500
00:32:56,700 --> 00:33:00,980
Допустим, функция error реализовывается
через throw, так называемый error call.

501
00:33:01,440 --> 00:33:03,360
Это один из конструкторов exception.

502
00:33:05,260 --> 00:33:07,800
Но хочется все-таки их ловить,
и давайте уже я тамить не буду.

503
00:33:08,680 --> 00:33:11,537
На самом деле подвох в
моем вопросе заключается в

504
00:33:11,549 --> 00:33:14,360
том, что вся моя программа
не может быть чистой.

505
00:33:14,380 --> 00:33:18,720
У меня точка входа в программу –
это main, который так или иначе ушли.

506
00:33:19,220 --> 00:33:24,080
Поэтому если уж мне очень хочется поймать
exception, который я кинул в чистом коде,

507
00:33:24,430 --> 00:33:29,360
я это могу сделать только в ближайшем иошном
коде, который вызывает мой чистый код.

508
00:33:30,440 --> 00:33:32,579
В хаскале по-другому
никак. То есть в чистом

509
00:33:32,591 --> 00:33:34,840
коде нельзя ловить
exception, только в иошном.

510
00:33:35,380 --> 00:33:37,810
Но в крайнем случае,
если уж нам очень хочется,

511
00:33:37,822 --> 00:33:40,160
в любой программе есть
иошный код – это main,

512
00:33:40,630 --> 00:33:42,140
и там мы можем поймать исключение.

513
00:33:45,100 --> 00:33:46,960
Вот в этом суть.

514
00:33:48,330 --> 00:33:49,490
А если в программе нету main?

515
00:33:53,170 --> 00:33:57,068
Допустим, если вы пишите
библиотеку, так или иначе вы будете

516
00:33:57,080 --> 00:34:00,860
ее использовать в конце концов
в каком-нибудь экзекютабле.

517
00:34:01,620 --> 00:34:02,620
И там есть main.

518
00:34:05,360 --> 00:34:11,060
Если же вы пишете библиотеку, в
которой нет никаких иошных функций,

519
00:34:11,100 --> 00:34:14,620
допустим, это библиотека для
арифметики, где трудно себе представить ее,

520
00:34:15,220 --> 00:34:19,540
то действительно поймать exception,
который вы кидаете из этой библиотеки,

521
00:34:19,800 --> 00:34:24,580
можно только в программе, которая
импортит вашу библиотеку в ее main.

522
00:34:25,300 --> 00:34:27,220
Ну или в другой ее иошной функции.

523
00:34:28,195 --> 00:34:30,300
Но мы здесь рассматриваем
программу в хаскале

524
00:34:30,312 --> 00:34:33,040
непосредственно как полноценное
приложение с точкой входа.

525
00:34:33,140 --> 00:34:37,020
То есть написание библиотек
на такие вещи мы не делим.

526
00:34:38,080 --> 00:34:40,310
Потому что так или иначе
вашу программу плюс чью-то

527
00:34:40,322 --> 00:34:42,520
библиотеку можно
рассматривать как одну программу.

528
00:34:48,610 --> 00:34:49,760
Окей, давайте пойдем дальше.

529
00:34:50,680 --> 00:34:53,780
И сегодня мы с вами изучили еще
один способ бросать исключения.

530
00:34:54,060 --> 00:34:56,560
Это функция throwTool, которая
бросает асинхронные исключения.

531
00:34:57,520 --> 00:35:00,690
Важная ремарка, что с точки
зрения рантайм-системы хаскаля,

532
00:35:02,000 --> 00:35:04,963
эксепшены синхронные
и эксепшены асинхронные

533
00:35:04,975 --> 00:35:07,680
оба представлены
type-классом exception.

534
00:35:08,185 --> 00:35:11,125
То есть нет никакого
различия для рантайма хаскаля,

535
00:35:11,137 --> 00:35:14,320
является ли данный эксепшен
синхронным или асинхронным.

536
00:35:16,020 --> 00:35:20,800
Различие между этими эксепшенами сугубо
семантическое по происхождению исключения.

537
00:35:20,940 --> 00:35:23,195
Произошло ли оно в
том же потоке, то есть

538
00:35:23,207 --> 00:35:25,640
является ли оно
асинхронным или асинхронным.

539
00:35:25,700 --> 00:35:27,460
Рантайм-системе хаскаля на это наплевать.

540
00:35:32,350 --> 00:35:36,240
Итого, мы имеем три способа кидать
исключения, два из которых кидают синхронные,

541
00:35:36,440 --> 00:35:37,840
одно из которых кидает асинхронные.

542
00:35:38,340 --> 00:35:40,620
И ровно один способ,
как эти исключения ловить.

543
00:35:41,195 --> 00:35:45,360
Таким образом, небольшой
самый нашей работы с эксепшеном.

544
00:35:46,460 --> 00:35:50,760
Как ловить асинхронные исключения с помощью
функции handle представлена на примере.

545
00:35:51,040 --> 00:35:53,240
Ровно так же мы ловим
наши асинхронные исключения.

546
00:35:53,760 --> 00:35:55,140
Между ними никакой разницы нет.

547
00:35:56,440 --> 00:35:57,440
Можно вопрос?

548
00:35:57,940 --> 00:35:58,080
Да.

549
00:35:58,560 --> 00:36:02,780
А у нас исключение
кидается в момент ожидания?

550
00:36:06,040 --> 00:36:07,240
Не совсем понял вопрос.

551
00:36:07,300 --> 00:36:13,260
Вы имеете в виду, допустим,
исключение в контексте

552
00:36:13,280 --> 00:36:15,020
эмбарго, когда мы ждем
какой-то mutex или что?

553
00:36:17,980 --> 00:36:18,500
Да.

554
00:36:18,880 --> 00:36:23,004
То есть в какой-нибудь Java,
например, у нас исключение

555
00:36:23,016 --> 00:36:26,400
из потока в поток кидается
в момент ожидания.

556
00:36:26,540 --> 00:36:28,800
То есть thread sleep или thread wait.

557
00:36:28,801 --> 00:36:30,940
Какой-то такой потуз.

558
00:36:31,740 --> 00:36:33,040
То же самое?

559
00:36:33,540 --> 00:36:37,220
В Haskell асинхронное исключение
может прилететь в любой момент.

560
00:36:39,060 --> 00:36:43,840
То есть он может прервать какую-то
операцию, если она не атомарна.

561
00:36:45,170 --> 00:36:49,680
Когда мы пишем concurrent код в Haskell,
мы должны держать в голове всегда,

562
00:36:50,040 --> 00:36:54,160
что во время любой нашей операции нам
может прилететь асинхронное исключение,

563
00:36:54,580 --> 00:36:57,940
которое нам по-хорошему бы
обработать в терминах очистки ресурсов.

564
00:36:58,190 --> 00:37:00,840
То есть просто навесить
хендлер на нашу программу.

565
00:37:00,920 --> 00:37:04,240
Допустим, когда мы открыли
файл, во время того, когда у нас

566
00:37:04,280 --> 00:37:05,776
файл открыт, нам может
прилететь асинхронное исключение.

567
00:37:05,800 --> 00:37:08,060
Если мы не повесили хендлер,
наш поток просто умрет.

568
00:37:08,720 --> 00:37:10,740
Вот мы никаким образом
не заглянапали ресурсы.

569
00:37:11,400 --> 00:37:16,700
Поэтому в Haskell дело стоит так, что
абсолютно в любой момент исключение прилетает.

570
00:37:18,440 --> 00:37:19,440
Понял, спасибо.

571
00:37:21,720 --> 00:37:24,940
Давайте разберем немного
примеров с исключениями.

572
00:37:26,560 --> 00:37:28,900
Как их можно кидать и как их можно ловить.

573
00:37:29,600 --> 00:37:31,180
Первый пример достаточно простой.

574
00:37:31,720 --> 00:37:34,160
Мы с помощью функции throw
его кидаем какой-то myException,

575
00:37:34,640 --> 00:37:37,460
который мы определили и
реализовали для него instanceException.

576
00:37:38,500 --> 00:37:41,120
Мы его кидаем, сразу же
ловим с помощью функции catch,

577
00:37:41,600 --> 00:37:44,440
и печатаем в консоль,
что мы поймали эксепшен.

578
00:37:44,900 --> 00:37:46,101
Здесь все довольно тривиально.

579
00:37:46,980 --> 00:37:49,760
Затем разберем чисто эксепшен
и, допустим, деление на 0.

580
00:37:50,300 --> 00:37:51,720
Здесь мы используем функцию when.

581
00:37:51,970 --> 00:37:54,280
When, как мы помним,
это монетическая функция,

582
00:37:55,760 --> 00:37:58,720
которая принимает какое-то
условие и выполняет действие,

583
00:37:59,560 --> 00:38:00,900
если это условие верно.

584
00:38:00,960 --> 00:38:03,020
Если это условие не верно,
ничего не выполняется.

585
00:38:03,100 --> 00:38:05,620
Иными словами, происходит
return в пустой скубочке.

586
00:38:05,940 --> 00:38:10,600
Это просто такая обертка на
default в бенче else в пустой скубочке.

587
00:38:12,230 --> 00:38:14,386
Таким образом мы
форсим данное выражение

588
00:38:14,398 --> 00:38:17,000
вычислиться до слабой
головной нормальной формы,

589
00:38:17,120 --> 00:38:19,340
чтобы проверить, истинно или ложно условие.

590
00:38:20,480 --> 00:38:23,720
Ловим исключение с помощью функции catch.

591
00:38:24,740 --> 00:38:27,580
В данном случае бросится
исключение типа it's exception,

592
00:38:28,160 --> 00:38:29,640
а именно его конструктор divide by 0.

593
00:38:30,380 --> 00:38:33,280
Мы его ловим и печатаем
в консоль, что поймали,

594
00:38:33,680 --> 00:38:36,720
также с помощью функции
catch, уже чистое исключение.

595
00:38:37,780 --> 00:38:42,760
И в конце концов разберем, как кидать
и как ловить синхронные исключения.

596
00:38:43,780 --> 00:38:46,420
Соответственно, мы форкаем
какое-то вычисление в отдельный поток,

597
00:38:46,421 --> 00:38:50,740
в нем мы ждем, и печатаем
в консоль, что дело сделано.

598
00:38:52,240 --> 00:38:55,100
И навешиваем на это действие хендлер.

599
00:38:55,500 --> 00:38:57,940
То есть этот хендлер
относится к этому действию.

600
00:38:58,020 --> 00:38:59,720
То есть он идет после форкового.

601
00:39:00,740 --> 00:39:04,040
Точнее, он относится к действию,
которую мы форкнули в отдельный поток.

602
00:39:05,140 --> 00:39:09,440
В catch мы также ловим наш myException
и печатаем, что мы его поймали.

603
00:39:10,540 --> 00:39:13,340
Ждем какое-то время,
меньшее, чем на что это работает,

604
00:39:13,490 --> 00:39:16,060
и кидаем myException на стред.

605
00:39:16,580 --> 00:39:19,600
То есть здесь просто для
примера было разобрано,

606
00:39:19,740 --> 00:39:26,360
что API для работы для того, чтобы кидать и
ловить синхронные исключения, довольно похож.

607
00:39:26,460 --> 00:39:29,580
То есть ловим мы
их все одинаково,

608
00:39:29,980 --> 00:39:31,800
а кидаем просто используя разные функции.

609
00:39:32,620 --> 00:39:35,220
То есть интерфейс exception в
Haskell более-менее унифицирован.

610
00:39:40,320 --> 00:39:43,570
Если есть какие-то вопросы по
исключениям, давайте, иначе пойдем дальше.

611
00:39:49,680 --> 00:39:50,680
Супер, видимо, нет.

612
00:39:52,130 --> 00:39:55,722
И поговорим про сложности
и трудности, которые

613
00:39:55,734 --> 00:39:58,790
у нас бывают во
время очистки ресурсов.

614
00:39:59,210 --> 00:40:00,410
Представим себе такой код.

615
00:40:02,290 --> 00:40:05,930
Наш main – это какое-то
действие со следующим handler.

616
00:40:06,150 --> 00:40:08,110
То есть мы ловим какой-то
произвольный exception.

617
00:40:08,750 --> 00:40:13,290
Кстати, напомнит ли мне
кто-нибудь, как в Haskell,

618
00:40:14,870 --> 00:40:18,170
используя функцию catch, можно
поймать абсолютно любой exception?

619
00:40:23,280 --> 00:40:27,960
То есть здесь мы видим, что
мы матчимся по myException.

620
00:40:28,220 --> 00:40:31,420
Это значит, что функция
catch, сигнатура ее хендлера,

621
00:40:32,400 --> 00:40:34,885
то есть сигнатура ее
второго аргумента – это

622
00:40:34,897 --> 00:40:37,280
myException, стрелка
и о, пустые скобочки.

623
00:40:38,660 --> 00:40:40,640
А как нам поймать любое исключение?

624
00:40:41,040 --> 00:40:46,320
То есть любое значение является
представителем класса типа catchException.

625
00:40:47,980 --> 00:40:50,420
Мы это разбирали на лекции про EO.

626
00:40:57,360 --> 00:40:59,490
Можно-то, по-моему, ловить catchException.

627
00:41:03,450 --> 00:41:05,650
Проблема в том, что
exception – это declass.

628
00:41:08,370 --> 00:41:14,070
Создадим класс, который является
instanceException, это exception и что-то такое.

629
00:41:14,071 --> 00:41:18,570
Мы здесь писали раньше чуть
выше instanceException, myException,

630
00:41:18,825 --> 00:41:21,746
только теперь мы сделаем instanceException,
exception его назовем, и все.

631
00:41:24,910 --> 00:41:26,390
Это ничем не будет отличать.

632
00:41:26,430 --> 00:41:29,810
Во-первых, конфликта имен у
вас, кажется, все-таки не будет,

633
00:41:30,250 --> 00:41:32,070
потому что это type класса, это data type.

634
00:41:33,590 --> 00:41:36,106
Потому что в худшем случае у
вас будет здесь конфликт нейминга,

635
00:41:36,130 --> 00:41:38,330
но в лучшем случае у вас
абсолютно ничего не изменится,

636
00:41:38,430 --> 00:41:42,120
потому что ваш exception отличается
от myException только именем.

637
00:41:42,295 --> 00:41:46,100
То есть мысловой нагрузки оно не несет.

638
00:41:46,680 --> 00:41:48,716
То есть exception – это не
какое-то магическое слово,

639
00:41:48,740 --> 00:41:51,380
которое позволяет в Haskell
ловить произвольные исключения.

640
00:41:54,450 --> 00:41:56,690
Давайте, если никто не
помнит, я немного напомню,

641
00:41:56,990 --> 00:42:02,110
что у нас есть такой data type,
который называется someException.

642
00:42:04,470 --> 00:42:05,470
Сейчас напишу в чате.

643
00:42:07,890 --> 00:42:13,710
Это коробочка, которая умеет содержать
внутри себя любое произвольное исключение.

644
00:42:14,410 --> 00:42:21,410
И у нас в type классе exception существуют
функции fromException и toException.

645
00:42:22,550 --> 00:42:25,250
И с помощью функции fromException
можно привести someException,

646
00:42:25,390 --> 00:42:28,150
то есть какое-то произвольное
исключение, мы пока не знаем, какое.

647
00:42:28,530 --> 00:42:31,310
То есть какое-то наше исключение,
которое лежит в коробочке.

648
00:42:31,710 --> 00:42:35,310
Мы с помощью функции
fromException можем попытаться

649
00:42:35,311 --> 00:42:37,750
скальфить это произвольное
исключение к нашему.

650
00:42:37,900 --> 00:42:40,086
Можно с помощью
функции fromException

651
00:42:40,098 --> 00:42:42,950
попытаться привести
someException к myException.

652
00:42:43,630 --> 00:42:45,210
Функция fromException разрешает maybe.

653
00:42:45,350 --> 00:42:49,510
То есть либо нам удалось распаковать
someException, и там лежит то, что нам нужно,

654
00:42:50,250 --> 00:42:52,990
либо там лежит что-то другое.

655
00:42:53,050 --> 00:42:54,530
В данном случае нам вернется nothing.

656
00:42:55,070 --> 00:42:58,790
Таким образом, если мы хотим в нашей
функции поймать произвольное исключение,

657
00:42:59,410 --> 00:43:01,990
но каким-либо конкретным
образом обработать, допустим,

658
00:43:02,670 --> 00:43:06,690
fileNotFound и divideByZero, условно
говоря, мы ловим someException,

659
00:43:09,190 --> 00:43:13,230
пытаемся достать из него
arithException, то есть divideByZero.

660
00:43:13,330 --> 00:43:16,390
Если нам удалось, мы каким-либо
образом в специфичном обрабатываем.

661
00:43:16,890 --> 00:43:19,590
Затем, если нам не
удалось, мы пытаемся достать

662
00:43:19,602 --> 00:43:21,910
оттуда ioshnyException
pro fileNotFound.

663
00:43:22,310 --> 00:43:26,390
Если нам удалось, мы каким-либо образом
чистим ресурсы или делаем что-то еще.

664
00:43:27,100 --> 00:43:30,230
И в каком-то общем кейсе, если
там лежит что-то, что нам неизвестно,

665
00:43:30,231 --> 00:43:33,111
какое-то произвольное исключение
другое, которое нам не удалось достать,

666
00:43:33,370 --> 00:43:37,710
мы каким-то последним
случаем это обрабатываем.

667
00:43:39,450 --> 00:43:40,691
В чем фундаментальная проблема?

668
00:43:41,070 --> 00:43:46,650
В том, что тип нашего хендлера, вот
этот аргумент, он называется хендлер.

669
00:43:47,110 --> 00:43:48,590
То есть это обработчик с исключением.

670
00:43:49,250 --> 00:43:51,330
Он должен иметь какой-то конкретный тип.

671
00:43:52,190 --> 00:43:54,970
Мы здесь можем ловить только
какой-то конкретный exception.

672
00:43:54,971 --> 00:43:57,850
Допустим, myException или ourException.

673
00:43:58,110 --> 00:44:00,790
Мы не можем тут поймать
какой-то е, который exception.

674
00:44:01,330 --> 00:44:03,369
И вот для того, чтобы
уметь поймать что-то

675
00:44:03,381 --> 00:44:05,970
произвольное, придумали
такую вещь, как самException.

676
00:44:06,950 --> 00:44:11,910
В него runtimeHaskell умеет запаковывать
исключение, которое мы бросили.

677
00:44:12,010 --> 00:44:14,730
Которое мы потом на стороне
ловли можем распаковать.

678
00:44:15,500 --> 00:44:16,980
На самом деле довольно важный аспект.

679
00:44:17,510 --> 00:44:19,865
Если кто не помнит, я
советую пересмотреть

680
00:44:19,877 --> 00:44:22,470
это дело, пересмотреть
слайды в лекции про IO.

681
00:44:23,020 --> 00:44:24,861
Мы там довольно подробно
на этом остановились.

682
00:44:26,050 --> 00:44:28,950
Сейчас это было просто
в качестве напоминания.

683
00:44:32,010 --> 00:44:33,590
На чем мы остановились?

684
00:44:33,710 --> 00:44:38,690
Мы остановились на том, какие у нас
подводные камни могут быть вот в таком ходе.

685
00:44:38,810 --> 00:44:42,230
То есть мы запускаем экшен, ловим
с помощью него какой-то exception,

686
00:44:44,330 --> 00:44:47,270
печатаем ошибку в консоль
и делаем какой-то cleanup.

687
00:44:47,910 --> 00:44:49,890
Видите ли вы какой-то подвох в этом ходе?

688
00:44:49,930 --> 00:44:50,930
Что может быть не так?

689
00:44:57,380 --> 00:44:59,431
Учитывая то, что для
нашей программы,

690
00:44:59,443 --> 00:45:02,120
представьте, критически
важно почистить ресурсы.

691
00:45:04,140 --> 00:45:05,220
Прям очень важно.

692
00:45:05,940 --> 00:45:07,240
Ошибка во время cleanup.

693
00:45:08,300 --> 00:45:09,900
Да, либо ошибка во время cleanup.

694
00:45:11,270 --> 00:45:16,320
Или, допустим, эта ошибка может
быть как синхронная, так и асинхронная.

695
00:45:16,960 --> 00:45:20,259
Вряд ли функция printError
умеет кидать синхронное

696
00:45:20,271 --> 00:45:23,980
исключение, по ее логике,
если мы ее нормально написали.

697
00:45:24,480 --> 00:45:27,340
Но вполне возможно, она может
произойти асинхронное исключение.

698
00:45:30,350 --> 00:45:31,551
Давайте попробуем сделать так.

699
00:45:33,080 --> 00:45:36,680
Но на самом-то деле, если
присмотреться, лучше не становится.

700
00:45:36,880 --> 00:45:41,171
У нас возникает бесконечная
лесенка из кечей, вложенных

701
00:45:41,183 --> 00:45:44,860
в каждом из которых
может произойти исключение.

702
00:45:45,890 --> 00:45:47,700
Сейчас мы разберемся, как с этим бороться.

703
00:45:49,040 --> 00:45:51,020
У нас есть такая
замечательная функция mask.

704
00:45:51,980 --> 00:45:54,640
Вообще, существует две
вариации функции mask.

705
00:45:54,760 --> 00:45:57,060
Есть функция просто
mask, она более сложная.

706
00:45:57,480 --> 00:46:00,160
Мы разберем более простой
случай, mask с нижним подчеркиваем.

707
00:46:00,620 --> 00:46:03,717
Это функция, которая
принимает какое-то иошное

708
00:46:03,729 --> 00:46:06,500
действие и оборачивает
его таким образом,

709
00:46:06,780 --> 00:46:09,820
что оно защищено от асинхронных исключений.

710
00:46:10,440 --> 00:46:13,700
То есть, в данном случае,
пока наше действие

711
00:46:13,712 --> 00:46:16,760
замаскировано, если
можно так выразиться,

712
00:46:16,985 --> 00:46:20,760
то его не может интерактнуть
асинхронные исключения.

713
00:46:21,160 --> 00:46:25,660
То есть, мы намеренно преграждаем, как
будто образуется очередь из исключений,

714
00:46:25,820 --> 00:46:28,360
если они туда летят, и
перед ними ставится такое.

715
00:46:28,700 --> 00:46:31,435
Но если это визуализировать,
то можно сказать, что

716
00:46:31,447 --> 00:46:34,140
мы блокируем проникновение
exception в наш поток.

717
00:46:34,900 --> 00:46:36,860
Блокируем, чтобы наш
exception прервался в поток.

718
00:46:38,300 --> 00:46:40,840
К сожалению, функция mask
– это довольно опасная штука,

719
00:46:41,490 --> 00:46:44,940
потому что таким
образом у нас появляется...

720
00:46:44,941 --> 00:46:49,940
Если же во время действия этого, которое
мы оборачиваем с помощью функции mask,

721
00:46:50,640 --> 00:46:53,467
наша программа внезапно
зацикливается, то с ней

722
00:46:53,479 --> 00:46:56,620
ничего нельзя делать,
кроме как кинуть ей seek kill.

723
00:46:57,300 --> 00:47:02,300
Потому что ни на какие асинхронные
исключения, ни на всякие seek interrupt,

724
00:47:02,400 --> 00:47:05,120
которые конвертятся в haskell
на user interrupt, она не реагирует.

725
00:47:05,460 --> 00:47:08,340
То есть, лучшее, что мы можем
сделать с этой программой – это ее кинуть.

726
00:47:08,970 --> 00:47:11,530
Поэтому функцию mask нужно
использовать с осторожностью.

727
00:47:12,130 --> 00:47:16,750
На какие-то минимальные действия,
допустим, на чистку ресурсов,

728
00:47:17,190 --> 00:47:19,772
в которых мы точно уверены,
что там не может произойти

729
00:47:19,784 --> 00:47:22,090
никакого зацикливания
или бесконечного ожидания.

730
00:47:22,490 --> 00:47:25,890
Потому что если мы в отчистке
ресурсов хотим ходить куда-то по сети,

731
00:47:27,710 --> 00:47:31,070
где возможен потенциальный
тайм-аут, мы не хотим этого делать.

732
00:47:32,220 --> 00:47:37,430
Поэтому для таких случаев функцию
cleanup мы оборачиваем функцию mask.

733
00:47:38,000 --> 00:47:41,030
И если же наша функция cleanup
достаточно минималистичная,

734
00:47:41,450 --> 00:47:44,950
то есть просто поудалять
какие-то файлики или что-то еще,

735
00:47:45,750 --> 00:47:49,090
хотя это тоже может быть небезопасно,
мы пользуемся функцией mask.

736
00:47:56,700 --> 00:47:58,820
Есть ли какие-то вопросы, может быть?

737
00:48:02,040 --> 00:48:06,590
А если исключение прилетит во время
принтерора, то мы тоже должны обернуть маску?

738
00:48:08,480 --> 00:48:11,813
Да, можно написать.
По-хорошему надо было,

739
00:48:11,825 --> 00:48:15,330
наверное, раз уж мы
говорим о худшем случае,

740
00:48:16,510 --> 00:48:21,610
то действительно по-хорошему
обернуть весь дублок в маску.

741
00:48:21,950 --> 00:48:25,070
Также потому что исключение действительно
может прилететь во время принтерора,

742
00:48:25,650 --> 00:48:28,930
пока наше действие еще
не стало замаскировано.

743
00:48:35,450 --> 00:48:37,780
Можно еще раз быстренько? Что такое mask?

744
00:48:38,640 --> 00:48:44,080
Это функция, которая оборачивает
наше действие какое-то иошное

745
00:48:44,605 --> 00:48:48,220
и возвращает новое иошное действие
в так называемом masked state.

746
00:48:48,460 --> 00:48:51,300
То есть, на самом деле, если лезть
по трахаронтайм-системе в Haskell

747
00:48:52,260 --> 00:48:55,080
и посмотреть состояние,
какие бывают у потоков,

748
00:48:55,081 --> 00:48:57,762
он может быть запущен,
он может ожидать, и

749
00:48:57,774 --> 00:49:00,660
вот одно из этих состояний
называется masked.

750
00:49:01,310 --> 00:49:06,940
Это значит, что данный поток не может
быть прерван асинхронным исключением.

751
00:49:07,380 --> 00:49:12,120
Представьте, что все асинхронные
исключения, которые летят в наше действие,

752
00:49:12,700 --> 00:49:16,480
которые находятся под
маском, они туда не долетают.

753
00:49:17,260 --> 00:49:20,980
Таким образом, оборачивая какое-либо
действие с помощью функции mask,

754
00:49:22,120 --> 00:49:26,600
мы делаем это действие непрерываемым
нашими асинхронными исключениями.

755
00:49:27,060 --> 00:49:28,100
Какая может быть проблема?

756
00:49:28,390 --> 00:49:30,513
Проблема может быть
в том, что если вот это

757
00:49:30,525 --> 00:49:32,760
действие, которое мы
обернули в функцию mask,

758
00:49:33,200 --> 00:49:36,440
содержит в себе потенциальную
бесконечную рекурсию или что-то еще,

759
00:49:36,760 --> 00:49:39,600
или там какое-то долгое время
исполнения, если мы идем куда-то по сети,

760
00:49:40,460 --> 00:49:44,260
нам нашу программу становится
никаким образом непрерывательным.

761
00:49:44,360 --> 00:49:48,300
Потому что на seekInterrupt
условно оно не будет реагировать,

762
00:49:48,400 --> 00:49:50,858
потому что seekInterrupt
представлен в Haskell

763
00:49:50,870 --> 00:49:53,340
с соответствующим
исключением – userInterrupt.

764
00:49:53,765 --> 00:49:55,387
Лучшее, что мы можем
сделать, и единственное,

765
00:49:55,399 --> 00:49:56,816
что мы можем сделать
в нашей программе,

766
00:49:56,840 --> 00:49:59,440
это посылать туда seekKill, потому
что для него нет обработчиков.

767
00:50:00,150 --> 00:50:02,150
Поэтому функцию mask
нужно использовать осторожно,

768
00:50:02,480 --> 00:50:06,560
только в критически важных и минимальных
местах, когда нам нужно почистить ресурсы.

769
00:50:08,340 --> 00:50:09,380
Вот такая мораль.

770
00:50:15,600 --> 00:50:18,157
Но на самом деле, слава
богу, нам не приходится

771
00:50:18,169 --> 00:50:20,520
в реальной жизни
использовать функцию mask,

772
00:50:20,770 --> 00:50:24,149
потому что за нас придумали
более высокоуровневые

773
00:50:24,161 --> 00:50:26,860
обработчики способа
работы с ресурсами.

774
00:50:27,160 --> 00:50:31,020
Мы уже на лекции про IO разбирали
такие функции, как bracket и final.

775
00:50:32,180 --> 00:50:36,720
Функция bracket представляет собой
реализацию идиомы RAI в Haskell.

776
00:50:37,180 --> 00:50:41,065
Это когда мы сначала
берем, acquire-им какой-то

777
00:50:41,077 --> 00:50:44,560
ресурс с помощью
нашего первого аргумента,

778
00:50:46,300 --> 00:50:48,820
мы предоставляем туда
какое-то действие, которое

779
00:50:48,832 --> 00:50:51,100
своим результатом
дает нам какой-то ресурс.

780
00:50:51,240 --> 00:50:54,360
Например, descriptor файл
или соединение с базой данных.

781
00:50:55,580 --> 00:51:01,460
Вторым аргументом мы принимаем
вычисления по освобождению нашего ресурса.

782
00:51:01,685 --> 00:51:04,201
То есть функцию из A в
IO B, которая принимает

783
00:51:04,213 --> 00:51:06,960
наш ресурс A, который был
рожден первым действием,

784
00:51:07,360 --> 00:51:09,400
и каким-либо образом с
ним работает, закрывает его.

785
00:51:09,590 --> 00:51:11,789
Допустим, закрыть соединение
с базой данных, закрыть

786
00:51:11,801 --> 00:51:14,140
сокет, закрыть файловый
дескриптор, что-то в этом духе.

787
00:51:14,780 --> 00:51:17,686
И третьим аргументом
мы принимаем вычисления,

788
00:51:17,698 --> 00:51:20,940
какое-то действие, которое
запускается между ними.

789
00:51:21,120 --> 00:51:23,559
То есть мы сначала
acquire-им ресурс, потом

790
00:51:23,571 --> 00:51:26,080
запускаем действие,
потом release-им ресурс.

791
00:51:27,340 --> 00:51:34,620
Функция bracket, вторая операция по
релизу ресурса, на нее навежен маск.

792
00:51:35,070 --> 00:51:38,960
То есть в явном виде маск мы
практически никогда не применяем.

793
00:51:39,040 --> 00:51:42,129
Потому что для работы с
ресурсами, как правило, в Hustle

794
00:51:42,141 --> 00:51:45,740
наиболее лучшей практикой является
использование функции bracket.

795
00:51:46,600 --> 00:51:49,453
Поэтому функция mask на самом
деле просто находится под капотом

796
00:51:49,465 --> 00:51:52,240
нашей функции bracket, которую
мы юзаем в повседневной жизни.

797
00:51:52,880 --> 00:51:55,173
Но мы коснулись функции
mask просто для того, чтобы

798
00:51:55,185 --> 00:51:57,400
понять, почему именно
функция bracket так хороша.

799
00:51:57,720 --> 00:52:00,221
Во-первых, у нее довольно
удобный интерфейс, во-вторых, она

800
00:52:00,233 --> 00:52:02,660
защищает нас от эксепшенов
во время освобождения ресурса.

801
00:52:04,910 --> 00:52:07,671
Также есть функция finally, она не
такая популярная, но тем не менее.

802
00:52:09,910 --> 00:52:13,940
Это представляет собой аналог finally блока
в той же Java, только в Hustle это функция.

803
00:52:14,260 --> 00:52:18,480
То есть мы принимаем какое-то вычисление
и принимаем следующее вычисление.

804
00:52:19,360 --> 00:52:21,921
Я всегда говорю про иошные
действия, я всегда говорю вычисления.

805
00:52:23,030 --> 00:52:24,937
Просто привычка, то
есть очевидно у нас любое

806
00:52:24,949 --> 00:52:26,740
действие в Hustle это
какое-то вычисление.

807
00:52:27,660 --> 00:52:30,602
То есть мы принимаем
какое-то иошное действие и затем

808
00:52:30,614 --> 00:52:33,680
принимаем действие, которое
будет выполнено после него.

809
00:52:33,805 --> 00:52:37,140
Даже если в данном случае
будет кинутые исключения.

810
00:52:37,800 --> 00:52:40,420
Это literally, finally
из какой-нибудь Java.

811
00:52:42,570 --> 00:52:45,896
То есть finally отличается от
bracket тем, что у нас нет первого

812
00:52:45,908 --> 00:52:48,880
действия, которое дает нам
ресурс, которым мы пользуемся.

813
00:52:51,440 --> 00:52:54,500
Ну и да, мораль всей басни.

814
00:52:55,820 --> 00:52:58,478
Использование mask может
быть проблематичным, с

815
00:52:58,490 --> 00:53:01,160
ним очень легко ошибиться
и получить программу,

816
00:53:01,161 --> 00:53:05,500
которая становится unresponsive к
каким-либо исключениям и сообщениям.

817
00:53:05,501 --> 00:53:06,501
Лучше взять bracket.

818
00:53:08,330 --> 00:53:09,330
Вторая мораль.

819
00:53:09,420 --> 00:53:13,443
То, что каким-либо образом
пытаться восстановить состояние

820
00:53:13,455 --> 00:53:17,560
нашей программы от асинхронных
исключений, это плохая идея.

821
00:53:17,640 --> 00:53:21,700
Потому что мы помним в голове, что
асинхронное исключение может прилететь всегда.

822
00:53:22,280 --> 00:53:24,476
То есть очень тяжело в
каждом моменте нашей

823
00:53:24,488 --> 00:53:27,260
программы, на каждой строчке
нашего кода думать о том,

824
00:53:27,261 --> 00:53:30,680
а как же мне восстановить мое
состояние от асинхронного исключения.

825
00:53:31,560 --> 00:53:34,048
Всегда делаю так. Если
нам прилетает асинхронное

826
00:53:34,060 --> 00:53:36,820
исключение, мы просто чистим
ресурсы и выходим нафиг.

827
00:53:38,820 --> 00:53:41,220
И ничего больше не
делаем в нашем потоке,

828
00:53:41,232 --> 00:53:43,880
пусть это асинхронное
исключение его убивает.

829
00:53:44,420 --> 00:53:46,300
С этим становится жить
намного и намного проще.

830
00:53:46,940 --> 00:53:48,840
И последнее, о чем мы
уже проговаривали с вами.

831
00:53:49,200 --> 00:53:51,470
То, что асинхронные и
синхронные исключения в

832
00:53:51,482 --> 00:53:54,120
трехчетверении runtime
системы Haskell не различимы.

833
00:53:54,121 --> 00:54:01,240
Если же мы хотим, чтобы они были
различимы в терминах хотя бы типов данных.

834
00:54:01,440 --> 00:54:07,040
Вот, например, помните, у нас был UserInterrupt,
который завернут в AsyncException.

835
00:54:07,930 --> 00:54:11,500
Где же он был? Где-то он был.

836
00:54:12,810 --> 00:54:16,828
Вот этот DataTypeAsyncException
определен не в

837
00:54:16,840 --> 00:54:21,220
стандартной библиотеке,
а в пакете SafeExceptions,

838
00:54:21,870 --> 00:54:24,158
который не дает ничего
принципиально нового, а

839
00:54:24,170 --> 00:54:26,520
просто нужным образом
классифицирует эксепшены,

840
00:54:27,360 --> 00:54:30,920
часто встречаемые для того,
чтобы было удобнее их ловить.

841
00:54:32,420 --> 00:54:35,520
Вот такая общая басня
работы с эксепшенами в Haskell.

842
00:54:36,090 --> 00:54:38,887
На первый взгляд
кажется, что эксепшены в

843
00:54:38,899 --> 00:54:42,120
Haskell это что-то очень
непонятное и странное,

844
00:54:42,280 --> 00:54:44,540
но на практике это довольно удобно.

845
00:54:45,950 --> 00:54:49,220
Также можно почитать какой-то
блог-пост, насколько я помню.

846
00:54:50,240 --> 00:54:53,540
Да, это пост на fpcomplete про
исключения, довольно хороший.

847
00:54:55,150 --> 00:54:56,320
В свое время его читал.

848
00:54:57,670 --> 00:55:00,200
Есть ли у вас какие-то
вопросы по исключениям?

849
00:55:08,350 --> 00:55:10,488
А мы вообще вот
именно mask, который без

850
00:55:10,500 --> 00:55:13,080
underscore мы будем
где-то в курсе использовать?

851
00:55:13,440 --> 00:55:16,200
Или это слишком опасная вещь для нас?

852
00:55:17,140 --> 00:55:19,980
Я бы сказал, что не будете использовать.

853
00:55:19,981 --> 00:55:24,000
Даже mask, который с нижним
подчеркиванием, вам вряд ли пригодится.

854
00:55:26,560 --> 00:55:30,200
Поэтому в какой-нибудь домашке
у вас будет работа с файлами,

855
00:55:30,460 --> 00:55:34,620
или, допустим, на практике у вас
были таски для работы с файлами,

856
00:55:34,980 --> 00:55:39,240
там можно использовать bracket
условный, и это вполне себе ок.

857
00:55:41,670 --> 00:55:45,008
Таски на многопоточность,
я надеюсь, у вас будут

858
00:55:45,020 --> 00:55:48,160
в этом году в домашках,
но там mask не нужен.

859
00:55:56,160 --> 00:55:57,640
Окей, давайте продолжать.

860
00:55:59,020 --> 00:56:01,620
Продолжим со слайда, который
имеет довольно интригующее название.

861
00:56:02,480 --> 00:56:04,180
Никогда не используйте форкуео.

862
00:56:04,640 --> 00:56:08,880
И сейчас мы разберем, почему форкуео –
это достаточно низкоуровневый примитив,

863
00:56:10,210 --> 00:56:12,941
и почему, используя
форкуео, можно довольно легко

864
00:56:12,953 --> 00:56:15,640
выстрелить себе в ногу с
помощью такого примера.

865
00:56:16,400 --> 00:56:18,600
Давайте заведем функцию,
которая называется async.

866
00:56:19,170 --> 00:56:21,813
exec, которая будет
принимать еошное действие и

867
00:56:21,825 --> 00:56:24,740
возвращать результат
нашего еошного действия,

868
00:56:24,920 --> 00:56:25,400
обернутый в mvar.

869
00:56:25,830 --> 00:56:28,560
То есть мы принимаем какой-то
action, создаем пустую коробочку,

870
00:56:30,240 --> 00:56:33,200
запускаем наш action и
кладем его результат в mvar.

871
00:56:33,820 --> 00:56:34,440
И возвращаем mvar.

872
00:56:34,660 --> 00:56:38,540
То есть это на самом
деле обертка над boilerplate,

873
00:56:38,580 --> 00:56:39,580
который раньше у нас был,
если мы запускали поток.

874
00:56:39,740 --> 00:56:42,780
Помните, у нас была функция,
когда мы разбирали mvar,

875
00:56:43,860 --> 00:56:47,320
мы там для каждого из
потока писали такой boilerplate.

876
00:56:47,720 --> 00:56:49,961
Сейчас мы его просто
абстрагировали в отдельную функцию.

877
00:56:51,020 --> 00:56:54,240
И таким образом сделали
удобный примитив для того,

878
00:56:54,360 --> 00:56:56,487
чтобы исполнять наше
действие асинхронно в

879
00:56:56,499 --> 00:56:58,740
отдельном потоке и
возвращать его результат.

880
00:56:59,040 --> 00:57:01,760
Потому что форкуео так делать не
умеет, для этого нужно делать mvar,

881
00:57:02,355 --> 00:57:03,556
что мы, собственно, и сделали.

882
00:57:05,640 --> 00:57:08,120
И запускаем параллельно два действия.

883
00:57:08,400 --> 00:57:10,618
Первый из них кладет в
первый mvar результат,

884
00:57:10,630 --> 00:57:12,860
второй из них кладет в
второй mvar результат.

885
00:57:13,980 --> 00:57:19,040
Затем удобно с помощью
аппликативов достаем результат в пары.

886
00:57:19,280 --> 00:57:25,200
То есть мы могли, как раньше,
res1 достать с помощью takemvar,

887
00:57:25,260 --> 00:57:27,656
res2 достать с помощью takemvar,
все это переместить в пару.

888
00:57:27,680 --> 00:57:32,440
Но зачем, если это можно сделать с помощью
конструктора пары, поднятого в аппликативы.

889
00:57:33,860 --> 00:57:34,860
Довольно удобно.

890
00:57:35,780 --> 00:57:41,860
Таким образом у нас
получается пара из результатов

891
00:57:41,861 --> 00:57:43,460
двух наших действий,
которые выполнены асинхронно.

892
00:57:43,480 --> 00:57:45,900
И мы выводим в консоль эти результаты.

893
00:57:48,810 --> 00:57:51,360
Что же может пойти не так, по-вашему,

894
00:57:52,100 --> 00:57:58,160
зная о том, что после того, как мы с вами
порядка 20 минут говорили об исключениях?

895
00:58:02,010 --> 00:58:03,970
Логично, бросится какое-то исключение.

896
00:58:06,190 --> 00:58:11,030
Конкретно в данном случае
никакое исключение не бросится,

897
00:58:11,130 --> 00:58:16,770
потому что наши действия, которые
мы исполняем в потоках, довольно тупые.

898
00:58:17,070 --> 00:58:19,230
То есть мы просто ждем и
возвращаем какое-то значение.

899
00:58:20,090 --> 00:58:22,870
А вот что, если действия у
нас будут какие-то умнее?

900
00:58:23,050 --> 00:58:25,710
Например, действия будут
более интеллектуальные,

901
00:58:26,190 --> 00:58:29,466
с какой-то более сложной логикой, которая
чисто в теории может бросить exception.

902
00:58:29,490 --> 00:58:30,490
Будем делить на 0.

903
00:58:31,020 --> 00:58:35,190
Да, если в начальном потоке что-то бросим,

904
00:58:35,450 --> 00:58:37,630
то основное, похоже, никогда не дождется.

905
00:58:38,610 --> 00:58:40,630
Да, все верно.

906
00:58:40,790 --> 00:58:42,990
Потому что представьте,
что во время нашего экшена,

907
00:58:43,310 --> 00:58:47,390
допустим, мы бросим
myException во втором потоке.

908
00:58:47,950 --> 00:58:50,010
Таким образом, мы в
нашей функции asyncExec,

909
00:58:50,170 --> 00:58:51,510
когда запустим действие forClose,

910
00:58:52,190 --> 00:58:56,030
наш поток, в котором исполняется
вот это действие, просто умрет,

911
00:58:56,680 --> 00:59:01,330
и мы никогда не дождемся
того, что putMvar отработает.

912
00:59:02,070 --> 00:59:04,210
Таким образом, мы вернем пустой mvar.

913
00:59:04,750 --> 00:59:08,670
То есть функция asyncExec вернет
пустой mvar для второго действия.

914
00:59:09,110 --> 00:59:10,750
Соответственно, данный mvar будет пустой,

915
00:59:11,350 --> 00:59:12,970
и мы бесконечно заблочимся.

916
00:59:13,970 --> 00:59:15,590
Собственно, это мы и увидим.

917
00:59:16,630 --> 00:59:20,610
И, конечно же, абсолютно не
хочется, чтобы такое происходило.

918
00:59:20,760 --> 00:59:25,290
Потому что мы хотим как
можно меньше париться

919
00:59:25,465 --> 00:59:29,290
о синхронизации потоков
при наличии исключений,

920
00:59:29,910 --> 00:59:31,250
о потенциальных дедлоков,

921
00:59:31,430 --> 00:59:34,710
и хотим иметь какие-то более
высокоуровневые примитивы

922
00:59:35,210 --> 00:59:38,610
для удобной работы с
многопоточностью и эксепшенами.

923
00:59:39,430 --> 00:59:42,910
Для этого у нас существует
библиотека, которая называется async,

924
00:59:44,270 --> 00:59:47,950
в которой уже есть функция,
которая называется concurrently.

925
00:59:48,340 --> 00:59:49,821
Сейчас мы ее разберем более подробно.

926
00:59:50,310 --> 00:59:52,450
Concurrently принимает два иошных действия,

927
00:59:52,590 --> 00:59:55,150
исполняет их параллельно
и кладет результат в пару.

928
00:59:56,150 --> 00:59:59,410
И в библиотеке async
все спроектировано так,

929
00:59:59,530 --> 01:00:03,970
что если вылетает какой-то эксепшен
в одном из наших дочерних потоков,

930
01:00:04,350 --> 01:00:06,610
он перепробрацивается в наш main поток.

931
01:00:06,930 --> 01:00:07,930
Что довольно логично.

932
01:00:07,990 --> 01:00:10,510
Потому что мы, если
запамнили какой-то поток,

933
01:00:10,950 --> 01:00:14,370
мы потенциально хотим знать, что
если что-то в том потоке пошло не так.

934
01:00:14,420 --> 01:00:16,790
Потому что если мы используем farqua,

935
01:00:17,290 --> 01:00:19,930
нас абсолютно никто не предупредил о том,

936
01:00:20,030 --> 01:00:23,510
что наш дочерний поток умер и
наш mvar всегда будет пустым.

937
01:00:24,270 --> 01:00:26,530
В случае библиотеки async это не так.

938
01:00:27,530 --> 01:00:32,890
Таким образом, здесь вместо
trend blocked indefinitely in mvar

939
01:00:33,240 --> 01:00:37,250
мы получим myException, который
был кинут в дочернем потоке.

940
01:00:37,710 --> 01:00:41,770
Здесь мы могли его каким-либо
образом поймать и обработать.

941
01:00:43,210 --> 01:00:45,810
Если у нас какое-то второе
вычисление недосчиталось,

942
01:00:45,930 --> 01:00:49,050
положить на худой конец nothing и
продолжить исполнение программы.

943
01:00:50,020 --> 01:00:57,210
Это один из пойнтов, где farqua
довольно опасен для использования.

944
01:00:57,770 --> 01:01:01,150
Мы его разобрали сугубо
в ознакомительной цели,

945
01:01:01,630 --> 01:01:06,610
чтобы понимать, какой самый низкоуровневый
примитив в Haskell для спавна потоков.

946
01:01:06,910 --> 01:01:08,630
Но в реальной жизни им никто не пользуется.

947
01:01:08,730 --> 01:01:10,390
Давайте уже разберем библиотеку async.

948
01:01:11,790 --> 01:01:19,290
В принципе, в простых кейсах
использование библиотеки async

949
01:01:20,040 --> 01:01:22,470
можно ограничиться
буквально двумя функциями.

950
01:01:22,570 --> 01:01:25,210
Это функции concurrently и функции race.

951
01:01:26,330 --> 01:01:30,570
По их названиям и сигнатурам довольно
интуитивно понятно, что они делают.

952
01:01:31,110 --> 01:01:33,410
Функция concurrently
берет два иошных действия

953
01:01:34,160 --> 01:01:38,070
и запускает их параллельно,
возвращая результат в пару.

954
01:01:38,870 --> 01:01:44,110
Функция race берет два иошных
действия и возвращает изр из ab.

955
01:01:44,390 --> 01:01:47,390
То есть она возвращает результат того
действия, которое завершилось первым.

956
01:01:47,850 --> 01:01:50,950
Что также бывает довольно удобно.

957
01:01:51,250 --> 01:01:54,510
И с помощью farqua нам придется
градить целый огород, чтобы это сделать.

958
01:01:54,650 --> 01:01:59,130
А уж тем более, чтобы это все работало
при наличии асинхронных заключений.

959
01:02:00,200 --> 01:02:03,330
Вообще, библиотека
async, помимо этого всего,

960
01:02:05,470 --> 01:02:10,210
в отличие от farqua, вот эти функции
спроектированы таким образом,

961
01:02:10,530 --> 01:02:13,330
что наше ио-действие умеет
возвращать какой-то результат.

962
01:02:13,930 --> 01:02:16,890
Что уже довольно большой прорыв,
потому что функция farqua, как мы помним,

963
01:02:17,210 --> 01:02:21,030
принимает иошное действие,
которое не возвращает результата.

964
01:02:21,570 --> 01:02:23,379
И нам приходилось
ручками писать boilerplate,

965
01:02:23,391 --> 01:02:25,050
которое создает embar
и кладет результат.

966
01:02:26,190 --> 01:02:27,790
Библиотека async делает это за нас.

967
01:02:28,040 --> 01:02:34,190
Также библиотека async человеческим
образом поступает с exception,

968
01:02:34,545 --> 01:02:39,170
интуитивно понятна программисту, в
отличие от нативного использования farqua.

969
01:02:39,900 --> 01:02:43,350
И также в библиотеке async есть
множество примитивов полезных,

970
01:02:43,590 --> 01:02:47,369
которые мы сейчас коротко
коснемся, для более тонких

971
01:02:47,381 --> 01:02:51,610
моментов обработки состояния
наших асинхронных вычислений.

972
01:02:51,970 --> 01:02:54,410
Но пока что остановимся
на функции concurrently erase.

973
01:02:55,730 --> 01:02:59,070
Давайте создадим функцию worker,
которая принимает какой-то int,

974
01:02:59,570 --> 01:03:03,850
будет ждать какое-то
время, зависящее от нашего

975
01:03:03,930 --> 01:03:05,390
int прямо пропорционально,
и возвращать n квадрат.

976
01:03:07,650 --> 01:03:11,710
И с помощью функции concurrently
можно запустить два worker параллельно.

977
01:03:12,670 --> 01:03:15,730
Или же с помощью функции erase можно
запустить также два worker параллельно.

978
01:03:15,830 --> 01:03:18,249
И тут очевидно, что
вернется всегда left, потому

979
01:03:18,261 --> 01:03:20,590
что левый по логике нашей
функции ждет меньше.

980
01:03:21,640 --> 01:03:24,725
Также, помимо функции
concurrently erase, на самом деле

981
01:03:24,737 --> 01:03:27,890
функция concurrently erase
является некоторым баггерсом,

982
01:03:27,970 --> 01:03:30,510
для того чтобы реализовать
некоторые более сложные функции.

983
01:03:31,110 --> 01:03:35,990
То есть с помощью функции concurrently
можно реализовать функцию map concurrently,

984
01:03:37,010 --> 01:03:41,782
которая принимает
список каких-то действий и

985
01:03:41,794 --> 01:03:46,470
запускает каждый из
них в отдельном потоке.

986
01:03:47,070 --> 01:03:51,230
Здесь мы понимаем и вспоминаем, что
мы используем хаскельные грин трейды,

987
01:03:51,890 --> 01:03:54,693
которые можно также
вкладить сотнями или даже

988
01:03:54,705 --> 01:03:57,770
тысячами, и наш программ
не будет от этого плохо.

989
01:03:58,135 --> 01:04:02,450
То есть сотни трейдов
– это вполне себе окей.

990
01:04:03,155 --> 01:04:04,970
Конечно же, с этим лучше не борщить.

991
01:04:05,350 --> 01:04:07,630
Если на каждый чик
создавать отдельный поток,

992
01:04:08,090 --> 01:04:10,450
перформанс нашей программы
очень и очень сильно просядет.

993
01:04:10,451 --> 01:04:14,079
Но обработать
какой-нибудь список из сотен

994
01:04:14,091 --> 01:04:18,510
элементов в параллель
ничего нам не мешает сделать.

995
01:04:18,910 --> 01:04:20,750
Для этого существует
функция map concurrently.

996
01:04:23,370 --> 01:04:31,290
Но для того, чтобы моделировать
какие-то кастомные условия,

997
01:04:33,810 --> 01:04:40,304
многопоточные вычисления,
мы хотим запустить

998
01:04:40,316 --> 01:04:47,971
три потока и вернуть пару к первым
элементам, которые являются изр.

999
01:04:49,550 --> 01:04:54,530
Мы хотим, чтобы первым элементом этой
пары был либо первый, либо второй поток.

1000
01:04:55,270 --> 01:04:56,350
Кто из них первый завершит.

1001
01:04:56,610 --> 01:04:59,370
И также третий поток, который
будет работать с ними параллельно.

1002
01:04:59,371 --> 01:05:01,419
Короче, какие-то более
нетривиальные кейсы, которые

1003
01:05:01,431 --> 01:05:03,411
выражаются, конечно же,
через concurrently erase.

1004
01:05:04,110 --> 01:05:06,910
Но мы хотим иметь для этого
более гибкое возможность.

1005
01:05:07,730 --> 01:05:10,710
Или мы хотим запустить
четыре потока, первый со вторым,

1006
01:05:10,850 --> 01:05:12,490
или первый с третьим, второй с четвертым.

1007
01:05:12,790 --> 01:05:13,910
И все это дело параллельно.

1008
01:05:15,165 --> 01:05:17,490
Нам помогает new type,
который называется concurrently.

1009
01:05:18,670 --> 01:05:21,550
Concurrently – это просто
обертка над иошным действием,

1010
01:05:22,350 --> 01:05:27,250
который может быть скомпозирован с
другими экземплярами типа concurrently,

1011
01:05:27,650 --> 01:05:30,870
с использованием инстансов этой
класса, аппликатив и альтернатив.

1012
01:05:31,870 --> 01:05:37,710
И на самом деле инстанс аппликатива –
это то же самое, что функция concurrently.

1013
01:05:37,990 --> 01:05:40,790
То есть она берет и оборачивает.

1014
01:05:41,650 --> 01:05:44,764
То есть мы с помощью
инстанса аппликатива можем

1015
01:05:44,776 --> 01:05:47,570
взять и скомбинировать
два наших действия,

1016
01:05:47,730 --> 01:05:49,090
чтобы они выполнялись параллельно.

1017
01:05:49,210 --> 01:05:51,310
То есть функцию
concurrently можно легко

1018
01:05:51,322 --> 01:05:53,750
реализовать с помощью
аппликативного инстанса.

1019
01:05:53,900 --> 01:05:57,830
Это просто мы берем конструктор пары,
применяем к нашему первому действию,

1020
01:05:58,310 --> 01:06:00,253
применяем к нашему
второму действию и вызываем

1021
01:06:00,265 --> 01:06:02,050
run concurrently, как
просто разворачивая.

1022
01:06:02,630 --> 01:06:06,990
То есть я сначала говорил, что new
type concurrently – это более общая вещь,

1023
01:06:07,105 --> 01:06:10,870
с помощью которой можно выразить
concurrently erase более удобным образом.

1024
01:06:11,705 --> 01:06:15,390
Функцию erase также легко
выразить через new type concurrently.

1025
01:06:15,470 --> 01:06:15,950
Что мы делаем?

1026
01:06:16,450 --> 01:06:20,630
Мы берем наше первое действие,
запаковываем его в конструктор left

1027
01:06:22,010 --> 01:06:26,070
и через альтернативу
комбинируем с вторым действием,

1028
01:06:26,130 --> 01:06:29,870
которое заворачивается в конструктор
right и выполняется там worker 2000.

1029
01:06:30,490 --> 01:06:33,850
И в конечном итоге мы распаковываем
все это дело с помощью run concurrently,

1030
01:06:34,310 --> 01:06:37,210
и у нас получается ровно то
же самое, что функция erase.

1031
01:06:38,010 --> 01:06:41,263
Но это что-то более гибкое,
потому что можно легко

1032
01:06:41,275 --> 01:06:44,670
сделать это для тюкла из
трех или четырех элементов.

1033
01:06:44,671 --> 01:06:47,250
Или для нашего какого-то
кастомного дата-тайпа,

1034
01:06:49,070 --> 01:06:52,290
каждое поле которого
вычисляется в отдельном потоке.

1035
01:06:52,450 --> 01:06:56,110
То есть мы можем более-менее произвольным
образом, с помощью двух данных инстанцев,

1036
01:06:59,030 --> 01:07:00,550
композировать параллельное вычисление.

1037
01:07:02,680 --> 01:07:04,321
Есть ли какие-то вопросы по этому поводу?

1038
01:07:15,075 --> 01:07:19,640
Окей, я надеюсь, что отсутствие вопросов,
потому что все более-менее понятно,

1039
01:07:19,840 --> 01:07:21,500
а не потому что ни черта не понятно.

1040
01:07:21,780 --> 01:07:27,040
Это один момент.
То есть мы тут можем только…

1041
01:07:27,041 --> 01:07:30,420
То есть это как бы обертка
над concurrently erase, да?

1042
01:07:31,040 --> 01:07:36,680
Скорее наоборот.
Скорее newtype concurrently позволяет…

1043
01:07:36,681 --> 01:07:39,980
Смотрите, функции
concurrently erase – это

1044
01:07:39,992 --> 01:07:43,540
частные случаи работы
с newtype concurrently.

1045
01:07:43,580 --> 01:07:46,780
Почему? Потому что вот мы
на примере явно показали то,

1046
01:07:47,280 --> 01:07:51,940
как с помощью newtype concurrently и
конструктора пары или же конструкторов изеров

1047
01:07:52,190 --> 01:07:53,520
смоделировать данные функции.

1048
01:07:54,140 --> 01:07:56,840
Но newtype concurrently
– это что-то более общее.

1049
01:07:57,000 --> 01:08:05,220
Представьте, что у нас есть API для
того, чтобы, имея два действия иошных,

1050
01:08:05,760 --> 01:08:10,040
либо запускать их параллельно и ждать оба,

1051
01:08:10,340 --> 01:08:12,160
либо запускать параллельно
и ждать один из них.

1052
01:08:12,161 --> 01:08:15,660
И с помощью этого мы можем
более-менее произвольную цепочку,

1053
01:08:15,780 --> 01:08:20,180
произвольное дерево наших
concurrent вычислений смоделировать.

1054
01:08:20,580 --> 01:08:23,116
Мы можем это сделать также с
помощью функции concurrently erase.

1055
01:08:23,140 --> 01:08:23,700
Никто не спорит.

1056
01:08:24,100 --> 01:08:27,740
Но в данном случае это будет
просто какой-то огород из пар и изеров,

1057
01:08:28,040 --> 01:08:29,040
обернутых друг в друга.

1058
01:08:29,500 --> 01:08:32,640
В случае же newtype concurrently мы
можем использовать абсолютно что угодно.

1059
01:08:32,740 --> 01:08:34,580
Вот здесь мы используем конструктор пары.

1060
01:08:34,680 --> 01:08:37,040
А представьте, что у
нас есть какой-то юзер,

1061
01:08:37,640 --> 01:08:39,160
что у нас есть какой-то datatype юзер,

1062
01:08:39,285 --> 01:08:42,000
каждый из полей которого мы
вычисляем в отдельном потоке.

1063
01:08:42,040 --> 01:08:44,065
В данном случае мы могли
бы вместо конструктора

1064
01:08:44,077 --> 01:08:45,680
пары применить сюда
конструктор юзера

1065
01:08:46,030 --> 01:08:47,460
и запустить не два потока, а три.

1066
01:08:48,060 --> 01:08:50,021
В случае с concurrently
нам бы пришлось страдать,

1067
01:08:50,300 --> 01:08:53,420
у нас бы появилась вложенная пара из пар,

1068
01:08:54,060 --> 01:08:57,040
потому что первый элемент у
нас один, а тут у нас два элемента,

1069
01:08:57,120 --> 01:08:59,321
потому что мы запускаем
конкурентли внутри конкурентли.

1070
01:08:59,640 --> 01:09:02,459
Короче говоря, это
более гибкий примитив для

1071
01:09:02,471 --> 01:09:05,880
конструирования произвольных
параллельных вычислений,

1072
01:09:06,840 --> 01:09:09,880
которые могут результировать в
абсолютно произвольный дататайп,

1073
01:09:10,680 --> 01:09:12,320
какой вашей душе угодно.

1074
01:09:12,700 --> 01:09:14,460
Просто у нас есть два оператора.

1075
01:09:14,920 --> 01:09:18,640
Вот такой вот для того, чтобы
запустить параллельно и ждать оба,

1076
01:09:19,000 --> 01:09:21,961
и вот такой вот для того, чтобы
запустить параллельно и ждать один из них.

1077
01:09:22,100 --> 01:09:24,680
Что после этого делать?
Что вашей душе угодно.

1078
01:09:24,940 --> 01:09:29,760
Можете собрать любое абсолютно
дерево, конкурент вычислений.

1079
01:09:31,640 --> 01:09:34,940
Получается, если бы мы там,
допустим, конструктор листа применили,

1080
01:09:35,060 --> 01:09:37,880
то мы могли бы там бесконечное
количество элементов считать.

1081
01:09:39,820 --> 01:09:41,980
Ну, оно бы у вас никогда не досчиталось,

1082
01:09:42,440 --> 01:09:45,880
если вы имеете в виду бесконечный
список взять и запустить параллельно.

1083
01:09:47,480 --> 01:09:49,540
Наверное, вы имели в виду
произвольное количество.

1084
01:09:50,860 --> 01:09:53,544
Да, действительно, мы
можем запустить какое-то

1085
01:09:53,556 --> 01:09:58,040
произвольное количество вычислений здесь
и обернуть это все в конструктор списка.

1086
01:09:58,760 --> 01:10:01,360
Почему нет? Таким образом
реализовав как раз-таки map concurrently.

1087
01:10:02,210 --> 01:10:03,380
Все, понял, спасибо.

1088
01:10:10,320 --> 01:10:11,660
Ну, видимо, пойдем дальше.

1089
01:10:12,100 --> 01:10:19,220
И теперь разберем более детально то,
что предоставляет нам библиотека Async.

1090
01:10:19,500 --> 01:10:22,520
То есть первое, что мы разобрали,
это функции concurrently erase,

1091
01:10:22,860 --> 01:10:24,400
как самый-самый базовый API.

1092
01:10:24,840 --> 01:10:27,160
В самых базовых случаях его может хватать.

1093
01:10:27,910 --> 01:10:30,727
В случае, если нам нужно
конструировать более

1094
01:10:30,739 --> 01:10:33,820
сложные деревья из наших
параллельных вычислений,

1095
01:10:33,940 --> 01:10:35,380
мы используем new type concurrently.

1096
01:10:36,020 --> 01:10:40,338
Сейчас мы будем говорить
про то, если нам нужно очень

1097
01:10:40,350 --> 01:10:45,660
внимательно следить за
состоянием нашего асинхронного

1098
01:10:45,740 --> 01:10:47,340
вычисления, которое мы
запустили в отдельном потоке.

1099
01:10:47,540 --> 01:10:52,780
Для этого существует функция visasync,
которая принимает наше иошное действие,

1100
01:10:54,040 --> 01:10:59,480
вторым аргументом принимает
функцию из так называемого async.

1101
01:11:00,440 --> 01:11:02,643
a, которая представляет
собой вот это действие,

1102
01:11:02,655 --> 01:11:04,820
которое запущено
асинхронно в новом потоке,

1103
01:11:04,980 --> 01:11:07,400
и его результатом является тип.a.

1104
01:11:07,980 --> 01:11:10,500
То есть это какое-то
действие, которое мы запустили.

1105
01:11:10,880 --> 01:11:13,180
Непонятно, оно еще завершилось,
оно еще не завершилось.

1106
01:11:14,200 --> 01:11:18,920
Но прикол функции visasync в том,
что мы в каждый момент времени

1107
01:11:19,370 --> 01:11:22,920
с помощью функции wait, cancel,
pull, которую мы сейчас разберем,

1108
01:11:23,200 --> 01:11:27,000
можем проследить за состоянием
вычисления, которое мы запустили.

1109
01:11:27,900 --> 01:11:32,940
С помощью той же функции for.co и асинхронных
исключений это можно было бы сделать,

1110
01:11:33,020 --> 01:11:35,198
просто запустив в
отдельный поток и пытаться до

1111
01:11:35,210 --> 01:11:37,540
него достучаться с помощью
асинхронных исключений.

1112
01:11:38,100 --> 01:11:42,620
Спросить, как ты там вообще выполняешься,
собираешься ли ты завершаться или нет.

1113
01:11:42,920 --> 01:11:46,320
В библиотеке async, конкретно
с помощью функции visasync,

1114
01:11:47,100 --> 01:11:49,948
у нас реализован удобный
API для контроля за

1115
01:11:49,960 --> 01:11:53,080
асинхронными вычислениями,
которые мы запустили.

1116
01:11:54,020 --> 01:11:56,826
Еще раз, наше
вычисление, наше действие,

1117
01:11:56,838 --> 01:12:00,220
которое мы запустили
асинхронно в другом потоке,

1118
01:12:00,660 --> 01:12:02,680
представляется дататайпом async.a.

1119
01:12:03,140 --> 01:12:06,421
Это просто какое-то действие, которое
запущено в отдельном потоке в данный момент,

1120
01:12:07,200 --> 01:12:08,940
которое вернет результат.

1121
01:12:10,230 --> 01:12:13,031
Как мы используем функцию visasync?
Давайте сразу разберем на примере.

1122
01:12:13,520 --> 01:12:17,920
Мы используем функцию visasync и
скамливаем туда какое-то действие getUrl.

1123
01:12:19,340 --> 01:12:25,260
Таким образом, наш get запрос по
данному URL будет исполняться параллельно.

1124
01:12:26,380 --> 01:12:29,720
И вот в этой функции, которая
передается вторым аргументом,

1125
01:12:30,900 --> 01:12:36,680
мы можем оперировать вот этим
дескриптором нашего вычисления,

1126
01:12:36,780 --> 01:12:38,061
которое выполняется параллельно.

1127
01:12:38,460 --> 01:12:40,960
Мы можем его подождать
с помощью функции wait.

1128
01:12:41,540 --> 01:12:46,620
Мы можем его отменить с
помощью функции cancel.

1129
01:12:47,200 --> 01:12:52,620
Мы можем сделать call, то есть
спросить его, правда ли ты завершился.

1130
01:12:53,090 --> 01:12:55,900
Если завершился, то ты завершился
с исключением или с результатом.

1131
01:12:56,400 --> 01:12:58,480
То есть если оно не
завершилось, оно вернет nothing.

1132
01:12:58,740 --> 01:13:01,800
Если оно завершилось с исключением,
оно вернет just, left some exception.

1133
01:13:02,350 --> 01:13:06,840
Если оно завершилось с результатом,
оно вернет just, right результат.

1134
01:13:08,040 --> 01:13:12,680
Таким образом, у нас можно
писать более сложные программы,

1135
01:13:14,900 --> 01:13:19,720
которые оперируют действиями,
исполняющимися в разных потоках.

1136
01:13:19,820 --> 01:13:24,860
Допустим, мы хотим, чтобы наше
действие не выполнялось слишком долго.

1137
01:13:25,200 --> 01:13:28,360
Мы можем тут подождать
сколько-то там и сделать cancel.

1138
01:13:29,080 --> 01:13:31,801
Ровно так же, как мы делали с
помощью функции call, но более удобно.

1139
01:13:32,280 --> 01:13:33,400
Итого, разбираем наш пример.

1140
01:13:34,460 --> 01:13:35,600
У нас есть два урла.

1141
01:13:36,080 --> 01:13:41,400
Мы хотим параллельно из них
отправить get-запрос по этому урлу

1142
01:13:41,950 --> 01:13:43,631
и получить два byte-стринга как результат.

1143
01:13:44,040 --> 01:13:45,481
Для этого у нас есть функция getUrl.

1144
01:13:46,400 --> 01:13:48,380
Мы используем функцию visasync.

1145
01:13:49,840 --> 01:13:51,540
Запускаем первое вычисление параллельно.

1146
01:13:51,640 --> 01:13:55,500
Получаем descriptor
первого нашего вычисления,

1147
01:13:55,501 --> 01:13:57,461
которое запускается
параллельно, в переменную a1.

1148
01:13:58,040 --> 01:14:02,460
Затем сразу же мы запускаем второе
вычисление в отдельном потоке, асинхронно,

1149
01:14:02,750 --> 01:14:03,880
и получаем его descriptor.

1150
01:14:04,440 --> 01:14:07,240
И вот, имея эти descriptors, мы
можем с ними делать что угодно.

1151
01:14:07,460 --> 01:14:12,660
Но в данном примитивном случае мы просто
берем и ждем оба из них и возвращаем пару.

1152
01:14:13,000 --> 01:14:16,160
То есть на самом деле данная
функция не несет ничего нового,

1153
01:14:17,780 --> 01:14:20,600
ничего не делает умнее, чем конкартный.

1154
01:14:21,200 --> 01:14:26,360
Но сам факт того, что мы, имея
данные вот эти штучки типа async,

1155
01:14:26,920 --> 01:14:29,100
могли бы делать с ними
вещи произвольной сложности.

1156
01:14:29,670 --> 01:14:32,020
В отличие от функции
concurrentlyErase, где мы запустили,

1157
01:14:32,680 --> 01:14:34,180
и бог весть, когда оно досчитается.

1158
01:14:34,700 --> 01:14:37,920
То есть функции
concurrentlyErase, как и datatype.

1159
01:14:38,840 --> 01:14:41,360
concurrently, они про то, когда мы
что-то запускаем в отдельный поток,

1160
01:14:41,640 --> 01:14:43,280
и не хотим особо это контролировать.

1161
01:14:43,420 --> 01:14:45,980
То есть когда-то оно
досчитается, и нам это вернется.

1162
01:14:47,800 --> 01:14:51,720
Функции же visasync
позволяют нам контролировать

1163
01:14:51,810 --> 01:14:53,171
то, что происходит
в отдельном потоке.

1164
01:14:54,800 --> 01:14:56,520
Есть ли по этому поводу какие-то вопросы?

1165
01:15:10,920 --> 01:15:12,780
Окей, давайте тогда продолжать.

1166
01:15:14,120 --> 01:15:17,065
И разберем баянистый
пример, который, мне кажется,

1167
01:15:17,077 --> 01:15:19,620
каждый из вас видел
большое количество раз.

1168
01:15:20,660 --> 01:15:22,580
Представим, что у нас есть...

1169
01:15:23,100 --> 01:15:24,380
Можно? Можно? Один вопрос.

1170
01:15:24,780 --> 01:15:27,440
У нас перерыв будет?

1171
01:15:28,560 --> 01:15:31,440
Давайте сейчас немного окину
глазами, сколько у нас осталось.

1172
01:15:34,000 --> 01:15:35,480
По ощущениям...
Осталось немного.

1173
01:15:35,980 --> 01:15:37,060
Нет, на самом деле немного.

1174
01:15:41,460 --> 01:15:44,320
Короче, нет.
Я думаю, что нам осталось где-то полчаса.

1175
01:15:45,610 --> 01:15:47,700
Потому что самый сложный
материал мы уже прошли.

1176
01:15:48,590 --> 01:15:51,220
Я бы эти полчаса провел без
перерыва, и мы бы разошлись.

1177
01:15:52,420 --> 01:15:53,420
Как вам?

1178
01:15:55,580 --> 01:15:57,480
Как вам такой вариант?

1179
01:15:59,430 --> 01:16:01,200
Я больше за то, чтобы не было перерыва.

1180
01:16:03,020 --> 01:16:05,140
Если не будет возражающих,
давайте так и сделаем.

1181
01:16:05,300 --> 01:16:08,040
Потому что, да, несмотря на
то, что у нас слайдов многовато,

1182
01:16:08,685 --> 01:16:10,845
последние 5-6 слайдов мы
вообще не будем использовать.

1183
01:16:12,080 --> 01:16:14,160
Они есть для тех, кто интересуется.

1184
01:16:15,000 --> 01:16:18,860
Нам осталось разобрать
транзакционную память и параллельность.

1185
01:16:19,840 --> 01:16:20,840
И все.

1186
01:16:21,320 --> 01:16:22,560
Если не полтора часа, я за.

1187
01:16:23,320 --> 01:16:24,320
Да, да.

1188
01:16:24,380 --> 01:16:28,580
Ну, давайте понадеемся, что
мы все-таки закончим быстро,

1189
01:16:28,680 --> 01:16:30,880
потому что, опять же, самые
сложные вещи мы уже прошли.

1190
01:16:32,500 --> 01:16:34,905
Давайте разберем в сотый
раз пример, который вы

1191
01:16:34,917 --> 01:16:37,540
видите уже, наверное, в
сотый раз на разных курсах.

1192
01:16:38,240 --> 01:16:40,760
Это перевод денег с одного счета на другой.

1193
01:16:41,660 --> 01:16:44,820
Заведем такой
дататайп-аккаунт, который ERF,

1194
01:16:45,360 --> 01:16:49,720
который представляет собой просто мутабельную
переменную с значением типа Integer.

1195
01:16:50,170 --> 01:16:52,200
ERF, который мы разбирали на лекции про EO.

1196
01:16:52,790 --> 01:16:56,880
И заведем функцию transfer,
которая принимает количество денег,

1197
01:16:57,280 --> 01:17:01,740
account from, account to, и делает
перевод денег со счета на счет.

1198
01:17:04,090 --> 01:17:05,611
Скажите, пожалуйста, почему это плохо?

1199
01:17:06,290 --> 01:17:09,580
Почему плохо так делать в
конкретной данной реализации?

1200
01:17:16,570 --> 01:17:21,580
Нам могут прислать исключение между
снятием денег и записью на другой счет.

1201
01:17:22,820 --> 01:17:23,400
Это валидно.

1202
01:17:23,625 --> 01:17:24,800
Это абсолютно валидно.

1203
01:17:24,920 --> 01:17:29,610
Но данный пример – это
такой, знаете, каноничный

1204
01:17:29,622 --> 01:17:34,520
пример плохого конкуренции
кода в отрыве от языка.

1205
01:17:34,760 --> 01:17:38,520
Если написать такой же
код на Java, будет тоже плохо.

1206
01:17:39,700 --> 01:17:42,460
Это правда, что данный код
страдает от асинхронных исключений,

1207
01:17:42,560 --> 01:17:49,540
но это далеко не его первая
проблема первостепенная.

1208
01:17:50,740 --> 01:17:54,400
Аналогично, только вместо исключения
компьютер выдергивают из розетки.

1209
01:17:56,360 --> 01:17:57,360
Вполне валидно.

1210
01:17:58,670 --> 01:18:02,600
В данном коде много проблем, но та,
на которую я хотел бы сфокусироваться,

1211
01:18:02,720 --> 01:18:09,100
это то, что мы используем нетрассейт примитив
для хранения денег на нашем аккаунте.

1212
01:18:09,440 --> 01:18:12,820
Нашу функцию transfer могут
запустить параллельно из двух потоков,

1213
01:18:13,070 --> 01:18:18,143
и бог везь что, есть несколько
вариантов того, каким образом

1214
01:18:18,155 --> 01:18:23,240
будет исполнена наша функция
transfer в двух разных потоках.

1215
01:18:23,580 --> 01:18:26,760
Я уверен, что кажется
на курсе Java такое было.

1216
01:18:26,860 --> 01:18:28,680
Возможно, у вас уже
было на курсе параллелок.

1217
01:18:29,160 --> 01:18:30,160
Такой вот пример.

1218
01:18:30,260 --> 01:18:32,465
То, что использование
нетрассейт примитивов в

1219
01:18:32,477 --> 01:18:34,940
реализации функции
transfer – это прям суперплохо.

1220
01:18:35,040 --> 01:18:37,600
В принципе, как использование
нетрассейт примитивов.

1221
01:18:37,700 --> 01:18:40,200
А я напоминаю, что EOF – это
просто мутабельная переменная.

1222
01:18:40,525 --> 01:18:43,374
Она не ограждена мьютексом,
нам не дается никакой

1223
01:18:43,386 --> 01:18:46,480
гарантии того, что операции
над ней будут атомарными.

1224
01:18:47,380 --> 01:18:52,640
Да, там на самом деле есть функции atomic,
modify и EOF, но мы и здесь не пользуемся.

1225
01:18:53,110 --> 01:18:55,040
То есть мы читаем и пишем в EOF.

1226
01:18:56,470 --> 01:18:59,514
Таким образом, использование
нетрассейт примитивов

1227
01:18:59,526 --> 01:19:02,520
в Haskell и в любом другом
языке программирования

1228
01:19:02,645 --> 01:19:05,870
при написании многоточных
программ, точнее, программ,

1229
01:19:05,882 --> 01:19:09,180
которые могут исполняться
в нескольких трудах – плохо.

1230
01:19:10,450 --> 01:19:17,060
Давайте уже исправим нашу
реализацию, заменив EOF на embark.

1231
01:19:18,120 --> 01:19:24,060
И для простоты отрефакторим
нашу функцию, заведем функцию debit.

1232
01:19:24,660 --> 01:19:27,420
Одна из них снимает, другая кладет деньги.

1233
01:19:27,740 --> 01:19:31,120
Соответственно, transfer
– это debit from и credit to.

1234
01:19:32,360 --> 01:19:37,900
Видите ли вы здесь проблему
при использовании мьютексов?

1235
01:19:39,420 --> 01:19:42,420
Кажется, та же проблема, что
и говорили до этого с ошибками.

1236
01:19:44,080 --> 01:19:46,360
Да, она абсолютно валидна.

1237
01:19:46,840 --> 01:19:51,940
Помимо этого, на самом деле
оно звучит немного нелогично,

1238
01:19:52,040 --> 01:19:55,289
то, что мы с вами половину
лекции общались об ошибках,

1239
01:19:55,301 --> 01:19:58,140
и теперь они нам
действительно везде мерещатся.

1240
01:19:58,280 --> 01:20:01,434
Но я вам так скажу, что
в данном коде хочется

1241
01:20:01,446 --> 01:20:04,400
фокусироваться именно
на логике программы,

1242
01:20:04,600 --> 01:20:07,400
а не на внезапно возникших исключениях.

1243
01:20:09,920 --> 01:20:14,200
Мы считаем ошибкой, что мы не
проверяем достаточно денег для перевода.

1244
01:20:14,480 --> 01:20:16,020
Не считаем, не считаем.

1245
01:20:16,720 --> 01:20:18,881
Хорошо, может ли возникнуть
данная программа deadlock?

1246
01:20:29,630 --> 01:20:30,940
На самом деле может, смотрите.

1247
01:20:31,080 --> 01:20:33,541
Как будто бы может,
потому что никто не

1248
01:20:33,553 --> 01:20:36,660
гарантирует, что мы с
одним и тем же аккаунтом...

1249
01:20:36,661 --> 01:20:39,680
Ну, то есть промо ту – это
может быть один и тот же аккаунт,

1250
01:20:39,720 --> 01:20:43,240
и тогда они оба возьмут свою
блокировку и не отдаст никто.

1251
01:20:44,220 --> 01:20:45,700
Да, это хороший поинт.

1252
01:20:47,000 --> 01:20:49,903
Помимо этого, есть еще
представьте, если мы параллельно

1253
01:20:49,915 --> 01:20:52,300
исполняем трансфер с
аккаунта А на аккаунт Б,

1254
01:20:52,860 --> 01:20:54,400
и с аккаунта Б на аккаунт А.

1255
01:20:55,040 --> 01:20:56,600
Что у нас может получиться?

1256
01:20:56,960 --> 01:21:01,260
Мы возьмем блокировку на аккаунт
А и на аккаунт Б в разных функциях.

1257
01:21:01,610 --> 01:21:05,109
Получается, вот это наш
первый, который взял блокировку

1258
01:21:05,121 --> 01:21:08,440
на А, он будет ждать, пока
освободится мьютекс на Б.

1259
01:21:08,900 --> 01:21:13,380
А тот поток, который взял мьютекс на Б,
будет ждать, пока освободится мьютекс на А.

1260
01:21:13,880 --> 01:21:16,840
Таким образом, у нас получается
такое перекрестие – deadlock.

1261
01:21:17,195 --> 01:21:18,996
Первый поток ждет
второй, второй ждет первый.

1262
01:21:19,180 --> 01:21:20,320
Они ждут этого бесконечно.

1263
01:21:21,330 --> 01:21:24,643
А разве так? У нас же вроде
что кредит, что дебит держат

1264
01:21:24,655 --> 01:21:27,920
блокировку только на один
аккаунт и сразу ее отпускают.

1265
01:21:28,520 --> 01:21:30,280
У нас нигде не берется две блокировки.

1266
01:21:31,380 --> 01:21:34,720
Смотрите, параллельно берется…

1267
01:21:37,105 --> 01:21:42,540
Здесь, кажется, проблема в
том, что у нас два потока могли…

1268
01:21:42,541 --> 01:21:45,620
Снова транзакция с А на Б и с Б на А.

1269
01:21:46,400 --> 01:21:50,158
В момент, когда мы сделали
takeMVAR, у нас там пусто, и

1270
01:21:50,170 --> 01:21:54,420
следующий takeMVAR, который
из второй транзакции, он зависнет.

1271
01:21:54,940 --> 01:21:57,021
Мне кажется, вот из-за
этого можно deadlock поймать.

1272
01:21:57,240 --> 01:21:58,640
Да, это справедливо.

1273
01:21:58,641 --> 01:22:00,720
Я, на самом деле, sorry, тут моя проблема.

1274
01:22:01,140 --> 01:22:02,500
Я действительно не особо вчитался.

1275
01:22:02,940 --> 01:22:05,861
Вот в такой реализации, если бы у нас
реализация была не отрефакторенная,

1276
01:22:06,260 --> 01:22:09,360
когда мы сначала берем блокировку,
а в самом конце ее отпускаем,

1277
01:22:09,600 --> 01:22:13,220
у нас действительно может быть
проблема в том, что у нас заблокируется.

1278
01:22:13,300 --> 01:22:18,200
В данном случае такой проблемы нет,
но все еще мы можем получить deadlock.

1279
01:22:19,500 --> 01:22:22,400
Как минимум потому, что у нас
дебит и кредит – это то же самое.

1280
01:22:22,720 --> 01:22:25,680
И наш код не работает с учетом этого.

1281
01:22:26,230 --> 01:22:30,975
Короче, хочется иметь
какой-то более удобный

1282
01:22:30,987 --> 01:22:35,960
примитив для работы с
данными в многоточности,

1283
01:22:36,440 --> 01:22:41,180
когда мы не будем париться
даже о взятии и отпускании mutex.

1284
01:22:42,070 --> 01:22:43,220
Такой примитив есть.

1285
01:22:44,480 --> 01:22:48,440
Он называется TEVAR, который
расшифровывается как Transaction Variable.

1286
01:22:50,000 --> 01:22:56,700
И все это дело происходит в такой вещи,
которая представлена FAST, LEMONADE и STM,

1287
01:22:57,560 --> 01:22:59,920
которая расшифровывается
как Software Transactional Memory.

1288
01:23:00,520 --> 01:23:04,180
Software Transactional
Memory – это такая конструкция,

1289
01:23:04,780 --> 01:23:08,000
которая позволяет нам
исполнять некоторые участки кода,

1290
01:23:08,680 --> 01:23:11,640
на самом деле произвольные
участки кода, транзакционно.

1291
01:23:13,880 --> 01:23:17,180
Транзакционно имеется в
виду в первую очередь ATOMAR.

1292
01:23:17,380 --> 01:23:22,260
Транзакция – вы, возможно,
слышали такой термин как база данных.

1293
01:23:23,440 --> 01:23:29,073
То, что оно должно
удовлетворять свойствами ACID,

1294
01:23:29,085 --> 01:23:34,500
ATOMICITY, CONSISTENCY,
ISOLATION и DURABILITY.

1295
01:23:34,620 --> 01:23:38,560
DURABILITY – это про то, что у нас
данные хранятся на жестком диске.

1296
01:23:39,700 --> 01:23:42,520
Нас это конкретно не интересует,
но свойства ATOMAR-ности,

1297
01:23:43,380 --> 01:23:45,720
изоляционности и
консистентности нас интересуют.

1298
01:23:46,830 --> 01:23:49,460
Итого. На самом деле, кстати, спойлер.

1299
01:23:50,200 --> 01:23:52,993
Вы будете конструкцию
Software Transactional Memory

1300
01:23:53,005 --> 01:23:55,480
изучать подробно с
теоретической точки зрения

1301
01:23:55,930 --> 01:23:59,360
на курсе параллельного программирования,
где-то на последних лекциях.

1302
01:23:59,900 --> 01:24:02,261
Поэтому мы сейчас не будем
подробно останавливаться на том,

1303
01:24:02,660 --> 01:24:05,400
как же она реализована.
Это выходит за рамки курса.

1304
01:24:06,100 --> 01:24:08,260
Нас это интересует сугубо с
практической точки зрения.

1305
01:24:08,640 --> 01:24:11,060
Как применять данную
конструкцию в Интерхаске.

1306
01:24:12,010 --> 01:24:13,620
Что нам позволяет делать STM?

1307
01:24:14,120 --> 01:24:21,900
STM нам позволяет брать
произвольный блок кода,

1308
01:24:23,020 --> 01:24:27,720
который находится в монаде STM,
и оборачивать его в функцию Atomic.

1309
01:24:28,600 --> 01:24:29,700
Что это значит?

1310
01:24:29,820 --> 01:24:35,020
Это значит, что наш блок кода будет
исполняться весь, как одна атомарная операция.

1311
01:24:35,520 --> 01:24:38,460
Представьте, что у нас существуют
две транзакции параллельно,

1312
01:24:38,800 --> 01:24:40,660
и вот этот блок кода называется транзакция.

1313
01:24:41,160 --> 01:24:44,300
То есть это какой-то код,
который исполняется атомарно.

1314
01:24:44,740 --> 01:24:45,940
И изолировано друг от друга.

1315
01:24:46,400 --> 01:24:50,600
Представьте, что у нас существует
две транзакции, вызванных параллельно,

1316
01:24:50,660 --> 01:24:52,760
которые работают над
одними и теми же данными.

1317
01:24:52,840 --> 01:24:54,660
Допустим, вот в эти же самые дебиты играть.

1318
01:24:55,440 --> 01:25:00,380
И данные транзакции, если во
время исполнения транзакции

1319
01:25:00,381 --> 01:25:03,780
данные были модифицированы другим
потоком, транзакция умеет rollback.

1320
01:25:04,230 --> 01:25:08,400
То есть она умеет запускаться
заново на уже обновленных данных.

1321
01:25:08,900 --> 01:25:11,900
И таким образом у нас гарантируется
атомарность нашего действия.

1322
01:25:12,740 --> 01:25:15,780
Да, это не гарантируется хороший
перформанс в данном случае,

1323
01:25:15,880 --> 01:25:18,520
потому что наши транзакции, если
мы не оптимально написали код,

1324
01:25:18,680 --> 01:25:22,740
особенно применили STM не там, где нужно,
наши транзакции могут много rollback.

1325
01:25:23,420 --> 01:25:26,740
Но зато нам не нужно
брать никаких блокировок.

1326
01:25:27,380 --> 01:25:31,160
Мы заранее уверены в
том, что весь наш блок кода,

1327
01:25:31,540 --> 01:25:33,101
который мы обернули в функцию Atomical,

1328
01:25:36,470 --> 01:25:37,470
используется параллельно.

1329
01:25:38,630 --> 01:25:39,630
Итого, смотрите.

1330
01:25:41,000 --> 01:25:44,020
Так как у нас все это дело
находится в монаде STM,

1331
01:25:44,840 --> 01:25:49,340
мы уверены, что каждая из операций
кредит и дебит является атомарной.

1332
01:25:50,180 --> 01:25:54,370
Это значит, что ничего не может
произойти между вот этими операциями.

1333
01:25:55,340 --> 01:25:59,480
Если же, допустим, у нас вот
этот аккаунт с айдишником 1

1334
01:26:00,100 --> 01:26:02,300
был модифицирован в
какой-то другой транзакции,

1335
01:26:03,100 --> 01:26:06,020
то эта операция кредит
rollback-ается полностью,

1336
01:26:06,600 --> 01:26:08,820
потому что была нарушена консистентность.

1337
01:26:09,560 --> 01:26:13,420
И запускается заново на
уже обновленном состоянии.

1338
01:26:13,560 --> 01:26:18,880
Таким образом, мы гарантируем то, что
у нас отсутствуют какие-либо датарейсы

1339
01:26:19,430 --> 01:26:22,560
или какая-то недетерминированность
нашей программы

1340
01:26:22,920 --> 01:26:27,740
вследствие использования
большего, чем 1 количества потоков.

1341
01:26:28,780 --> 01:26:32,340
Таким образом, STM является
универсальным решением для того,

1342
01:26:33,100 --> 01:26:37,240
чтобы написать многоточечный код и
абсолютно не думать о синхронизации.

1343
01:26:38,700 --> 01:26:42,740
Просто STM дает нам
гарантию того, что наш блок кода,

1344
01:26:43,250 --> 01:26:46,720
который мы написали в Monado STM
и который мы можем преобразить в EO

1345
01:26:46,721 --> 01:26:49,440
с помощью функции
Atomical, выполнен атомарно.

1346
01:26:51,440 --> 01:26:52,700
Есть ли какие-то вопросы?

1347
01:26:55,070 --> 01:26:58,600
Не может ли быть такой ситуации, когда,
например, мы вызвали функцию дебит,

1348
01:26:59,050 --> 01:27:02,691
у нас снялись деньги
с счета, но вдруг после

1349
01:27:02,703 --> 01:27:06,440
этого нам прилетел
какой-то exception все же.

1350
01:27:06,480 --> 01:27:08,796
От какого-нибудь, например,
другого потока прилетел exception,

1351
01:27:08,820 --> 01:27:12,220
и мы не выполнили функцию
кредит, и все, мы потеряли.

1352
01:27:12,580 --> 01:27:13,740
Транзакция rollbackается.

1353
01:27:16,500 --> 01:27:16,810
Гарантированно?

1354
01:27:17,180 --> 01:27:22,900
Да. То есть в STM реализован
обработчик исключений,

1355
01:27:23,000 --> 01:27:26,380
который rollbackает транзакции в
случае, если вы исключение не обработали.

1356
01:27:26,381 --> 01:27:32,040
Вы можете его обработать с
помощью функции кедж STM,

1357
01:27:32,220 --> 01:27:34,920
которая на самом деле
специализирована в функции кедж от STM.

1358
01:27:35,060 --> 01:27:37,960
Это не какая-то фундаментально
новая конструкция.

1359
01:27:38,320 --> 01:27:41,560
Вы можете обрабатывать ее
каким-нибудь своим образом.

1360
01:27:41,700 --> 01:27:43,380
И в таком случае не rollback транзакцию.

1361
01:27:43,460 --> 01:27:45,896
Тогда уже ответственность
будет на вас, как на программистов.

1362
01:27:45,920 --> 01:27:49,100
Но по дефолту, при возникновении
любой внештатной ситуации,

1363
01:27:50,245 --> 01:27:51,460
STM транзакции rollbackаются.

1364
01:27:52,060 --> 01:27:55,640
Потому что представьте, что у
вас есть какой-то снимок данных,

1365
01:27:56,020 --> 01:27:59,940
изначальное состояние вашей программы,
ваших данных на момент начала транзакции.

1366
01:28:00,400 --> 01:28:04,680
И эти действия, которые вы делаете в рамках
транзакции, они делаются не in place.

1367
01:28:04,820 --> 01:28:07,460
Представьте, что вы куда-то копируете,

1368
01:28:09,000 --> 01:28:11,320
копируете на копии данных модификации,

1369
01:28:11,640 --> 01:28:13,600
и только если транзакция
завершилась успешно,

1370
01:28:13,640 --> 01:28:15,880
вы накладываете эти
изменения на актуальные данные.

1371
01:28:16,300 --> 01:28:21,360
То есть во время выполнения транзакции,
по факту, ваши данные не модифицируются.

1372
01:28:22,120 --> 01:28:25,840
Потому что действительно очень сложно будет
восстановить состояние вашей программы,

1373
01:28:25,920 --> 01:28:27,720
если вам где-то вот тут
прилетело исключение.

1374
01:28:28,900 --> 01:28:31,240
Поэтому все это делается более хитро.

1375
01:28:31,440 --> 01:28:36,380
На самом деле там даже копия не
создается, в каких-то из реализаций.

1376
01:28:36,440 --> 01:28:39,340
У STM бывают разные
реализации, бывают с блокировками,

1377
01:28:39,460 --> 01:28:42,520
бывают без блокировок, но в Haskell
используется реализация без блокировок.

1378
01:28:45,030 --> 01:28:47,320
Там все довольно хитро и продумано.

1379
01:28:48,340 --> 01:28:51,060
У STM это очень и очень хорошая вещь.

1380
01:28:51,460 --> 01:28:52,540
И удобная.

1381
01:28:54,500 --> 01:28:57,261
Для того, чтобы писать многоточечный
код и вообще ни о чем не думать.

1382
01:28:59,120 --> 01:29:03,520
А в чем была проблема
предыдущего кода, который без STM?

1383
01:29:04,570 --> 01:29:07,260
Так, давайте еще раз на нем остановимся.

1384
01:29:08,200 --> 01:29:12,560
У нас есть функция debit-credit,
которую у нас использует EMWAR.

1385
01:29:13,680 --> 01:29:18,460
Утверждается то, что если у нас
одновременно будет запущена...

1386
01:29:19,660 --> 01:29:20,660
Сейчас.

1387
01:29:22,430 --> 01:29:23,840
Давайте на нее еще раз поглядим.

1388
01:29:24,580 --> 01:29:28,000
Ну, как минимум, есть проблема того,
что если у нас debit-credit вызовется,

1389
01:29:28,580 --> 01:29:33,320
что у нас трансфер будет с одного
аккаунта, то мы бесконечно будем ждать.

1390
01:29:35,220 --> 01:29:36,220
Это первая проблема.

1391
01:29:37,200 --> 01:29:39,764
Вторая проблема того, что
у нас все еще существует

1392
01:29:39,776 --> 01:29:41,940
дедлок, который я не
могу глядеть глазами.

1393
01:29:42,690 --> 01:29:48,940
Он менее тривиальный, чем
если бы у нас была реализация...

1394
01:29:49,780 --> 01:29:52,140
Хотя сейчас, подождите,
дайте 3 секунды подумать.

1395
01:29:52,650 --> 01:29:54,280
С одним аккаунтом какая проблема?

1396
01:29:55,340 --> 01:29:57,820
Мы на него положили деньги, потому что...

1397
01:29:57,821 --> 01:30:00,980
У нас трансфер из одного
аккаунта в один аккаунт.

1398
01:30:04,390 --> 01:30:05,610
Нет, на самом деле ладно.

1399
01:30:05,790 --> 01:30:07,648
У нас все более-менее
нормально, потому что

1400
01:30:07,660 --> 01:30:09,790
данные действия у нас
происходят последовательно.

1401
01:30:09,791 --> 01:30:12,071
Мы берем действительно
take and buy, кладем,

1402
01:30:12,083 --> 01:30:14,270
потом берем еще раз
take and buy и кладем.

1403
01:30:14,330 --> 01:30:17,330
Это в предыдущем могли быть
какие-то проблемы, насколько я понял.

1404
01:30:17,930 --> 01:30:19,250
Я немного завис, подождите.

1405
01:30:20,150 --> 01:30:21,671
Я настолько давно не видел этот слайд.

1406
01:30:22,570 --> 01:30:25,410
А если у нас from и to –
это один и тот же аккаунт?

1407
01:30:25,610 --> 01:30:26,851
Мы здесь заблокируемся на себе.

1408
01:30:29,150 --> 01:30:30,150
Окей, давайте разберемся.

1409
01:30:30,250 --> 01:30:35,570
Если from и to – это один и тот же аккаунт.

1410
01:30:35,910 --> 01:30:38,190
Мы берем и запускаем debit на from.

1411
01:30:38,540 --> 01:30:44,510
Мы берем take and buy
и сразу же туда кладем.

1412
01:30:44,750 --> 01:30:47,070
У нас debit с кредитом не
происходит параллельно.

1413
01:30:48,750 --> 01:30:50,290
Почему мы тут заблокируемся?

1414
01:30:53,700 --> 01:30:57,300
Две параллельные операции
трансфера на одном и том же аккаунте.

1415
01:30:58,185 --> 01:31:00,705
Две параллельные операции
трансфера на одном и том же аккаунте.

1416
01:31:02,080 --> 01:31:07,480
Мы заблокируемся, потом мы будем там ждать.

1417
01:31:07,830 --> 01:31:08,560
Почему же?

1418
01:31:08,700 --> 01:31:14,670
В одном потоке мы все-таки возьмем
и второй поток не успеет и будет ждать.

1419
01:31:15,340 --> 01:31:19,040
Мы положим туда и второй
аккаунт также возьмет.

1420
01:31:19,860 --> 01:31:22,160
У нас может получиться
неконсистентное состояние,

1421
01:31:22,200 --> 01:31:27,610
что мы можем использовать
debit в одной транзакции.

1422
01:31:36,610 --> 01:31:40,750
Смотрите, каждая из операций
debit и кредит – она атомарна.

1423
01:31:42,190 --> 01:31:44,950
Но проблема в том, что у нас
может произойти проблема,

1424
01:31:46,020 --> 01:31:51,330
пока мы отпустили лог после дебита
и еще не взяли ее во время кредита.

1425
01:31:52,170 --> 01:31:56,090
То есть вот это место между строчками
debit и кредит является нашей уязвимостью.

1426
01:31:56,091 --> 01:31:58,790
Потому что сам вот этот
дублок не является атомарным.

1427
01:32:00,690 --> 01:32:04,010
Это makes sense? Или пока все еще не ясно?

1428
01:32:05,320 --> 01:32:06,370
Уязвимость к чему?

1429
01:32:07,190 --> 01:32:11,370
К тому, что пока мы не выполнили...

1430
01:32:12,290 --> 01:32:14,610
Смотрите, хочется, чтобы
трансфер был атомарной операцией.

1431
01:32:14,730 --> 01:32:20,670
Представьте, что у нас на
аккаунте первом лежит 10 рублей.

1432
01:32:23,090 --> 01:32:27,550
Мы здесь сняли какое-то
количество денег, но еще не положили.

1433
01:32:28,350 --> 01:32:31,630
И в это же время, пока мы
сняли деньги, но еще не положили,

1434
01:32:31,710 --> 01:32:33,990
запускается какая-то вторая
транзакция параллельно,

1435
01:32:34,850 --> 01:32:37,670
которая залезает между
нашим debit и нашим кредитом

1436
01:32:38,910 --> 01:32:41,090
и снимает еще раз деньги с этого аккаунта.

1437
01:32:41,550 --> 01:32:43,546
И если бы у нас тут была
бы какая-то сложная логика,

1438
01:32:43,570 --> 01:32:47,270
у нас бы было бы выпрошено исключение того,
что у нас типа hello, у нас нет денег.

1439
01:32:48,370 --> 01:32:50,330
Таким образом нарушается атомарность.

1440
01:32:50,720 --> 01:32:53,250
Трансфер предполагается
атомарной операцией,

1441
01:32:54,230 --> 01:32:59,550
которая атомарно, то есть
единым действием берет и снимает

1442
01:32:59,551 --> 01:33:01,150
деньги с первого аккаунта и
кладет деньги на второй аккаунт.

1443
01:33:01,730 --> 01:33:07,050
Но в данном случае, между тем, как
мы берем блокировку на первый аккаунт

1444
01:33:07,051 --> 01:33:11,050
и берем блокировку на второй аккаунт, у
нас может залезть какой-то другой поток,

1445
01:33:11,430 --> 01:33:14,930
который также ждет блокировку на этот
аккаунт и нарушит нашу консистентность.

1446
01:33:15,370 --> 01:33:17,670
Но согласитесь, довольно
легко представить кейс,

1447
01:33:18,070 --> 01:33:24,170
когда между дебитом и кредитом
залезает какой-то другой платеж,

1448
01:33:24,570 --> 01:33:25,990
который нам нафиг все рушит.

1449
01:33:29,290 --> 01:33:31,950
Только он выбросит
исключение в своем потоке,

1450
01:33:32,270 --> 01:33:35,990
наш это исключение не получит и
рано или поздно сделает кредит?

1451
01:33:37,830 --> 01:33:41,230
Наш кредит будет исполняться
на неконсистентном,

1452
01:33:43,340 --> 01:33:45,350
у нас будет неконсистентность данных.

1453
01:33:45,351 --> 01:33:51,150
У нас делался дебит, мы
хотим сразу же сделать кредит,

1454
01:33:51,630 --> 01:33:54,690
но у нас может быть такая
ситуация, что мы сделали дебит тут,

1455
01:33:55,290 --> 01:33:57,810
а потом сделали дебит
в каком-то другом потоке.

1456
01:33:58,150 --> 01:34:00,510
В данном случае у нас
данные неконсистентные,

1457
01:34:01,370 --> 01:34:04,146
потому что мы сделали
дебит с одного и того же

1458
01:34:04,170 --> 01:34:05,310
аккаунта два раза до того,
как положили туда кредит.

1459
01:34:08,960 --> 01:34:12,120
Получается проблема только в
этой неатомарности операций.

1460
01:34:12,320 --> 01:34:14,660
Проблемы с бейдлоками у нас нет здесь.

1461
01:34:14,810 --> 01:34:18,100
Да, это факт.

1462
01:34:18,500 --> 01:34:20,061
Проблем с бейдлоками, оказывается, нет.

1463
01:34:20,280 --> 01:34:24,340
Я перепутал пример с тем,
что у нас есть такая вещь,

1464
01:34:24,341 --> 01:34:28,620
если вы помните, есть такая
вещь, как в параллелках,

1465
01:34:28,880 --> 01:34:31,940
в курсе параллелок был такой пример,
когда у нас аккаунт тоже дебит-кредит,

1466
01:34:32,760 --> 01:34:36,120
когда мы лочимся, когда it
переводит jit, jit переводит it.

1467
01:34:36,400 --> 01:34:39,300
Я почему-то не обратил внимания на
этот слайд, когда готовился к лекции,

1468
01:34:39,640 --> 01:34:42,220
думал, что это ровно тот же самый
пример, но все понятно, тут deadlock.

1469
01:34:42,600 --> 01:34:43,600
На самом деле, нифига.

1470
01:34:44,160 --> 01:34:46,960
Тут проблема в отсутствии атомарности.

1471
01:34:47,640 --> 01:34:53,980
Смотрите, в том, что mutex позволяет нам

1472
01:34:55,390 --> 01:34:58,820
действие над какой-либо
структурой данных делать атомарным.

1473
01:34:59,180 --> 01:35:03,200
Но если у нас имеется взаимодействие
сразу с несколькими структурами данных,

1474
01:35:03,510 --> 01:35:06,240
в данном случае у нас структура данных
простая, это просто коробка симптомов.

1475
01:35:06,660 --> 01:35:08,600
Но даже в таком простом случае,

1476
01:35:08,825 --> 01:35:10,740
когда наша логика оперирует

1477
01:35:13,300 --> 01:35:15,180
несколькими разными структурами данных,

1478
01:35:15,520 --> 01:35:17,480
операции над каждой из которых атомарны,

1479
01:35:18,410 --> 01:35:21,980
пусть это у нас коробки
симптомов, пусть это у

1480
01:35:22,020 --> 01:35:23,020
нас concurrent очередь,
пусть у нас что-то ещё,

1481
01:35:23,320 --> 01:35:28,500
несмотря на то, что операции
над каждой из них атомарны,

1482
01:35:29,180 --> 01:35:30,600
нам не гарантируется того,

1483
01:35:31,260 --> 01:35:33,560
что операции над композицией фиктур данных,

1484
01:35:33,600 --> 01:35:35,480
когда мы используем
эту и эту структуру данных,

1485
01:35:35,700 --> 01:35:37,140
то что какие-то более комплексные операции

1486
01:35:37,141 --> 01:35:40,736
над ними являются
атомами. В этом как раз-таки

1487
01:35:40,748 --> 01:35:44,120
основная проблема
использования блокировок.

1488
01:35:44,900 --> 01:35:47,425
В том, что в данном
случае это решалось бы, как

1489
01:35:47,437 --> 01:35:50,460
говорилось у вас в курсе
параллельного программирования,

1490
01:35:50,540 --> 01:35:53,419
грубой блокировкой.
Когда мы нафиг лочим все,

1491
01:35:53,431 --> 01:35:56,580
делаем debit-credit и потом
отпускаем блокировку.

1492
01:35:56,640 --> 01:36:01,720
Но это у нас значительно уменьшает процент
кода, который исполняется параллельно.

1493
01:36:03,800 --> 01:36:06,270
Казалось бы, это тоже
тогда получится проблемой,

1494
01:36:06,282 --> 01:36:08,660
что мы навешиваем
блокировку на весь трансфер,

1495
01:36:08,940 --> 01:36:13,018
что у нас очень мало кода
исполняется параллельно, и

1496
01:36:13,030 --> 01:36:17,120
все равно эти трансферы
полностью блокируют систему,

1497
01:36:17,200 --> 01:36:19,640
до тех пор, пока они не
завершатся со своими debit и credit.

1498
01:36:20,160 --> 01:36:26,620
Казалось бы, почему нельзя оставить
атомарными только debit и credit,

1499
01:36:27,070 --> 01:36:30,220
и просто какую-то ксевдо-очередь создать.

1500
01:36:30,860 --> 01:36:34,800
Если кто-то вызвал debit, значит,
надо потом после этого вызвать credit.

1501
01:36:35,260 --> 01:36:40,080
Когда-нибудь вызовем. Когда придет
время, когда дойдет до этого процесса.

1502
01:36:40,440 --> 01:36:45,660
И то, что там не атомарность операций
трансфер, никак на это не повлияет.

1503
01:36:45,661 --> 01:36:49,240
Но вы хотите с помощью данной очереди
как раз-таки обеспечивать порядок того,

1504
01:36:49,400 --> 01:36:54,080
что после debit обязательно должен идти
credit, то, что никто перед ними не залезет.

1505
01:36:54,680 --> 01:36:57,316
То есть вы хотите исполнить
debit и потом в очередь

1506
01:36:57,328 --> 01:36:59,820
положить credit, который
исполнится в следующем.

1507
01:36:59,821 --> 01:37:02,880
На одном потоке никто
между ними не залезет.

1508
01:37:03,120 --> 01:37:07,200
На нескольких потоках, пожалуйста,
пусть другие залезают, это не помешает нам.

1509
01:37:07,540 --> 01:37:13,320
Нет, есть проблема, что если у
тебя, допустим, в аккаунте 0 рублей,

1510
01:37:13,380 --> 01:37:17,680
и у тебя происходит debit,
то у тебя exception возникает.

1511
01:37:17,681 --> 01:37:25,940
А как раз-таки STM делает такую штуку, что
он не возникнет, если операций достаточно.

1512
01:37:26,860 --> 01:37:28,700
То есть если там кредит какой-то произошел.

1513
01:37:28,800 --> 01:37:30,938
Если мне приходит debit,
когда у меня на аккаунте

1514
01:37:30,950 --> 01:37:32,880
0 рублей, то явно я
сам делаю что-то не так.

1515
01:37:33,540 --> 01:37:35,821
Потому что зачем мне снимать
деньги, где у меня 0 рублей.

1516
01:37:36,240 --> 01:37:38,971
А может быть этот debit
приходит, когда у вас 0

1517
01:37:38,983 --> 01:37:41,960
рублей из-за того, что
кредит не успел исполниться.

1518
01:37:44,600 --> 01:37:45,780
Это уже проблема кода.

1519
01:37:48,380 --> 01:37:52,235
Потому что по логике вашей
программы, представьте,

1520
01:37:52,247 --> 01:37:55,960
у вас есть debit-кредит
и еще один debit-кредит.

1521
01:37:56,520 --> 01:37:59,040
И они исполняются параллельно.

1522
01:37:59,140 --> 01:38:03,240
По логике пара debit плюс кредит
должна исполняться атомарно.

1523
01:38:03,360 --> 01:38:07,460
Если у вас залезло оно вот так вот
друг на друга, это проблема программы.

1524
01:38:07,580 --> 01:38:11,780
Потому что состояние на момент
второго дебита неконсистентное.

1525
01:38:11,880 --> 01:38:16,400
Потому что вам еще не успел
прийти кредит на ваш счет.

1526
01:38:16,750 --> 01:38:19,760
А что если в следующем
дебите он также используется?

1527
01:38:20,280 --> 01:38:24,500
И логика вашей программы рассчитывает
на то, что состояние консистентное.

1528
01:38:24,785 --> 01:38:27,600
То, что трансфер исполнился
полностью, но он исполнился не полностью.

1529
01:38:30,100 --> 01:38:36,403
Короче, по-моему, довольно очевидный
момент в том, что мы хотим, чтобы

1530
01:38:36,415 --> 01:38:42,640
как можно больше вещей в нашей
программе имела инвариант атомарности.

1531
01:38:43,100 --> 01:38:44,640
Так намного проще писать код.

1532
01:38:44,740 --> 01:38:48,960
Когда мы не задумываемся над тем,
исполняется ли данный кусок атомарно или нет.

1533
01:38:49,620 --> 01:38:53,685
Также очевидно, что мы
сейчас поняли, что если мы

1534
01:38:53,697 --> 01:38:57,940
используем атомарные
примитивы, атомарные операции,

1535
01:38:58,780 --> 01:39:04,360
друг за другом, это не делает всю нашу
последовательность операции атомарной.

1536
01:39:04,480 --> 01:39:06,920
Потому что так или иначе
между ними может кто-то залезть.

1537
01:39:07,890 --> 01:39:11,571
А если между ними кто-то
залезает, это плохо, потому

1538
01:39:11,583 --> 01:39:14,920
что нарушается консистентность
нашей программы.

1539
01:39:16,960 --> 01:39:20,920
На мой взгляд, пример с дебитами и
кредитами уже весьма репрезентативен.

1540
01:39:21,220 --> 01:39:24,153
Потому что в промежуточных
состояниях у нас может быть на

1541
01:39:24,165 --> 01:39:27,420
аккаунтах лежать не то количество
денег, которое должно лежать,

1542
01:39:27,610 --> 01:39:29,160
потому что не успел дойти к кредитам.

1543
01:39:29,620 --> 01:39:31,792
Но на каких-то более
сложных примерах, я

1544
01:39:31,804 --> 01:39:34,260
уверен, это будет еще
более и более выражено.

1545
01:39:34,910 --> 01:39:39,660
Таким образом, гол, который мы хотим
достигнуть и который дает нам STM,

1546
01:39:40,200 --> 01:39:44,948
это возможность делать
любой блок-кода атомарным,

1547
01:39:44,960 --> 01:39:49,720
просто обернув его в
кейворд Atomical и исполнив.

1548
01:39:51,080 --> 01:39:54,018
Дошли ли мы все к консенсусу
по этому поводу? Или

1549
01:39:54,030 --> 01:39:57,100
у кого-то есть еще какие-то
возражения или вопросы?

1550
01:39:59,360 --> 01:40:00,360
Вопросов вроде нет.

1551
01:40:00,675 --> 01:40:05,680
Окей, да, короче, я немного извиняюсь,
что я действительно перепутал примеры.

1552
01:40:06,140 --> 01:40:08,300
Думал, что тут будет пример с дедлоком.

1553
01:40:08,880 --> 01:40:12,680
Оказывается, что это пример куда более
мотивирующий на использование STM.

1554
01:40:13,020 --> 01:40:15,300
Потому что от дедлока мы
избавились путем рефакторинга.

1555
01:40:16,520 --> 01:40:17,520
Все, супер.

1556
01:40:18,450 --> 01:40:24,740
Таким образом, имея наши
действия обернутые в монаду STM,

1557
01:40:27,580 --> 01:40:31,621
мы лишаем нашу программу
потенциальной уязвимости того, что

1558
01:40:31,633 --> 01:40:35,960
между дебетом и кредитом
протиснится еще какой-нибудь трансфер.

1559
01:40:36,060 --> 01:40:39,560
Потому что если же он успел протиснуться,
наша транзакция просто rollback.

1560
01:40:40,600 --> 01:40:44,320
То есть все исполняется
в данном случае атомарно.

1561
01:40:44,570 --> 01:40:48,440
Какие есть у нас примитивы
для работы с STM?

1562
01:40:48,720 --> 01:40:51,215
Во-первых, это сама
непосредственно дата-тайп

1563
01:40:51,227 --> 01:40:53,400
STM, которая является
инстанцем монаду.

1564
01:40:54,180 --> 01:40:59,120
То есть код в STM мы можем писать с
использованием doNotatz, как мы здесь уже видим.

1565
01:40:59,740 --> 01:41:02,680
Есть переменная
Transactional Variable, TWAR.

1566
01:41:02,900 --> 01:41:05,700
То есть это переменная, которую мы
используем в нашей STM-транзакции.

1567
01:41:06,180 --> 01:41:08,681
У нас есть функция
newTowar, которая возвращает

1568
01:41:08,693 --> 01:41:11,420
нам товар, обернутый в
STM, readTowar и writeTowar.

1569
01:41:11,720 --> 01:41:18,260
В отличие от mvar, не путать, данные
у нас в STM отсутствуют в блокировке.

1570
01:41:18,460 --> 01:41:20,620
То есть STM – это код без блокировок.

1571
01:41:21,280 --> 01:41:23,700
У нас тут нет никаких mutex,
нет никаких разведаний.

1572
01:41:25,000 --> 01:41:27,660
TWAR, в отличие от mvar, не может
быть либо пустым, либо полным.

1573
01:41:27,720 --> 01:41:30,481
Это просто мутабельная переменная,
в которой лежит какое-то значение.

1574
01:41:30,760 --> 01:41:32,620
Ровно так же, как было с EORIOF.

1575
01:41:34,020 --> 01:41:37,313
Если мы хотим писать
какой-то более умный код в STM

1576
01:41:37,325 --> 01:41:40,500
и самим понимать, что у
нас прошло что-то не так,

1577
01:41:40,750 --> 01:41:46,180
то есть помимо непосредственно модификации
данных, модификации shared данных,

1578
01:41:46,440 --> 01:41:51,120
которые сама STM умеет распознавать
самостоятельно и rollback транзакцию.

1579
01:41:51,620 --> 01:41:54,980
Если уже у нас какие-то более сложные
условия, допустим, семантические,

1580
01:41:55,480 --> 01:41:58,500
когда мы понимаем, что состояние
нашей программы неконсистентное,

1581
01:41:59,060 --> 01:42:01,000
мы можем заретравиться самостоятельно.

1582
01:42:01,720 --> 01:42:04,200
Именно в силу того, что мы можем
заретравиться самостоятельно,

1583
01:42:04,480 --> 01:42:07,420
в STM также можно заблокироваться
и выстрелить себе в ногу.

1584
01:42:07,421 --> 01:42:09,825
Вы помните изначально,
когда мы разбирали exception,

1585
01:42:09,837 --> 01:42:12,020
который умеет кидать
runtime в систему Haskell,

1586
01:42:12,715 --> 01:42:15,220
там же был exception
blocked indefinitely on STM.

1587
01:42:15,620 --> 01:42:18,180
Вот как раз и в случае неаккуратного
использования функции retry

1588
01:42:18,780 --> 01:42:22,280
можно выстрелить себе в ногу и
получить бесконечную STM транзакцию.

1589
01:42:24,000 --> 01:42:25,700
Поэтому ее нужно использовать с умом.

1590
01:42:25,840 --> 01:42:28,400
Но на практике очень редко
хочется использовать функцию retry.

1591
01:42:28,980 --> 01:42:32,740
Просто берем, заворачиваем
наш соклодатблок Atomically,

1592
01:42:33,140 --> 01:42:35,861
или же исполняем все это в Monodext,
и мы потом вызываем Atomically,

1593
01:42:35,940 --> 01:42:40,300
для того, чтобы преобразовать это в
OOP, и чувствуем себя счастливым.

1594
01:42:41,700 --> 01:42:45,620
Также у нас есть функция Orals,
которая принимает две транзакции.

1595
01:42:45,840 --> 01:42:49,040
Если первая из них абортится,
фейлится, то исполняет вторую.

1596
01:42:49,990 --> 01:42:53,080
Также может быть полезно при
написании каких-то комплексных сценариев.

1597
01:42:53,780 --> 01:42:58,900
Допустим, если мы хотим взять
данные из двух разных источников,

1598
01:42:59,150 --> 01:43:01,980
первый у нас запейлился, по
какой-либо причине берем из второго.

1599
01:43:03,080 --> 01:43:05,760
Также есть функции throwStm и catchStm,

1600
01:43:06,500 --> 01:43:13,520
которые просто специализированные версии
функций throw, yaw и catch для Monodext.

1601
01:43:13,880 --> 01:43:16,960
То есть никакой смысловой
нагрузки новой там не прибавляется.

1602
01:43:17,140 --> 01:43:20,460
Это не является еще одним фундаментально
новым способом lowly exception.

1603
01:43:21,460 --> 01:43:24,780
Это просто вещи, которые
удобно использовать в Monodext.

1604
01:43:28,590 --> 01:43:31,650
Есть ли какие-то вопросы по остальным?

1605
01:43:33,050 --> 01:43:38,550
Да, мне кажется странным, что она
перезапускает транзакцию при изменении данных.

1606
01:43:39,050 --> 01:43:43,550
Кажется, здесь очень легко задеволочиться,
даже на нашем примере с банком.

1607
01:43:45,010 --> 01:43:47,610
Давайте подумаем, как это сделать.

1608
01:43:48,650 --> 01:43:55,230
Две транзакции, одна с аккаунта A на B,
вторая с B на A, одновременно запустить.

1609
01:43:55,630 --> 01:44:01,290
Первая списала деньги с аккаунта A,
начинает зачислять на B, приходит вторая,

1610
01:44:02,010 --> 01:44:05,590
меняет на аккаунте B, это
видит первая, перезапускается.

1611
01:44:06,360 --> 01:44:11,630
Вторая снимает деньги с B, начинает
записывать на A, приходит первая,

1612
01:44:12,250 --> 01:44:14,570
видит, что ашку изменили, перезапускается.

1613
01:44:14,970 --> 01:44:16,530
Я понял, о чем вы говорите.

1614
01:44:21,370 --> 01:44:27,190
Перезапуск транзакций – это не такая
тривиальная вещь, как мы с вами сейчас думаем.

1615
01:44:27,530 --> 01:44:37,950
Очевидно, шедулер потоков, так же
как и шедулер, он называется VSTM,

1616
01:44:38,030 --> 01:44:40,315
это называется Transaction
Manager, это механизм,

1617
01:44:40,327 --> 01:44:42,530
который ответственный
за перезапуск транзакции.

1618
01:44:42,905 --> 01:44:47,950
Он достаточно интеллектуален для
того, чтобы такие кейсы не допускать.

1619
01:44:48,570 --> 01:44:50,710
Он умеет давать какой-то
транзакции и подождать.

1620
01:44:51,270 --> 01:44:53,397
В данном случае, согласитесь,
эта проблема решается в

1621
01:44:53,409 --> 01:44:55,670
том, чтобы дать какой-то
транзакции и немного подождать,

1622
01:44:56,090 --> 01:45:01,210
если же идет вот такая вот
зацикленная конкуренция за данную.

1623
01:45:02,870 --> 01:45:07,490
А разве VSTM мы не навешиваем прям
всю блокировку на всю операцию трансфера,

1624
01:45:07,610 --> 01:45:10,010
так что у нас не залезет
транзакция друг на друга?

1625
01:45:11,050 --> 01:45:17,610
В VSTM у нас нет блокировок.
В STM отсутствуют блокировки.

1626
01:45:18,290 --> 01:45:21,830
Это вещь, которая реализована
на других примитивах.

1627
01:45:22,650 --> 01:45:28,250
Одна из реализаций STM,
она реализована в MPP.

1628
01:45:28,610 --> 01:45:31,571
У вас, наверное, уже была такая тема,
такая операция, как compare-and-set.

1629
01:45:32,580 --> 01:45:42,190
Это можно сделать без блокировок с
помощью цикловайл с compare-and-set.

1630
01:45:42,450 --> 01:45:45,830
Если что-то у нас не сошлось,
мы просто LBK транзакцию.

1631
01:45:46,280 --> 01:45:47,790
Тут нет блокировок от слова совсем.

1632
01:45:51,890 --> 01:46:00,370
Разве мы не давляем состояние,
когда у нас произошел STM,

1633
01:46:00,371 --> 01:46:03,299
то есть мы вышли из
STM, тогда мы говорим,

1634
01:46:03,311 --> 01:46:06,530
что новые потоки не
успели запускаться заново.

1635
01:46:08,450 --> 01:46:13,070
Что сейчас? Смотрите, мы вышли из STM.
Я просто не понял ваш вопрос.

1636
01:46:13,470 --> 01:46:19,070
Да, мы вышли из STM. Другие потоки,
допустим, там, в этом STM еще находятся.

1637
01:46:20,030 --> 01:46:22,970
Мы им говорим о том, что
давайте вывести все заново,

1638
01:46:23,090 --> 01:46:27,410
потому что какой-то там вышел,
состояние обновилось, давайте заново.

1639
01:46:29,860 --> 01:46:30,901
Совершенно так происходит.

1640
01:46:31,190 --> 01:46:34,130
Да, это так происходит.
Только мы явно никому не говорим.

1641
01:46:34,550 --> 01:46:38,610
За это механизм STM умеет
это разруливать самостоятельно.

1642
01:46:39,250 --> 01:46:42,410
Смотрите, если у нас есть две
транзакции, которые конкурируют за данные,

1643
01:46:43,050 --> 01:46:47,510
одна из них видит, что данные
были изменены каким-либо образом.

1644
01:46:49,330 --> 01:46:53,570
Я сам, честно признаться, далеко не
знаю, как в деталях реализована STM.

1645
01:46:54,020 --> 01:46:57,330
Очевидно, там условия не такие
тривиальные, как просто данные изменены.

1646
01:46:57,630 --> 01:47:01,990
Там выстраиваются зависимости между данными,
используются более сложные механизмы.

1647
01:47:02,690 --> 01:47:04,690
Давайте просто разбирать на примере.

1648
01:47:04,750 --> 01:47:08,730
Две транзакции. Обе из них
оперируют какими-то shared данными.

1649
01:47:09,730 --> 01:47:11,910
Одна из них успеет изменять эти данные.

1650
01:47:12,170 --> 01:47:15,050
Вторая из них видит, ага, они уже изменены.
Давайте-ка я rollback.

1651
01:47:15,450 --> 01:47:18,164
Таким любым образом
у нас присутствует

1652
01:47:18,176 --> 01:47:21,690
постоянный прогресс в
нашей параллельной системе.

1653
01:47:21,940 --> 01:47:28,550
То, что у нас не бывает такое, что обе наши
транзакции рождают rollback друг друга.

1654
01:47:28,910 --> 01:47:32,770
Одна из них всегда идет дальше, а вторая
перезапускается уже на обновленных данных.

1655
01:47:32,830 --> 01:47:37,450
И вторая может перезапуститься
2-3 раза, если у нас много транзакций.

1656
01:47:37,530 --> 01:47:41,290
Но у нас имеется постоянный прогресс.
Отсутствует голодание.

1657
01:47:42,230 --> 01:47:43,878
По-моему, это
называется, если я не забыл

1658
01:47:43,890 --> 01:47:45,671
терминологию параллельного
программирования.

1659
01:47:48,360 --> 01:47:50,001
Короче, все менеджируется самостоятельно.

1660
01:47:50,210 --> 01:47:53,518
Нам, как программисту,
достаточно написать doblock в

1661
01:47:53,530 --> 01:47:56,850
Monado STM и запустить это
с помощью функции Atomic.

1662
01:48:03,275 --> 01:48:04,900
Есть ли еще какие-то
вопросы по STM? Вроде нет.

1663
01:48:08,920 --> 01:48:09,920
Супер.

1664
01:48:10,360 --> 01:48:15,420
Да, еще немного
отвлечения в сторону.

1665
01:48:17,260 --> 01:48:22,640
Нельзя не пропиарить, что Haskell является
одним из достаточно немногих языков,

1666
01:48:22,860 --> 01:48:25,865
где STM реализована
из коробки и присутствует,

1667
01:48:25,877 --> 01:48:28,500
можно сказать, в
стандартной библиотеке.

1668
01:48:29,280 --> 01:48:32,760
Да, у нас пакет STM, это
не стандартная библиотека,

1669
01:48:32,880 --> 01:48:36,940
но он входит в список библиотек, которые
поставляются вместе с компилятором грешки.

1670
01:48:37,600 --> 01:48:39,320
Они называются boot libraries.

1671
01:48:39,940 --> 01:48:42,320
Haskell называется почти
стандартной библиотекой.

1672
01:48:42,321 --> 01:48:43,521
Ровно так же, как пакет текст.

1673
01:48:43,920 --> 01:48:46,720
Его нет в стандартной библиотеке,
но он поставляется вместе с грешкой.

1674
01:48:47,520 --> 01:48:51,251
И STM, если мне не изменяет
память, есть в Haskell,

1675
01:48:51,263 --> 01:48:55,080
есть в Rust, есть в Clojure,
есть в OCaml и в Scala.

1676
01:48:56,060 --> 01:49:00,800
По-моему, также есть какая-то экспериментальная
реализация в плюсах на Monado.

1677
01:49:01,940 --> 01:49:04,760
Но я не уверен, что она
production-ready от слова совсем.

1678
01:49:05,240 --> 01:49:08,145
Короче, так уж вышло,
и в курсе параллельного

1679
01:49:08,157 --> 01:49:10,880
программирования вы
также этого коснетесь.

1680
01:49:10,881 --> 01:49:15,160
То есть реализация STM очень хорошо
разложится на функциональную парадигму.

1681
01:49:16,930 --> 01:49:18,963
И поэтому большинство
из языков, где присутствует

1682
01:49:18,975 --> 01:49:20,520
STM, это именно
функциональные языки.

1683
01:49:20,820 --> 01:49:23,875
Потому что там довольно
просто реализовать вот

1684
01:49:23,887 --> 01:49:26,820
такую бы нетривиальную
конструкцию, как STM.

1685
01:49:28,960 --> 01:49:31,120
Вот такие дела.
И последний на сегодня пример с STM.

1686
01:49:31,640 --> 01:49:34,320
Про то, как использовать
функции retry и or else.

1687
01:49:35,260 --> 01:49:39,720
Давайте заведем довольно тупой
трансфер, который принимает amount from to.

1688
01:49:40,500 --> 01:49:44,904
И смотрит, что если у нас
достаточно денег, чтобы снять с

1689
01:49:44,916 --> 01:49:49,720
этого аккаунта, мы делаем
debit-credit, иначе мы делаем retry.

1690
01:49:50,180 --> 01:49:53,420
Данный пример абсолютно не
имеет никакого практического смысла.

1691
01:49:53,580 --> 01:49:58,114
Потому что писать банк,
который retry транзакцию,

1692
01:49:58,126 --> 01:50:02,580
если там нет достаточно
денег, это очень наивно.

1693
01:50:03,140 --> 01:50:06,200
Данный пример нужен просто, чтобы
продемонстрировать пример функции retry.

1694
01:50:06,650 --> 01:50:12,094
То есть в данном случае наша данная
транзакция будет бесконечно выполняться,

1695
01:50:12,106 --> 01:50:16,700
пока кто-то другой не положит
нам деньги на наш банковский счет.

1696
01:50:17,140 --> 01:50:19,983
Очевидно, что это плохой
пример реализации бизнес-логики,

1697
01:50:19,995 --> 01:50:22,400
но это неплохой пример
реализации функции retry.

1698
01:50:23,820 --> 01:50:27,617
Потому что обычно функцию retry нам
не хочется очень часто использовать,

1699
01:50:27,629 --> 01:50:31,280
поэтому хотелось какой-то
репрезентативный, но не самый умный пример.

1700
01:50:31,830 --> 01:50:32,830
Вот, собственно, есть.

1701
01:50:33,740 --> 01:50:37,473
И также, если мы хотим каким-либо
образом комбинировать наши

1702
01:50:37,485 --> 01:50:40,980
тайм-транзакции, представьте,
что у нас есть два товара,

1703
01:50:42,080 --> 01:50:47,620
и хотим попытаться взять
либо один из них, либо второй.

1704
01:50:51,400 --> 01:50:54,380
А, господи, это у нас
на самом деле не товар.

1705
01:50:54,505 --> 01:50:56,160
Товар – это такая вещь, как TMVAR.

1706
01:50:56,600 --> 01:51:01,750
Это товар еще и с mutex,
который можно использовать

1707
01:51:01,762 --> 01:51:06,620
в Monado STM, и на который
также можно лочиться.

1708
01:51:08,060 --> 01:51:10,980
Что мы тут делаем?
Мы тут пытаемся взять первый MVAR.

1709
01:51:12,780 --> 01:51:16,040
Если транзакция у нас зафрейлилась,
мы пытаемся брать второй MVAR.

1710
01:51:16,260 --> 01:51:19,106
И оборачиваем это дело либо в
constructor.left, либо в constructor.right.

1711
01:51:19,130 --> 01:51:21,843
Честно вам скажу,
видел в жизни достаточно

1712
01:51:21,855 --> 01:51:24,840
много concurrent кода,
ни разу не видел TMVAR.

1713
01:51:25,480 --> 01:51:28,780
Это что-то из области
очень и очень странного.

1714
01:51:29,060 --> 01:51:31,380
Ни разу в жизни не приходилось
использовать этот примитив.

1715
01:51:31,800 --> 01:51:35,480
В основном хочется использовать либо
MVAR для mutex, либо товар для STM.

1716
01:51:36,230 --> 01:51:38,700
Но такой зверек, как
TMVAR, тоже существует.

1717
01:51:39,800 --> 01:51:42,640
Также есть пакет, который
называется STM Containers,

1718
01:51:42,840 --> 01:51:45,716
в который включены
реализацию concurrent

1719
01:51:45,728 --> 01:51:49,050
структур данных MapAsset
с использованием STM.

1720
01:51:49,960 --> 01:51:51,220
Можно с ним ознакомиться.

1721
01:51:52,900 --> 01:51:56,960
В конечном итоге давайте
подведем итоги того,

1722
01:51:57,360 --> 01:52:04,180
что нам дают фичи Haskell при
написании concurrent программ.

1723
01:52:05,340 --> 01:52:06,680
Easier to debug.

1724
01:52:07,260 --> 01:52:11,600
Довольно спорное утверждение,
потому что в Haskell нет дебегеров.

1725
01:52:12,075 --> 01:52:18,600
Но действительно отсутствие
мутабельности во всех аспектах,

1726
01:52:18,720 --> 01:52:23,180
то есть имение какой-то лимитированной
мутабельности только в URF или MVAR,

1727
01:52:23,860 --> 01:52:27,340
действительно делает код проще для анализа.

1728
01:52:28,540 --> 01:52:34,400
Но в чем точно мутабельность помогает очень
сильно, так это в написании TRC в коду.

1729
01:52:34,920 --> 01:52:38,780
Представьте, что у нас есть какой-то
MVAR, в котором лежит какая-то мапа.

1730
01:52:38,830 --> 01:52:42,200
Довольно большая структура
данных, которая завернута в mutex.

1731
01:52:45,880 --> 01:52:48,600
Почему в силу того, что
данная мапа мутабельна,

1732
01:52:48,612 --> 01:52:50,820
нам может быть легче
писать TRC в код?

1733
01:52:51,230 --> 01:52:54,037
Потому что в Haskell
мы можем взять нашу

1734
01:52:54,049 --> 01:52:57,220
мапу из MVAR и сразу
же отпустить блокировку.

1735
01:52:57,580 --> 01:53:00,449
И при этом, зная, что эта
мапа мутабельна, мы знаем,

1736
01:53:00,461 --> 01:53:03,120
что никто из другого
потока не изменит эту мапу.

1737
01:53:03,670 --> 01:53:06,685
В другом языке программирования
наивная реализация

1738
01:53:06,697 --> 01:53:09,180
будет держать
блокировку на всю эту мапу,

1739
01:53:09,400 --> 01:53:12,460
или хотя бы на один из ее ключей,
если мы работаем с этим ключом,

1740
01:53:13,160 --> 01:53:16,520
до тех пор, пока мы полностью
не осуществим нашу операцию.

1741
01:53:16,680 --> 01:53:20,880
Потому что в любой момент до нашей
мапы могут достучаться и изменить ее.

1742
01:53:21,340 --> 01:53:24,070
В Haskell мы просто на
секундочку берем блокировку,

1743
01:53:24,082 --> 01:53:26,340
достаем нашу мапу и
работаем с ней дальше.

1744
01:53:26,990 --> 01:53:30,960
Потому что наша мапа мутабельна, мы
можем взять блокировку всего на чуть-чуть

1745
01:53:31,310 --> 01:53:34,020
и знать, что никто нашу мапу не изменит.

1746
01:53:35,280 --> 01:53:37,560
Это такой достаточно мотивирующий пример.

1747
01:53:38,880 --> 01:53:40,896
Ну и классическая
байка про то, что в Haskell

1748
01:53:40,908 --> 01:53:42,800
тяжело выстрелить
себе в ногу и так далее.

1749
01:53:42,860 --> 01:53:44,660
На самом деле мы
увидели, что довольно легко.

1750
01:53:45,140 --> 01:53:48,160
Но утверждается, что в
других языках не сложнее.

1751
01:53:51,020 --> 01:53:57,120
Также у нас, если грамотно все использовать,
у нас ни датарейсов, ни блокировок,

1752
01:53:57,900 --> 01:53:59,560
если у нас используется Monado ST.

1753
01:54:00,655 --> 01:54:07,800
Короче, если сильно не хайпить
Haskell и по-реалистичному смотреть,

1754
01:54:08,160 --> 01:54:11,340
я бы сказал, что киллер-фичей
для конкуренции Haskell является то,

1755
01:54:11,400 --> 01:54:15,820
что его потоки достаточно легковесные и
то, что присутствует такая вещь, как STM,

1756
01:54:16,300 --> 01:54:19,420
которая действительно позволяет
нам очень легко писать многоточный код.

1757
01:54:20,020 --> 01:54:23,600
Вот это действительно является киллер-фичей
Haskell в контексте конкуренции.

1758
01:54:24,300 --> 01:54:27,860
Байки про мутабельность, это конечно
хорошо, они действительно помогают,

1759
01:54:27,861 --> 01:54:30,788
но во всех остальных
языках программирования уже

1760
01:54:30,800 --> 01:54:33,800
завезли нормальную работу
с мутабельными данными.

1761
01:54:33,980 --> 01:54:34,980
Этим никого не удивить.

1762
01:54:35,240 --> 01:54:38,420
А вот STM из коробки, я
думаю, можно много кого удивить.

1763
01:54:43,140 --> 01:54:48,960
На этом мы с вами заканчиваем такой
раздел нашей лекции, как конкуренции,

1764
01:54:49,740 --> 01:54:53,135
который про EOS-ные
многопоточные программы и

1765
01:54:53,147 --> 01:54:57,160
взаимодействие между ними,
синхронизацию и так далее.

1766
01:54:57,161 --> 01:54:58,800
Сейчас будем говорить про параллелизм.

1767
01:54:59,320 --> 01:55:00,920
И поговорим мы с вами достаточно быстро.

1768
01:55:01,360 --> 01:55:04,720
Есть ли у вас какие-то вопросы
про раздел по конкуренции?

1769
01:55:10,500 --> 01:55:11,500
Ок.

1770
01:55:11,560 --> 01:55:14,358
Давайте тогда по-быстренькому
пробежимся, как же мы

1771
01:55:14,370 --> 01:55:17,180
можем исполнять наш
Haskell-чистый код параллельно.

1772
01:55:17,820 --> 01:55:24,260
И посмотрим, как это дело профайлить
по-быстренькому и закончим лекцию.

1773
01:55:25,360 --> 01:55:28,548
Напоминаю, что
параллельность в терминах Haskell

1774
01:55:28,560 --> 01:55:31,760
– это когда у нас есть
какое-то чистое действие,

1775
01:55:32,160 --> 01:55:33,640
и мы хотим выполнить его параллельно.

1776
01:55:34,340 --> 01:55:35,960
Распараллелить на несколько потоков.

1777
01:55:36,340 --> 01:55:39,360
Для этого дела
существует, вы не поверите,

1778
01:55:39,372 --> 01:55:42,620
но отдельная монада,
которая называется Eval.

1779
01:55:43,200 --> 01:55:46,260
Это монада для исполнения
параллельных вычислений.

1780
01:55:47,150 --> 01:55:49,640
Давайте разберем, какие у нее есть функции.

1781
01:55:49,990 --> 01:55:55,100
Есть функция runEval, которая
принимает значение в монаде A,

1782
01:55:57,360 --> 01:56:00,060
значение комплексное, которое
мы хотим посчитать параллельно.

1783
01:56:00,560 --> 01:56:04,008
И с помощью функции runEval
доставать оттуда, запускать

1784
01:56:04,020 --> 01:56:07,480
параллельное вычисление и
на выходе получать результат.

1785
01:56:08,400 --> 01:56:11,400
И есть две функции, основные,
с которыми мы будем работать.

1786
01:56:11,520 --> 01:56:13,020
Это rpar и rsec.

1787
01:56:14,240 --> 01:56:19,620
Функция rpar применяется в монаде Eval,
принимает какое-то значение и говорит,

1788
01:56:19,840 --> 01:56:23,680
вычисли мне его, пожалуйста, до слабой
головной нормальной формы параллельно.

1789
01:56:23,880 --> 01:56:28,060
То есть создай отдельный
спарк в своем трекпуле,

1790
01:56:28,800 --> 01:56:31,408
для того чтобы вычислить
вот это значение до

1791
01:56:31,420 --> 01:56:34,100
слабой головной нормальной
формы параллельно.

1792
01:56:36,430 --> 01:56:40,020
В спарке, если вы помните, в самом
начале лекции у нас была такая диаграммка,

1793
01:56:40,620 --> 01:56:46,820
и у нас там были ядра, оэстроды,
хаскельные троды и спарки.

1794
01:56:46,880 --> 01:56:50,740
Спарки — это куда более мелкие
единицы, которые используются как задачки,

1795
01:56:51,380 --> 01:56:52,840
вида вычисления что-то параллельно.

1796
01:56:53,930 --> 01:56:56,520
Есть функция rpar, которая
просто берет значение

1797
01:56:56,580 --> 01:56:57,740
и говорит, посчитай
мне его параллельно.

1798
01:56:58,040 --> 01:57:00,480
Есть функция rsec, которая
берет значение и говорит,

1799
01:57:01,060 --> 01:57:05,180
посчитай мне его
последовательно, в этом же потоке,

1800
01:57:05,500 --> 01:57:08,500
и дождись его вычисления до
слабой головной нормальной формы.

1801
01:57:11,560 --> 01:57:14,800
Как мы уже говорили, спарк
— это просто какая-то работа,

1802
01:57:14,920 --> 01:57:18,104
которая может быть
сделана, и хинт компилятору,

1803
01:57:18,116 --> 01:57:20,700
что ты можешь сделать
это параллельно.

1804
01:57:21,720 --> 01:57:24,000
Вот, разберем, как это
все дело у нас работает.

1805
01:57:24,680 --> 01:57:30,220
Представьте, что у нас есть функция f, и
мы хотим вычислить fx и fy параллельно.

1806
01:57:30,710 --> 01:57:32,351
Что мы делаем? Мы
находимся в monad.

1807
01:57:33,860 --> 01:57:36,200
yval, и говорим,
пожалуйста, вычисли f от x,

1808
01:57:37,020 --> 01:57:39,360
и присвоим это дело
переменной a параллельно.

1809
01:57:40,240 --> 01:57:42,420
Затем сразу же вычисли f от y,

1810
01:57:42,940 --> 01:57:44,740
и присвоим это дело
переменной b параллельно.

1811
01:57:45,140 --> 01:57:48,660
И затем верни пока еще
недосчитанные thunks a и b.

1812
01:57:49,120 --> 01:57:51,200
Если рассматривать все
это дело как таймлайн,

1813
01:57:51,960 --> 01:57:54,300
и представить, что f от x
вычисляется дольше, чем f от y,

1814
01:57:55,020 --> 01:57:58,780
то return будет вызван ровно в то же время,

1815
01:57:59,560 --> 01:58:01,920
когда у нас были запущены
параллельные вычисления.

1816
01:58:02,560 --> 01:58:05,660
То есть на момент нашего с вами return,

1817
01:58:06,310 --> 01:58:09,500
вот эти thunks, пока еще не
вычисленные выражения f от x,

1818
01:58:09,680 --> 01:58:12,360
чистые выражения, они
все еще будут читаться.

1819
01:58:12,700 --> 01:58:15,780
Если же нам где-то, допустим,
понадобится вывести их на консоль,

1820
01:58:16,100 --> 01:58:19,080
или с чем-то сравнить,
то в данном моменте мы

1821
01:58:19,081 --> 01:58:21,400
остановимся и подождем,
пока наш thunk довычислится.

1822
01:58:21,960 --> 01:58:25,480
Но в данном случае мы свободно можем
продолжать дальше и подождать где-нибудь потом.

1823
01:58:25,940 --> 01:58:28,920
То есть мы можем вернуть
эти thunks из нашей функции,

1824
01:58:30,220 --> 01:58:31,980
и они когда-то потом посчитаются.

1825
01:58:33,280 --> 01:58:36,801
И потом уже, может быть, на момент
использования они уже будут досчитаны.

1826
01:58:37,240 --> 01:58:38,660
В этом прикол функции rpath.

1827
01:58:38,900 --> 01:58:40,280
То, что мы берем и просто говорим,

1828
01:58:40,400 --> 01:58:42,480
вычисли мне, пожалуйста,
параллельно, и идем дальше.

1829
01:58:42,640 --> 01:58:44,921
И так же говорим, вычисли
мне параллельно, и идем дальше.

1830
01:58:45,280 --> 01:58:48,080
И так как это у нас чистые значения,

1831
01:58:48,560 --> 01:58:52,040
у нас нет никаких future, нет
никаких iot и прочих других обертков,

1832
01:58:52,740 --> 01:58:56,120
это просто какое-то ленивое
значение, которое пошло вычисляться.

1833
01:58:56,600 --> 01:58:58,260
Вычислилось оно еще или нет, фиг знает.

1834
01:58:58,660 --> 01:59:01,800
Но если оно нам нужно, и оно
не вычислилось, мы подождем.

1835
01:59:02,920 --> 01:59:03,920
Вот такие периоды.

1836
01:59:04,700 --> 01:59:05,880
Разберем, как работает RSEC.

1837
01:59:06,900 --> 01:59:10,080
Мы говорим, давай f от
x вычисляй параллельно,

1838
01:59:10,530 --> 01:59:11,580
и отправили вычисляться.

1839
01:59:11,820 --> 01:59:14,160
А f от y мы хотим
вычислить последовательно.

1840
01:59:14,520 --> 01:59:18,180
То есть мы хотим, чтобы на момент
ретерна b уже было вычислено,

1841
01:59:18,505 --> 01:59:23,180
а a еще нет, потому что мы
предполагаем, что a считается дольше.

1842
01:59:23,760 --> 01:59:26,740
Получается, ретерн будет вызван
сразу после того, когда считается b.

1843
01:59:27,710 --> 01:59:30,340
И на этом, собственно, интерфейс
Monado Eval заканчивается.

1844
01:59:30,820 --> 01:59:32,640
Основной интерфейс
Monado Eval заканчивается.

1845
01:59:32,720 --> 01:59:36,920
Там, понятно, есть более сложные
примитивы, как и с Concartly Erase,

1846
01:59:37,380 --> 01:59:41,280
для работы с всякими списками, для
работы с произвольными траверсаблами,

1847
01:59:41,900 --> 01:59:42,860
фолдаблами и так далее.

1848
01:59:42,920 --> 01:59:46,360
Но все это дело можно смоделировать,
представить через mpar и RSEC.

1849
01:59:49,300 --> 01:59:51,740
Если же мы хотим...

1850
01:59:52,480 --> 01:59:54,280
Смотрите, последний пример мотивирующий.

1851
01:59:54,580 --> 01:59:57,700
Мы отправляем a
вычисляться в отдельный поток,

1852
01:59:58,460 --> 02:00:02,340
затем в том же потоке вычисляем b,

1853
02:00:03,040 --> 02:00:04,620
а потом все-таки хотим дождаться a.

1854
02:00:05,165 --> 02:00:07,380
Тогда ретерн будет выполнен уже после того,

1855
02:00:07,880 --> 02:00:10,500
когда у нас обе a и b будут вычислены.

1856
02:00:10,680 --> 02:00:13,740
Короче, мы с помощью mpar и
RSEC можем манипулировать

1857
02:00:13,965 --> 02:00:16,040
параллельными вычислениями как нам угодно.

1858
02:00:16,180 --> 02:00:18,920
То есть мы в нужный момент
можем подождать с помощью RSEC,

1859
02:00:19,480 --> 02:00:22,720
в нужный момент можем что-то
отправить читаться с помощью mpar.

1860
02:00:23,420 --> 02:00:26,560
Все. То есть на этом API
monad и val заканчиваются.

1861
02:00:26,860 --> 02:00:29,720
И потом с помощью run и val мы это
дело достаем и получаем чистое значение.

1862
02:00:35,690 --> 02:00:37,690
Мне показалось, что там
кто-то четко что-то писал.

1863
02:00:38,550 --> 02:00:39,550
Есть ли какие-то
вопросы? Да, конечно.

1864
02:00:40,430 --> 02:00:41,430


1865
02:00:41,900 --> 02:00:45,370
Почему это сделано монадой
отдельной и другим типом?

1866
02:00:45,590 --> 02:00:47,110
Ведь если у нас чистые функции,

1867
02:00:47,290 --> 02:00:51,530
компилятор мог бы сам неявно это
все запускать параллельно и вычислять.

1868
02:00:52,430 --> 02:00:53,870
Зачем нам что-то делать?

1869
02:00:53,871 --> 02:00:55,191
Об этом мы сейчас будем говорить.

1870
02:00:57,390 --> 02:01:00,290
Потому что это делать невыгодно.

1871
02:01:00,970 --> 02:01:04,710
Хочется, чтобы программист явно указывал,

1872
02:01:05,070 --> 02:01:06,470
что мы хотим параллелить.

1873
02:01:06,810 --> 02:01:08,350
Потому что это логичное предположение.

1874
02:01:08,390 --> 02:01:09,390
У нас все чистое.

1875
02:01:09,590 --> 02:01:10,750
Почему бы не параллелить все?

1876
02:01:11,050 --> 02:01:15,830
Но на самом деле, если
делать это без ведома

1877
02:01:15,831 --> 02:01:17,890
программиста и параллелить
каждую операцию,

1878
02:01:18,410 --> 02:01:22,730
ну или до какого-то осмысленного
момента, то может быть две проблемы.

1879
02:01:22,850 --> 02:01:23,090
Первая.

1880
02:01:23,640 --> 02:01:25,831
То, что мы наплодим с лица,
это слишком много спарков.

1881
02:01:26,230 --> 02:01:28,366
Несмотря на то, что
их, в принципе, можно

1882
02:01:28,390 --> 02:01:29,590
плодить очень много, мы
можем с этим переборщить.

1883
02:01:30,090 --> 02:01:35,266
Во-вторых, порой оверхед на создание спарка,
несмотря на то, что он очень маленький,

1884
02:01:35,290 --> 02:01:38,390
может быть больше, чем
оверхед на выполнение операции.

1885
02:01:39,130 --> 02:01:41,610
Поэтому параллелить все
и всегда – это невыгодно.

1886
02:01:42,170 --> 02:01:45,730
А делать какой-то conditional
параллелизм – а зачем?

1887
02:01:46,090 --> 02:01:48,390
Если можно предоставить
программисту удобный API?

1888
02:01:48,990 --> 02:01:50,310
Потому что, на мой взгляд,

1889
02:01:50,490 --> 02:01:53,490
Monado и VAL – это очень
простая и очень удобная вещь.

1890
02:01:53,540 --> 02:01:54,910
Просто берешь RUN и VAL,

1891
02:01:55,370 --> 02:01:58,331
просто говоришь, что вычислить
параллельно, что вычислить последовательно.

1892
02:01:58,710 --> 02:02:00,550
И никаких датарейсов, вообще ничего,

1893
02:02:00,750 --> 02:02:02,310
у тебя все иммутабельное, все чистое,

1894
02:02:02,470 --> 02:02:04,190
ты живешь в себе прикрывающий.

1895
02:02:05,050 --> 02:02:08,850
Лучше уж сделать вот
так, чем параллелить все.

1896
02:02:09,590 --> 02:02:12,070
А уж тем более, чем грабить
какие-то костыли в компиляторе,

1897
02:02:12,090 --> 02:02:14,770
чтобы он пытался догадываться,
что лучше параллелить, а что нет.

1898
02:02:16,230 --> 02:02:17,770
Но это мы уже забегая вперед сказали.

1899
02:02:19,130 --> 02:02:26,030
Ну, тут у нас пример, как вычислять
Fibonacci от 39 и от 38 параллельно.

1900
02:02:27,190 --> 02:02:29,990
И если же мы вдруг хотим посмотреть,

1901
02:02:33,370 --> 02:02:35,450
сколько у нас ядер
процессора было задействовано,

1902
02:02:35,550 --> 02:02:38,030
сколько у нас отработал
garbage collector,

1903
02:02:38,210 --> 02:02:39,870
и на другую интересную инфографику,

1904
02:02:40,550 --> 02:02:43,450
мы можем передать туда флажок event log

1905
02:02:45,010 --> 02:02:46,650
и какие-то другие флажки,

1906
02:02:47,370 --> 02:02:50,830
о которых, я думаю, нет смысла
останавливаться, если что, прочитать.

1907
02:02:51,470 --> 02:02:55,450
И запустить утилиту
Threadscope на файле .

1908
02:02:55,590 --> 02:02:58,770
eventlog, который был с предыдущим
запуском ваших программ.

1909
02:02:59,730 --> 02:03:01,330
И увидеть, что в данном случае,

1910
02:03:02,810 --> 02:03:08,910
если вы запускаете с
плюс RTS, но без минус n2,

1911
02:03:09,650 --> 02:03:13,090
то есть на один поток, вы будете видеть,
что у вас всего одно ядро задействовано.

1912
02:03:19,970 --> 02:03:22,830
Это применение Monado и
Val, но все еще с одним потоком.

1913
02:03:23,110 --> 02:03:24,970
А вот если же мы скомпилировали с минус n2,

1914
02:03:25,270 --> 02:03:26,810
мы увидим, что вот оно первое ядро,

1915
02:03:27,070 --> 02:03:28,070
вот оно второе ядро,

1916
02:03:29,620 --> 02:03:30,620
оба ядра были загружены.

1917
02:03:31,550 --> 02:03:33,810
Тут мы можем посмотреть
какую-то интересную аналитику

1918
02:03:33,811 --> 02:03:35,950
по количеству спарков,
которая была создана,

1919
02:03:36,270 --> 02:03:39,770
и много всякого интересного, которое,
вполне возможно, нам никогда не пригодится.

1920
02:03:40,970 --> 02:03:42,370
Но если уж очень хочется,

1921
02:03:42,630 --> 02:03:43,850
если уж мы заботимся,

1922
02:03:44,230 --> 02:03:47,210
если нам нужно найти
какой-то bottleneck в

1923
02:03:47,230 --> 02:03:48,230
performance нашей программы,
оно может быть полезно.

1924
02:03:50,370 --> 02:03:53,230
Вот этот вопрос, который вы задавали.

1925
02:03:54,180 --> 02:03:56,210
Давайте просто попробуем
параллелизовать все.

1926
02:03:57,250 --> 02:04:01,030
Проблема в том, что
компилятор недостаточно умный

1927
02:04:01,180 --> 02:04:03,366
для того, чтобы понять, что
параллелить стоит, а что нет.

1928
02:04:03,390 --> 02:04:05,710
Это, в принципе, не является
ответственностью компилятора.

1929
02:04:06,030 --> 02:04:08,890
Можно очень тупо начать параллелить.

1930
02:04:09,010 --> 02:04:11,306
Вот, допустим, представьте
наивную реализацию чисел Фибоначчи,

1931
02:04:11,330 --> 02:04:13,170
которая, как известно,
работает за экспоненту.

1932
02:04:13,610 --> 02:04:16,590
И попытаемся каждый из веток
нашей рекурсии параллелить.

1933
02:04:16,810 --> 02:04:20,010
То есть мы будем плодить
экспоненциальное количество потоков.

1934
02:04:21,090 --> 02:04:23,310
Попробуем все это дело скомпилировать,

1935
02:04:23,370 --> 02:04:27,370
и будем видеть то, что ядра
использованы довольно неоптимально,

1936
02:04:27,650 --> 02:04:31,250
потому что если в этом случае мы видим,

1937
02:04:31,450 --> 02:04:32,450
что все довольно плотно,

1938
02:04:35,510 --> 02:04:40,110
то каждый из ядер все время
делал какую-то полезную

1939
02:04:40,210 --> 02:04:43,010
работу, потому что была
сплошная зеленая полоска.

1940
02:04:44,105 --> 02:04:46,870
Здесь же мы видим, что
желтый – это garbage collect,

1941
02:04:47,500 --> 02:04:51,110
то что было очень много лишних вызовов,

1942
02:04:51,990 --> 02:04:54,510
очень много каких-то лишних
данных, которые сразу в garbage collect.

1943
02:04:54,790 --> 02:04:58,270
И поэтому очень часто были прерывания
между нашими физическими ядрами,

1944
02:04:58,390 --> 02:05:00,930
которых четыре, а на спавне
лимы потоков, простите,

1945
02:05:02,220 --> 02:05:03,341
экспоненциальное количество.

1946
02:05:04,310 --> 02:05:08,730
Это мотивирующий пример, почему
параллелить каждый из действий,

1947
02:05:09,000 --> 02:05:12,610
несмотря на то, что все чистое и,
казалось бы, нам это дозволено, плохо.

1948
02:05:13,390 --> 02:05:16,170
Поэтому вместо того, чтобы параллелить все,

1949
02:05:16,330 --> 02:05:20,010
в Haskell сделали удобный механизм
для параллельных вычислений,

1950
02:05:20,490 --> 02:05:22,490
чтобы разработчик сам об этом задумался.

1951
02:05:23,510 --> 02:05:26,490
Если же вас заинтересовало
параллельное программирование в Haskell,

1952
02:05:27,110 --> 02:05:28,711
можете ознакомиться с следующими вещами.

1953
02:05:29,490 --> 02:05:33,650
Библиотека Repo для вычислений на GPU

1954
02:05:35,210 --> 02:05:40,410
и операций над многомерными
массивами, тензорами и всем остальным.

1955
02:05:41,350 --> 02:05:46,950
И также пакет DPH для вычислений
численных методов на Haskell.

1956
02:05:47,830 --> 02:05:51,110
Мы также не коснулись такой
вещи, как каналы в Haskell,

1957
02:05:51,550 --> 02:05:55,330
Chan и Tchan, аналогичные тому,
что бывает, например, в Golang.

1958
02:05:56,330 --> 02:05:59,510
Также мы не коснулись
другой монады для

1959
02:05:59,610 --> 02:06:00,610
параллельных вычислений,
которая называется Plan.

1960
02:06:00,830 --> 02:06:07,150
Она более интересная, но и, как
следствие, менее простая, чем монада Eval.

1961
02:06:07,700 --> 02:06:09,301
Можно ознакомиться с ней самостоятельно.

1962
02:06:09,630 --> 02:06:13,110
Можно ознакомиться с распределенным
программированием на Haskell,

1963
02:06:13,390 --> 02:06:15,310
с использованием платформы Cloud Haskell,

1964
02:06:15,690 --> 02:06:18,350
которая, к сожалению,
уже давным-давно умерла,

1965
02:06:19,030 --> 02:06:21,050
но мало ли кому-нибудь интересно.

1966
02:06:23,750 --> 02:06:27,610
Кому интересно, там будет ссылочка в
конце про то, как работает Scheduler в VRC.

1967
02:06:28,570 --> 02:06:31,750
И также можно тюнить и дебагить программу.

1968
02:06:31,890 --> 02:06:34,190
Вот тут куча ссылочек на все это дело.

1969
02:06:34,470 --> 02:06:36,070
Если вам интересно, можете ознакомиться.

1970
02:06:36,590 --> 02:06:38,410
На этом мы заканчиваем лекцию.

1971
02:06:39,530 --> 02:06:41,531
Кажется, мы даже более-менее
уложились в тайминге.

1972
02:06:42,210 --> 02:06:43,490
Есть ли у кого какие-то вопросы?

1973
02:06:45,370 --> 02:06:49,570
Зачем проверять вектора, если
они и так в процессорах проверены?

1974
02:06:54,210 --> 02:06:56,110
Вы сразу о каких векторах
речь? Математические.

1975
02:06:57,010 --> 02:06:58,010


1976
02:06:58,890 --> 02:07:00,630
Или тут не математические вектора?

1977
02:07:00,650 --> 02:07:03,090
Нет, тут имеется в виду многомерный вектор.

1978
02:07:03,380 --> 02:07:05,610
Допустим, если вы ML на
Haskell хотите посчитать,

1979
02:07:05,970 --> 02:07:08,290
а почему вы решили, что они и
так параллельно вычисляются?

1980
02:07:08,410 --> 02:07:12,590
Из-за инструкции, из-за
векторов инструкции на СПУ?

1981
02:07:13,830 --> 02:07:14,830
Да.

1982
02:07:15,130 --> 02:07:17,010
Как раз-таки это библиотека.

1983
02:07:18,910 --> 02:07:25,090
Если вы представите ваш
математический вектор Haskell-ным списком,

1984
02:07:25,670 --> 02:07:28,810
он не будет считаться
параллельно либо на ГПУ,

1985
02:07:28,970 --> 02:07:30,650
либо с использованием векторов инструкции.

1986
02:07:30,870 --> 02:07:32,430
То есть это обертка над этим?

1987
02:07:32,930 --> 02:07:37,510
Да, это просто обертка над
вызовами вот этих системных штук.

1988
02:07:39,280 --> 02:07:41,870
Haskell-ные списки плохо
годятся под это дело.

1989
02:07:41,970 --> 02:07:43,250
Это просто специализированная версия.

1990
02:07:43,251 --> 02:07:44,690
Всё окей.

1991
02:07:50,100 --> 02:07:52,520
Окей, если вопросов нет,
видимо, тогда заканчиваем.

1992
02:07:53,640 --> 02:07:56,520
Всем спасибо. Пока.

1993
02:07:57,680 --> 02:07:58,680
Спасибо, до свидания.

1994
02:07:58,720 --> 02:07:59,720
До свидания.

